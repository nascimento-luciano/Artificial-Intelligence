{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nascimento-luciano/Artificial-Intelligence/blob/master/pre_processamento_de_dados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sR6KeHEBCxJ"
      },
      "source": [
        "**Redes Neurais/Aprendizagem de Máquina - Prof. Dr. Luis F. Alves Pereira**\n",
        "\n",
        "---\n",
        "**Conteúdo:**\n",
        "\n",
        "* Carregamento de dados\n",
        "* Pré-processamento de dados \n",
        "    * Dados ausentes\n",
        "    * Dados fora de escala\n",
        "    * Representação de dados categóricos\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#1. Carregamento dos dados\n",
        "\n",
        "\n",
        "Neste exemplo usaremos a base dados **Titanic** que está armazenada em um repositório **git**. Essa coleção de dados contém o registro de um grupo passageiros da primeira e única viagem do navio Titanic. Mais informações sobre os dados podem ser encontrados [aqui](https://www.kaggle.com/c/titanic).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-ydmNm7QE2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "926bdbaa-8e1e-4406-da5e-a3498335bbd0"
      },
      "source": [
        "!mkdir ./data_exp/\n",
        "!git clone https://gist.github.com/0e94a01bd6db87d666866b56f25556d0.git ./data_exp/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into './data_exp'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Total 9 (delta 0), reused 0 (delta 0), pack-reused 9\u001b[K\n",
            "Unpacking objects: 100% (9/9), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjud2ImcEqvc"
      },
      "source": [
        "Para trabalhar com uma base de dados em formato **csv**, podemos carregá-la em memória usando o método **red_csv** da biblioteca **pandas**.\n",
        "\n",
        "Com a base de dados carregada em memória, podemos ter uma visualização rápida dos **n** primeiros registros usando o método **head**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PyMGj54AjdYc",
        "outputId": "0a3ed688-9eb8-4fa5-922e-a92a259eb5cc"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"./data_exp/titanic.csv\")\n",
        "\n",
        "print('A base possui um total de {} registros. Os 30 primeiros são:'.format(len(data)))\n",
        "data.head(30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A base possui um total de 891 registros. Os 30 primeiros são:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Moran, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330877</td>\n",
              "      <td>8.4583</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>McCarthy, Mr. Timothy J</td>\n",
              "      <td>male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17463</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>E46</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Palsson, Master. Gosta Leonard</td>\n",
              "      <td>male</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>349909</td>\n",
              "      <td>21.0750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
              "      <td>female</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>347742</td>\n",
              "      <td>11.1333</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
              "      <td>female</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>237736</td>\n",
              "      <td>30.0708</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
              "      <td>female</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PP 9549</td>\n",
              "      <td>16.7000</td>\n",
              "      <td>G6</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Bonnell, Miss. Elizabeth</td>\n",
              "      <td>female</td>\n",
              "      <td>58.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>113783</td>\n",
              "      <td>26.5500</td>\n",
              "      <td>C103</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Saundercock, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5. 2151</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Andersson, Mr. Anders Johan</td>\n",
              "      <td>male</td>\n",
              "      <td>39.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>347082</td>\n",
              "      <td>31.2750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
              "      <td>female</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>350406</td>\n",
              "      <td>7.8542</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
              "      <td>female</td>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>248706</td>\n",
              "      <td>16.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Rice, Master. Eugene</td>\n",
              "      <td>male</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>382652</td>\n",
              "      <td>29.1250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Williams, Mr. Charles Eugene</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>244373</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
              "      <td>female</td>\n",
              "      <td>31.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>345763</td>\n",
              "      <td>18.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Masselmani, Mrs. Fatima</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2649</td>\n",
              "      <td>7.2250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Fynney, Mr. Joseph J</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>239865</td>\n",
              "      <td>26.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>22</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>Beesley, Mr. Lawrence</td>\n",
              "      <td>male</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>248698</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>D56</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>McGowan, Miss. Anna \"Annie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330923</td>\n",
              "      <td>8.0292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Sloper, Mr. William Thompson</td>\n",
              "      <td>male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>113788</td>\n",
              "      <td>35.5000</td>\n",
              "      <td>A6</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>25</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Palsson, Miss. Torborg Danira</td>\n",
              "      <td>female</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>349909</td>\n",
              "      <td>21.0750</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>347077</td>\n",
              "      <td>31.3875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Emir, Mr. Farred Chehab</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2631</td>\n",
              "      <td>7.2250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Fortune, Mr. Charles Alexander</td>\n",
              "      <td>male</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>19950</td>\n",
              "      <td>263.0000</td>\n",
              "      <td>C23 C25 C27</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330959</td>\n",
              "      <td>7.8792</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Todoroff, Mr. Lalio</td>\n",
              "      <td>male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>349216</td>\n",
              "      <td>7.8958</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    PassengerId  Survived  Pclass  ...      Fare        Cabin  Embarked\n",
              "0             1         0       3  ...    7.2500          NaN         S\n",
              "1             2         1       1  ...   71.2833          C85         C\n",
              "2             3         1       3  ...    7.9250          NaN         S\n",
              "3             4         1       1  ...   53.1000         C123         S\n",
              "4             5         0       3  ...    8.0500          NaN         S\n",
              "5             6         0       3  ...    8.4583          NaN         Q\n",
              "6             7         0       1  ...   51.8625          E46         S\n",
              "7             8         0       3  ...   21.0750          NaN         S\n",
              "8             9         1       3  ...   11.1333          NaN         S\n",
              "9            10         1       2  ...   30.0708          NaN         C\n",
              "10           11         1       3  ...   16.7000           G6         S\n",
              "11           12         1       1  ...   26.5500         C103         S\n",
              "12           13         0       3  ...    8.0500          NaN         S\n",
              "13           14         0       3  ...   31.2750          NaN         S\n",
              "14           15         0       3  ...    7.8542          NaN         S\n",
              "15           16         1       2  ...   16.0000          NaN         S\n",
              "16           17         0       3  ...   29.1250          NaN         Q\n",
              "17           18         1       2  ...   13.0000          NaN         S\n",
              "18           19         0       3  ...   18.0000          NaN         S\n",
              "19           20         1       3  ...    7.2250          NaN         C\n",
              "20           21         0       2  ...   26.0000          NaN         S\n",
              "21           22         1       2  ...   13.0000          D56         S\n",
              "22           23         1       3  ...    8.0292          NaN         Q\n",
              "23           24         1       1  ...   35.5000           A6         S\n",
              "24           25         0       3  ...   21.0750          NaN         S\n",
              "25           26         1       3  ...   31.3875          NaN         S\n",
              "26           27         0       3  ...    7.2250          NaN         C\n",
              "27           28         0       1  ...  263.0000  C23 C25 C27         S\n",
              "28           29         1       3  ...    7.8792          NaN         Q\n",
              "29           30         0       3  ...    7.8958          NaN         S\n",
              "\n",
              "[30 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8iH-25SkJ7Z"
      },
      "source": [
        "#2.Pré-processamento de dados\n",
        "\n",
        "Os dados brutos geralmente não estão prontos para serem analisados e processados por ferramentas e técnicas estatísticas e de aprendizagem de máquina. Os principais problemas que encontramos ao iniciar um trabalho com uma nova base de dados são: **dados ausentes** e **dados fora de escala**. \n",
        "\n",
        "###2.1. Dados ausentes\n",
        "\n",
        "Para checar se nossa base possui dados ausentes, podemos usar o metodo *Pandas.DataFrame.isna()* que retorna **True** para as células da base com valor **NaN**:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyWsTgZ5kOMt",
        "outputId": "c88b5527-5e63-45f1-d87d-81454bf761ac"
      },
      "source": [
        "data.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age            177\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             0\n",
              "Cabin          687\n",
              "Embarked         2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_0U8xQpJ7QM"
      },
      "source": [
        "Para remover os dados ausentes podemos usar duas abordagens: **descartar dados** ou **substituir dados ausentes**.\n",
        "\n",
        "####2.1.1. Descarte de dados\n",
        "\n",
        "Podemos descartar *(i)* todo um registro/exemplo (linha) da base que contém ao menos um dado ausente ou *(ii)* todas as features (coluna) que contém ao menos um dado ausente.\n",
        "\n",
        "#####2.1.1.1. Descarte de registros com dados ausentes\n",
        "\n",
        "Para isso, utilizamos o método *Pandas.DataFrame.dropna()* com o parâmetro **axis** igual a 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "A5oDeVnOMC-U",
        "outputId": "c91819d0-dce3-4c8a-aa99-e8e3ab841501"
      },
      "source": [
        "data = data.dropna(axis=0)\n",
        "print('A base possui um total de {} registros. Os 5 primeiros são:'.format(len(data)))\n",
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A base possui um total de 183 registros. Os 5 primeiros são:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>McCarthy, Mr. Timothy J</td>\n",
              "      <td>male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17463</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>E46</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
              "      <td>female</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>PP 9549</td>\n",
              "      <td>16.7000</td>\n",
              "      <td>G6</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Bonnell, Miss. Elizabeth</td>\n",
              "      <td>female</td>\n",
              "      <td>58.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>113783</td>\n",
              "      <td>26.5500</td>\n",
              "      <td>C103</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "1             2         1       1  ...  71.2833   C85         C\n",
              "3             4         1       1  ...  53.1000  C123         S\n",
              "6             7         0       1  ...  51.8625   E46         S\n",
              "10           11         1       3  ...  16.7000    G6         S\n",
              "11           12         1       1  ...  26.5500  C103         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGY2SAUurSKl"
      },
      "source": [
        "Checagem de valores **NaN** na base:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DZwfJb_MVRW",
        "outputId": "89b28592-1e87-43f9-e5cc-694e52effc6e"
      },
      "source": [
        "data.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId    0\n",
              "Survived       0\n",
              "Pclass         0\n",
              "Name           0\n",
              "Sex            0\n",
              "Age            0\n",
              "SibSp          0\n",
              "Parch          0\n",
              "Ticket         0\n",
              "Fare           0\n",
              "Cabin          0\n",
              "Embarked       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHtd9WirtzoQ"
      },
      "source": [
        "É possível ser um pouco mais específico e aplicar o descarte de registros apenas a um subconjunto da base. Veja o exemplo a seguir que elimina apenas os registros em que a idade é desconhecida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "TDsIEMsFt2RI",
        "outputId": "a8a35097-aafa-4086-807c-aac868646ae5"
      },
      "source": [
        "data = pd.read_csv(\"./data_exp/titanic.csv\") #necessário recarregar a base pois os valores NaN foram eliminados anteriormente\n",
        "data = data.dropna(subset=['Age'],axis=0)\n",
        "print('A base possui um total de {} registros. Os 5 primeiros são:'.format(len(data)))\n",
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A base possui um total de 714 registros. Os 5 primeiros são:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "3            4         1       1  ...  53.1000  C123         S\n",
              "4            5         0       3  ...   8.0500   NaN         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE_Lq6y7uvpZ"
      },
      "source": [
        "Checagem de valores **NaN** na base:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRRikK_9uz64",
        "outputId": "247ef41a-514c-40fd-8125-6aaf08d25751"
      },
      "source": [
        "data.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age              0\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             0\n",
              "Cabin          529\n",
              "Embarked         2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bA4mjNcGLMa2"
      },
      "source": [
        "#####2.1.1.2. Descarte de colunas com dados ausentes\n",
        "\n",
        "Para isso, utilizamos o método **dropna** com o parâmetro **axis** igual a 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "f2GYYo5fsKdh",
        "outputId": "1af9ce68-1dfe-4a79-87cb-9b0b3ec2b2b8"
      },
      "source": [
        "data = pd.read_csv(\"./data_exp/titanic.csv\") #necessário recarregar a base pois os valores NaN foram eliminados anteriormente\n",
        "data = data.dropna(axis=1)\n",
        "print('A base possui um total de {} registros. Os 5 primeiros são:'.format(len(data)))\n",
        "data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A base possui um total de 891 registros. Os 5 primeiros são:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ... Parch            Ticket     Fare\n",
              "0            1         0       3  ...     0         A/5 21171   7.2500\n",
              "1            2         1       1  ...     0          PC 17599  71.2833\n",
              "2            3         1       3  ...     0  STON/O2. 3101282   7.9250\n",
              "3            4         1       1  ...     0            113803  53.1000\n",
              "4            5         0       3  ...     0            373450   8.0500\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_U4QamOsn_x"
      },
      "source": [
        "Checagem de valores **NaN** na base:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNsSIkIystBk",
        "outputId": "9f1d7ddd-6e36-4785-8026-de97a7497340"
      },
      "source": [
        "data.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId    0\n",
              "Survived       0\n",
              "Pclass         0\n",
              "Name           0\n",
              "Sex            0\n",
              "SibSp          0\n",
              "Parch          0\n",
              "Ticket         0\n",
              "Fare           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4CQryS1vDex"
      },
      "source": [
        "####2.1.2. Substituição de dados\n",
        "\n",
        "Também é possível substuir os dados ausentes para evitar o descarte de dados. No entanto, essa opção está associada a uma questão fundamental: qual valor deve ser inserido para substituir um dado ausente? A solução depende do tipo de dado em questão:\n",
        "\n",
        "* para **atributos numéricos**, pode-se substituir o valor ausente pela média da medida encontrada ao longo de toda a base;\n",
        "* para **atributos categóricos**, pode-se substituir o valor ausente pelo valor mais frequente encontrado ao longo de toda a base; \n",
        "\n",
        "No próximo código, os valores NaN em todos os atributos numéricos da base são substituídos pela média dos valores das colunas.\n",
        "\n",
        "Veja que, através do método *Pandas.DataFrame.fillna()* é possível indicar o novo valor que irá substituir os NaNs (ou dict/DataFrames que especifiquem o novo valor para cada atributo da base).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDRBe8ZZ7oHF",
        "outputId": "021a5cc9-dbe0-4d07-8ca4-e81fa5257885"
      },
      "source": [
        "#necessário recarregar a base pois os valores NaN foram eliminados anteriormente\n",
        "data = pd.read_csv(\"./data_exp/titanic.csv\") \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "numeric_columns = data.select_dtypes(include=np.number).columns.tolist()\n",
        "data[numeric_columns] = data[numeric_columns].fillna(data.mean())\n",
        "data.isna().sum()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId      0\n",
              "Survived         0\n",
              "Pclass           0\n",
              "Name             0\n",
              "Sex              0\n",
              "Age              0\n",
              "SibSp            0\n",
              "Parch            0\n",
              "Ticket           0\n",
              "Fare             0\n",
              "Cabin          687\n",
              "Embarked         2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVUaWVJpBzxz"
      },
      "source": [
        "A seguir, demonstramos o tratamento para os atributos categóricos da base substituindo cada ocorrência de NaN pelo valor mais frequênte na respectiva coluna.\n",
        "\n",
        "Veja que o método Pandas.DataFrame.mode() retorna o valor mais frequente de cada atributo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3ulCzvJB0MS",
        "outputId": "ce2416b1-5d4d-4af9-e405-aec837726ef2"
      },
      "source": [
        "categorical_columns = data.select_dtypes(include=np.object).columns.tolist()\n",
        "\n",
        "data[categorical_columns] = data[categorical_columns].fillna(data[categorical_columns].mode().loc[0])\n",
        "print(\"valores utilizados para substituir os dados ausentes:\")\n",
        "data[categorical_columns].mode().loc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valores utilizados para substituir os dados ausentes:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Name        Abbing, Mr. Anthony\n",
              "Sex                        male\n",
              "Ticket                     1601\n",
              "Cabin                   B96 B98\n",
              "Embarked                      S\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1HX1GgzL7Zu"
      },
      "source": [
        "Checagem por NaNs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zFvKPDjL04w",
        "outputId": "2bfe51fe-ffb6-4272-826f-de31bb4ec61d"
      },
      "source": [
        "data.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PassengerId    0\n",
              "Survived       0\n",
              "Pclass         0\n",
              "Name           0\n",
              "Sex            0\n",
              "Age            0\n",
              "SibSp          0\n",
              "Parch          0\n",
              "Ticket         0\n",
              "Fare           0\n",
              "Cabin          0\n",
              "Embarked       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HSCfOqrI8D6"
      },
      "source": [
        "###2.2. Dados fora de escala\n",
        "\n",
        "A seguir, vemos a descrição estatítica dos dados numéricos da base de dados Titanic. Veja que o atributo **Age** está distrbuido entre os valores *0.42 - 80*. Enquanto isso os valores em **Fare** variam entre *0 - 512.33*.\n",
        "\n",
        "Desta forma, quando aplicados à entrada de um neurônio com pesos iniciais com valores entre *0 - 1*, o atrbuto **Fare** iria se sobrepor ao atributo **Age**. Várias épocas do treinamento da rede neural seriam necessárias para que os pesos se ajustassem apenas para compensar esse efeito.\n",
        "\n",
        "Dessa forma, veremos aqui duas técnicas de pré-processamento para equalizar as distribuções dos dados entre atributos: a **padronização** e a **normalização**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OixVYkQNI7Wb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "4ba4a08a-e70b-46f1-9ba7-e65b024bfbf8"
      },
      "source": [
        "data[numeric.columns].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.383838</td>\n",
              "      <td>2.308642</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0.523008</td>\n",
              "      <td>0.381594</td>\n",
              "      <td>32.204208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>257.353842</td>\n",
              "      <td>0.486592</td>\n",
              "      <td>0.836071</td>\n",
              "      <td>13.002015</td>\n",
              "      <td>1.102743</td>\n",
              "      <td>0.806057</td>\n",
              "      <td>49.693429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>223.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.910400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.454200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>668.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId    Survived      Pclass  ...       SibSp       Parch        Fare\n",
              "count   891.000000  891.000000  891.000000  ...  891.000000  891.000000  891.000000\n",
              "mean    446.000000    0.383838    2.308642  ...    0.523008    0.381594   32.204208\n",
              "std     257.353842    0.486592    0.836071  ...    1.102743    0.806057   49.693429\n",
              "min       1.000000    0.000000    1.000000  ...    0.000000    0.000000    0.000000\n",
              "25%     223.500000    0.000000    2.000000  ...    0.000000    0.000000    7.910400\n",
              "50%     446.000000    0.000000    3.000000  ...    0.000000    0.000000   14.454200\n",
              "75%     668.500000    1.000000    3.000000  ...    1.000000    0.000000   31.000000\n",
              "max     891.000000    1.000000    3.000000  ...    8.000000    6.000000  512.329200\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc_PvlpULi1N"
      },
      "source": [
        "####2.2.1. Padronização\n",
        "\n",
        "O objetivo da padronização é tranformar os dados em uma distribuição com média 0 e desvio padrão 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "XIigEe5OPHY9",
        "outputId": "3f2bc357-610a-4383-ee4b-34ee239bc750"
      },
      "source": [
        "from scipy.stats import zscore\n",
        "\n",
        "numeric_columns = numeric.columns.to_list()\n",
        "numeric_columns.remove(\"PassengerId\")\n",
        "numeric_columns.remove(\"Survived\")\n",
        "\n",
        "data[numeric_columns] = zscore(data[numeric_columns])\n",
        "\n",
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>8.910000e+02</td>\n",
              "      <td>8.910000e+02</td>\n",
              "      <td>8.910000e+02</td>\n",
              "      <td>8.910000e+02</td>\n",
              "      <td>8.910000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.383838</td>\n",
              "      <td>-1.091532e-16</td>\n",
              "      <td>1.570012e-17</td>\n",
              "      <td>3.643426e-16</td>\n",
              "      <td>7.675616e-17</td>\n",
              "      <td>-4.373606e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>257.353842</td>\n",
              "      <td>0.486592</td>\n",
              "      <td>1.000562e+00</td>\n",
              "      <td>1.000562e+00</td>\n",
              "      <td>1.000562e+00</td>\n",
              "      <td>1.000562e+00</td>\n",
              "      <td>1.000562e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.566107e+00</td>\n",
              "      <td>-2.253155e+00</td>\n",
              "      <td>-4.745452e-01</td>\n",
              "      <td>-4.736736e-01</td>\n",
              "      <td>-6.484217e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>223.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-3.693648e-01</td>\n",
              "      <td>-5.924806e-01</td>\n",
              "      <td>-4.745452e-01</td>\n",
              "      <td>-4.736736e-01</td>\n",
              "      <td>-4.891482e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.273772e-01</td>\n",
              "      <td>-1.834173e-16</td>\n",
              "      <td>-4.745452e-01</td>\n",
              "      <td>-4.736736e-01</td>\n",
              "      <td>-3.573909e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>668.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.273772e-01</td>\n",
              "      <td>4.079260e-01</td>\n",
              "      <td>4.327934e-01</td>\n",
              "      <td>-4.736736e-01</td>\n",
              "      <td>-2.424635e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.273772e-01</td>\n",
              "      <td>3.870872e+00</td>\n",
              "      <td>6.784163e+00</td>\n",
              "      <td>6.974147e+00</td>\n",
              "      <td>9.667167e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId    Survived  ...         Parch          Fare\n",
              "count   891.000000  891.000000  ...  8.910000e+02  8.910000e+02\n",
              "mean    446.000000    0.383838  ...  7.675616e-17 -4.373606e-17\n",
              "std     257.353842    0.486592  ...  1.000562e+00  1.000562e+00\n",
              "min       1.000000    0.000000  ... -4.736736e-01 -6.484217e-01\n",
              "25%     223.500000    0.000000  ... -4.736736e-01 -4.891482e-01\n",
              "50%     446.000000    0.000000  ... -4.736736e-01 -3.573909e-01\n",
              "75%     668.500000    1.000000  ... -4.736736e-01 -2.424635e-02\n",
              "max     891.000000    1.000000  ...  6.974147e+00  9.667167e+00\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2FjlNgJR5Ry"
      },
      "source": [
        "Visualização do estado final da base de dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "m6n-eIrjSAcw",
        "outputId": "c6861ae4-9948-4e8f-f832-768889d4a036"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.827377</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>-5.924806e-01</td>\n",
              "      <td>0.432793</td>\n",
              "      <td>-0.473674</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>-0.502445</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.566107</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>6.387890e-01</td>\n",
              "      <td>0.432793</td>\n",
              "      <td>-0.473674</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>0.786845</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0.827377</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>-2.846632e-01</td>\n",
              "      <td>-0.474545</td>\n",
              "      <td>-0.473674</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>-0.488854</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.566107</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>4.079260e-01</td>\n",
              "      <td>0.432793</td>\n",
              "      <td>-0.473674</td>\n",
              "      <td>113803</td>\n",
              "      <td>0.420730</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.827377</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>4.079260e-01</td>\n",
              "      <td>-0.474545</td>\n",
              "      <td>-0.473674</td>\n",
              "      <td>373450</td>\n",
              "      <td>-0.486337</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.369365</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>-2.077088e-01</td>\n",
              "      <td>-0.474545</td>\n",
              "      <td>-0.473674</td>\n",
              "      <td>211536</td>\n",
              "      <td>-0.386671</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.566107</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>-8.233437e-01</td>\n",
              "      <td>-0.474545</td>\n",
              "      <td>-0.473674</td>\n",
              "      <td>112053</td>\n",
              "      <td>-0.044381</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>0.827377</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>-1.834173e-16</td>\n",
              "      <td>0.432793</td>\n",
              "      <td>2.008933</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>-0.176263</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.566107</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>-2.846632e-01</td>\n",
              "      <td>-0.474545</td>\n",
              "      <td>-0.473674</td>\n",
              "      <td>111369</td>\n",
              "      <td>-0.044381</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>0.827377</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>1.770629e-01</td>\n",
              "      <td>-0.474545</td>\n",
              "      <td>-0.473674</td>\n",
              "      <td>370376</td>\n",
              "      <td>-0.492378</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived    Pclass  ...      Fare    Cabin  Embarked\n",
              "0              1         0  0.827377  ... -0.502445  B96 B98         S\n",
              "1              2         1 -1.566107  ...  0.786845      C85         C\n",
              "2              3         1  0.827377  ... -0.488854  B96 B98         S\n",
              "3              4         1 -1.566107  ...  0.420730     C123         S\n",
              "4              5         0  0.827377  ... -0.486337  B96 B98         S\n",
              "..           ...       ...       ...  ...       ...      ...       ...\n",
              "886          887         0 -0.369365  ... -0.386671  B96 B98         S\n",
              "887          888         1 -1.566107  ... -0.044381      B42         S\n",
              "888          889         0  0.827377  ... -0.176263  B96 B98         S\n",
              "889          890         1 -1.566107  ... -0.044381     C148         C\n",
              "890          891         0  0.827377  ... -0.492378  B96 B98         Q\n",
              "\n",
              "[891 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OiqbBZ3PIRT"
      },
      "source": [
        "####2.2.2. Normalização\n",
        "\n",
        "O objetivo da normalização é tranformar os dados em uma distribuição com valores entre 0 e 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFQV8l4hPxfL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "9d075a6b-3487-4fc0-b5da-bcb0c6729d0b"
      },
      "source": [
        "data = pd.read_csv(\"./data_exp/titanic.csv\") #necessário recarregar a base pois a base agora está padronizada\n",
        "\n",
        "numeric_columns = data.select_dtypes(include=np.number).columns.tolist()\n",
        "data[numeric_columns] = data[numeric_columns].fillna(data.mean()) #substituindo missing values numéricos\n",
        "\n",
        "categorical_columns = data.select_dtypes(include=np.object).columns.tolist()\n",
        "data[categorical_columns] = data[categorical_columns].fillna(data[categorical_columns].mode().loc[0]) #subsitituindo missing values categoricos\n",
        "\n",
        "data[numeric_columns] = (data[numeric_columns]-data[numeric_columns].min())/(data[numeric_columns].max()-data[numeric_columns].min())\n",
        "\n",
        "data[numeric_columns].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.383838</td>\n",
              "      <td>0.654321</td>\n",
              "      <td>0.367921</td>\n",
              "      <td>0.065376</td>\n",
              "      <td>0.063599</td>\n",
              "      <td>0.062858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.289162</td>\n",
              "      <td>0.486592</td>\n",
              "      <td>0.418036</td>\n",
              "      <td>0.163383</td>\n",
              "      <td>0.137843</td>\n",
              "      <td>0.134343</td>\n",
              "      <td>0.096995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.271174</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.367921</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.028213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.060508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId    Survived      Pclass  ...       SibSp       Parch        Fare\n",
              "count   891.000000  891.000000  891.000000  ...  891.000000  891.000000  891.000000\n",
              "mean      0.500000    0.383838    0.654321  ...    0.065376    0.063599    0.062858\n",
              "std       0.289162    0.486592    0.418036  ...    0.137843    0.134343    0.096995\n",
              "min       0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
              "25%       0.250000    0.000000    0.500000  ...    0.000000    0.000000    0.015440\n",
              "50%       0.500000    0.000000    1.000000  ...    0.000000    0.000000    0.028213\n",
              "75%       0.750000    1.000000    1.000000  ...    0.125000    0.000000    0.060508\n",
              "max       1.000000    1.000000    1.000000  ...    1.000000    1.000000    1.000000\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwGrxSStVMPx"
      },
      "source": [
        "Visualização do estado final da base de dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "pLzDUEH9VP5c",
        "outputId": "5b8d5e6d-5d65-474d-acf5-3e040b000085"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>0.271174</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>0.014151</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001124</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>0.472229</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>0.139136</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002247</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>0.015469</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.003371</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>113803</td>\n",
              "      <td>0.103644</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.004494</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>373450</td>\n",
              "      <td>0.015713</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0.995506</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>0.334004</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>211536</td>\n",
              "      <td>0.025374</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>0.996629</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>0.233476</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112053</td>\n",
              "      <td>0.058556</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0.997753</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>0.367921</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>0.045771</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>0.998876</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>111369</td>\n",
              "      <td>0.058556</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>0.396833</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>370376</td>\n",
              "      <td>0.015127</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...      Fare    Cabin  Embarked\n",
              "0       0.000000       0.0     1.0  ...  0.014151  B96 B98         S\n",
              "1       0.001124       1.0     0.0  ...  0.139136      C85         C\n",
              "2       0.002247       1.0     1.0  ...  0.015469  B96 B98         S\n",
              "3       0.003371       1.0     0.0  ...  0.103644     C123         S\n",
              "4       0.004494       0.0     1.0  ...  0.015713  B96 B98         S\n",
              "..           ...       ...     ...  ...       ...      ...       ...\n",
              "886     0.995506       0.0     0.5  ...  0.025374  B96 B98         S\n",
              "887     0.996629       1.0     0.0  ...  0.058556      B42         S\n",
              "888     0.997753       0.0     1.0  ...  0.045771  B96 B98         S\n",
              "889     0.998876       1.0     0.0  ...  0.058556     C148         C\n",
              "890     1.000000       0.0     1.0  ...  0.015127  B96 B98         Q\n",
              "\n",
              "[891 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar6exTMcY7eY"
      },
      "source": [
        "### 2.3. Representação de dados categóricos\n",
        "\n",
        "Agora que já processamos os atributos numéricos, nos restam os dados categóricos. Como alimentar uma rede neural com dados categóricos?\n",
        "\n",
        "Veremos aqui duas estratégias: *Integer Enconding* e *One Hot Encoding*\n",
        "\n",
        "####2.2.1. *Integer Encoding*\n",
        "\n",
        "Nessa estratégia um valor numérico será atribuído para cada label categórica única.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X08oi3yY6ZZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "a4731efc-6415-43f8-9a2e-a73379f99f26"
      },
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "enc = OrdinalEncoder()\n",
        "enc.fit(data[['Sex']])\n",
        "data['Sex'] = enc.transform(data[['Sex']])\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.271174</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>0.014151</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001124</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.472229</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>0.139136</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002247</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>0.015469</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.003371</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>113803</td>\n",
              "      <td>0.103644</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.004494</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.434531</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>373450</td>\n",
              "      <td>0.015713</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0.995506</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.334004</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>211536</td>\n",
              "      <td>0.025374</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>0.996629</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.233476</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>112053</td>\n",
              "      <td>0.058556</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0.997753</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.367921</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>0.045771</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>0.998876</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.321438</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>111369</td>\n",
              "      <td>0.058556</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.396833</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>370376</td>\n",
              "      <td>0.015127</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ...      Fare    Cabin  Embarked\n",
              "0       0.000000       0.0     1.0  ...  0.014151  B96 B98         S\n",
              "1       0.001124       1.0     0.0  ...  0.139136      C85         C\n",
              "2       0.002247       1.0     1.0  ...  0.015469  B96 B98         S\n",
              "3       0.003371       1.0     0.0  ...  0.103644     C123         S\n",
              "4       0.004494       0.0     1.0  ...  0.015713  B96 B98         S\n",
              "..           ...       ...     ...  ...       ...      ...       ...\n",
              "886     0.995506       0.0     0.5  ...  0.025374  B96 B98         S\n",
              "887     0.996629       1.0     0.0  ...  0.058556      B42         S\n",
              "888     0.997753       0.0     1.0  ...  0.045771  B96 B98         S\n",
              "889     0.998876       1.0     0.0  ...  0.058556     C148         C\n",
              "890     1.000000       0.0     1.0  ...  0.015127  B96 B98         Q\n",
              "\n",
              "[891 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4y6UxV1ZUHh"
      },
      "source": [
        "####2.2.2. *One Hot Encoding*\n",
        "\n",
        "Representação onde cada valor categórico representa uma dimensão no vetor resultante.\n",
        "\n",
        "**Importante:** deve-se utiizar a codificação One Hot Enconding para representar classes categóricas que são as saídas em problemas de classificação!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "-Yk6fGHbelE-",
        "outputId": "0f258235-9e7f-4283-f31d-b1d6a8bbd117"
      },
      "source": [
        "data = pd.read_csv(\"./data_exp/titanic.csv\") \n",
        "\n",
        "numeric_columns = data.select_dtypes(include=np.number).columns.tolist()\n",
        "data[numeric_columns] = data[numeric_columns].fillna(data.mean()) #substituindo missing values numéricos\n",
        "\n",
        "categorical_columns = data.select_dtypes(include=np.object).columns.tolist()\n",
        "data[categorical_columns] = data[categorical_columns].fillna(data[categorical_columns].mode().loc[0]) #subsitituindo missing values categoricos\n",
        "\n",
        "new_sex = pd.get_dummies(data.Sex)\n",
        "data = pd.concat([data,y], axis=1)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>female</th>\n",
              "      <th>male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>male</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>female</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>female</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>male</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>male</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>Q</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ... Embarked female  male\n",
              "0              1         0       3  ...        S      0     1\n",
              "1              2         1       1  ...        C      1     0\n",
              "2              3         1       3  ...        S      1     0\n",
              "3              4         1       1  ...        S      1     0\n",
              "4              5         0       3  ...        S      0     1\n",
              "..           ...       ...     ...  ...      ...    ...   ...\n",
              "886          887         0       2  ...        S      0     1\n",
              "887          888         1       1  ...        S      1     0\n",
              "888          889         0       3  ...        S      1     0\n",
              "889          890         1       1  ...        C      0     1\n",
              "890          891         0       3  ...        Q      0     1\n",
              "\n",
              "[891 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKmJUZbqh2XD"
      },
      "source": [
        "Por fim, removemos o atributo *Sex* que não será mais usado na base:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9yHcN94WikTP",
        "outputId": "a3cdd46e-5bea-4f68-ec57-7fbf846e4893"
      },
      "source": [
        "atributos = data.columns.tolist()\n",
        "atributos.remove(\"Sex\")\n",
        "data = data[atributos]\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>female</th>\n",
              "      <th>male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Montvila, Rev. Juozas</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211536</td>\n",
              "      <td>13.0000</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>888</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Graham, Miss. Margaret Edith</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>112053</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>B42</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>889</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>W./C. 6607</td>\n",
              "      <td>23.4500</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>S</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>890</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Behr, Mr. Karl Howell</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>111369</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>C148</td>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>891</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Dooley, Mr. Patrick</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>370376</td>\n",
              "      <td>7.7500</td>\n",
              "      <td>B96 B98</td>\n",
              "      <td>Q</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     PassengerId  Survived  Pclass  ... Embarked  female  male\n",
              "0              1         0       3  ...        S       0     1\n",
              "1              2         1       1  ...        C       1     0\n",
              "2              3         1       3  ...        S       1     0\n",
              "3              4         1       1  ...        S       1     0\n",
              "4              5         0       3  ...        S       0     1\n",
              "..           ...       ...     ...  ...      ...     ...   ...\n",
              "886          887         0       2  ...        S       0     1\n",
              "887          888         1       1  ...        S       1     0\n",
              "888          889         0       3  ...        S       1     0\n",
              "889          890         1       1  ...        C       0     1\n",
              "890          891         0       3  ...        Q       0     1\n",
              "\n",
              "[891 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8JLTQI6l6P0"
      },
      "source": [
        "#3. Prática com Redes Neurais\n",
        "\n",
        "Implemente três experimentos para classificação de instâncias da base Titanic em *Survived* e *Not Survived*. As condições de cada exprimentos são indicados a seguir:\n",
        "\n",
        "* Rede com uma única camada (além das camadas de etrada e saída) com 3 neurônios usando apenas funções de ativação sigmoid;\n",
        "\n",
        "* Rede com duas camadas (além das camadas de etrada e saída) com 3 neurônios cada usando apenas funções de ativação sigmoid;\n",
        "\n",
        "* Rede com três camadas (além das camadas de etrada e saída) com 3 neurônios cada usando as funções de ativação Relu e sigmoid;\n",
        "\n",
        "Apresente o decaimento da *Loss Function* durante cada um dos treinamentos, bem como as taxas finais de acerto para cada um dos casos. Por fim, **discuta** o que os resultados indicam sobre as capacidades de generalização das três redes. Como você explica os resultados obtidos?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicialmente, vamos carregar a base de dados:"
      ],
      "metadata": {
        "id": "yig8bhYX1FAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"./data_exp/titanic.csv\")\n",
        "\n",
        "print('A base possui um total de {} registros. Os 30 primeiros são:'.format(len(data)))\n",
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "DOTPcnw91FXF",
        "outputId": "7b195a88-ae3e-414e-e585-c535ed2936d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A base possui um total de 891 registros. Os 30 primeiros são:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac1600f6-5f78-4388-8138-7729c01d67a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac1600f6-5f78-4388-8138-7729c01d67a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac1600f6-5f78-4388-8138-7729c01d67a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac1600f6-5f78-4388-8138-7729c01d67a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesse exemplo inicial, vamos considerar apenas os atributos numéricos e o atributo categórico \"sexo\". Em seguida, procedemos com o pré-processamento para retirar os missing values..."
      ],
      "metadata": {
        "id": "sidhuZwG1Tit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "numeric_columns = data.select_dtypes(include=np.number).columns.tolist()\n",
        "numeric_columns.remove('PassengerId')\n",
        "newdata = data[numeric_columns]\n",
        "newdata = pd.concat([newdata, pd.get_dummies(data.Sex) ],axis=1)\n",
        "newdata.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1vJ-5ot1T0p",
        "outputId": "1893dea0-06e0-42e5-8564-d3efb29cb682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Survived      0\n",
              "Pclass        0\n",
              "Age         177\n",
              "SibSp         0\n",
              "Parch         0\n",
              "Fare          0\n",
              "female        0\n",
              "male          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = newdata.dropna(subset=['Age'],axis=0)\n",
        "print('A base possui um total de {} registros. Os 5 primeiros são:'.format(len(data)))\n",
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "AVdmVFHG1uea",
        "outputId": "5cb27742-4b5e-4494-9c5a-3858a0db8c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A base possui um total de 714 registros. Os 5 primeiros são:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Survived  Pclass   Age  SibSp  Parch     Fare  female  male\n",
              "0         0       3  22.0      1      0   7.2500       0     1\n",
              "1         1       1  38.0      1      0  71.2833       1     0\n",
              "2         1       3  26.0      0      0   7.9250       1     0\n",
              "3         1       1  35.0      1      0  53.1000       1     0\n",
              "4         0       3  35.0      0      0   8.0500       0     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d9848d42-435b-432e-864c-05b408db0e81\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>female</th>\n",
              "      <th>male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9848d42-435b-432e-864c-05b408db0e81')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d9848d42-435b-432e-864c-05b408db0e81 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d9848d42-435b-432e-864c-05b408db0e81');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHp5s1Lj1yyd",
        "outputId": "9cfcd800-66a2-42f5-a4c4-c5f347b56bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Survived    0\n",
              "Pclass      0\n",
              "Age         0\n",
              "SibSp       0\n",
              "Parch       0\n",
              "Fare        0\n",
              "female      0\n",
              "male        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em seguida, dividimos os dados em treinamento, validação e teste."
      ],
      "metadata": {
        "id": "ZRr2x7VO12FN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prop = {'train': 0.5,  'val':0.25,  'test': 0.25}\n",
        "\n",
        "data.sample(frac=1) #randomização na ordem dos dados\n",
        "data_train = data.sample(frac=prop['train'])\n",
        "data_not_train = data.drop(data_train.index)\n",
        "data_val = data_not_train.sample(frac=prop['val']*1/(1-prop['train']))\n",
        "data_test = data_not_train.drop(data_val.index)\n",
        "\n",
        "print(\"Tamanho da base original:\", len(data))\n",
        "print(\"Tamanho da base de treino:\", len(data_train))\n",
        "print(\"Tamanho da base de validação:\", len(data_val))\n",
        "print(\"Tamanho da base de teste:\", len(data_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Id7FqIPA16W4",
        "outputId": "8e83c93b-64b0-465f-dc3a-d8e7699840a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho da base original: 714\n",
            "Tamanho da base de treino: 357\n",
            "Tamanho da base de validação: 178\n",
            "Tamanho da base de teste: 179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, é importante separar as features e as labels em cada uma das partições de dados:"
      ],
      "metadata": {
        "id": "rPGhOPf819ry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = data_train.columns.to_list()\n",
        "features.remove('Survived')\n",
        "\n",
        "features_data_train = data_train[features]\n",
        "labels_data_train = data_train['Survived']\n",
        "\n",
        "features_data_val = data_val[features]\n",
        "labels_data_val = data_val['Survived']\n",
        "\n",
        "features_data_test = data_test[features]\n",
        "labels_data_test = data_test['Survived']\n",
        "\n",
        "labels_data_train = pd.get_dummies(data_train.Survived)\n",
        "labels_data_val= pd.get_dummies(data_val.Survived)\n",
        "labels_data_test= pd.get_dummies(data_test.Survived)"
      ],
      "metadata": {
        "id": "7QFFsmnR2HAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos visualizar uma amostra das features e labels para treino.\n",
        "\n",
        "Primeiro, as features de treino:"
      ],
      "metadata": {
        "id": "dMFEz_fM2n1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_data_train.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YupYsSvY2yNN",
        "outputId": "5726b4fb-7579-4104-98e6-5087af76956e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Pclass   Age  SibSp  Parch      Fare  female  male\n",
              "177       1  50.0      0      0   28.7125       1     0\n",
              "550       1  17.0      0      2  110.8833       0     1\n",
              "422       3  29.0      0      0    7.8750       0     1\n",
              "377       1  27.0      0      2  211.5000       0     1\n",
              "788       3   1.0      1      2   20.5750       0     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa76def6-a906-4180-88ea-6751a00f830d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>female</th>\n",
              "      <th>male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>1</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28.7125</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>550</th>\n",
              "      <td>1</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>110.8833</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>3</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.8750</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>1</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>211.5000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>20.5750</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa76def6-a906-4180-88ea-6751a00f830d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa76def6-a906-4180-88ea-6751a00f830d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa76def6-a906-4180-88ea-6751a00f830d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, uma amostra das labels de treino:"
      ],
      "metadata": {
        "id": "K6ClMEkD3BQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_data_train.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "--Zx8dy13EWm",
        "outputId": "03220ead-d876-451f-b394-bb9897a49fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     0  1\n",
              "177  1  0\n",
              "550  0  1\n",
              "422  1  0\n",
              "377  1  0\n",
              "788  0  1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3b9ac6c-f465-4d9e-8932-3de205324746\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>550</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3b9ac6c-f465-4d9e-8932-3de205324746')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3b9ac6c-f465-4d9e-8932-3de205324746 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3b9ac6c-f465-4d9e-8932-3de205324746');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos agora padronizar todos os dados de acordo com parâmetros identificados na base de treino."
      ],
      "metadata": {
        "id": "Dhz3QdZb3Npp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "numeric_columns.remove(\"Survived\")\n",
        "\n",
        "train_mean = features_data_train[numeric_columns].mean()\n",
        "train_std = features_data_train[numeric_columns].std()\n",
        "\n",
        "features_data_train[numeric_columns] = (features_data_train[numeric_columns]-train_mean)/(train_std)\n",
        "features_data_train.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "3uujjhsz3NxM",
        "outputId": "4fbc7c29-0469-4dc6-a199-3b766d8fe0a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Pclass       Age     SibSp     Parch      Fare  female  male\n",
              "177 -1.471152  1.420258 -0.547323 -0.527317 -0.142590       1     0\n",
              "550 -1.471152 -0.943972 -0.547323  1.740783  1.253030       0     1\n",
              "422  0.899960 -0.084252 -0.547323 -0.527317 -0.496502       0     1\n",
              "377 -1.471152 -0.227539 -0.547323  1.740783  2.961942       0     1\n",
              "788  0.899960 -2.090265  0.508862  1.740783 -0.280800       0     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38eac862-7d6a-40ae-be67-e6aedc5fb28a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>female</th>\n",
              "      <th>male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>-1.471152</td>\n",
              "      <td>1.420258</td>\n",
              "      <td>-0.547323</td>\n",
              "      <td>-0.527317</td>\n",
              "      <td>-0.142590</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>550</th>\n",
              "      <td>-1.471152</td>\n",
              "      <td>-0.943972</td>\n",
              "      <td>-0.547323</td>\n",
              "      <td>1.740783</td>\n",
              "      <td>1.253030</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>0.899960</td>\n",
              "      <td>-0.084252</td>\n",
              "      <td>-0.547323</td>\n",
              "      <td>-0.527317</td>\n",
              "      <td>-0.496502</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>-1.471152</td>\n",
              "      <td>-0.227539</td>\n",
              "      <td>-0.547323</td>\n",
              "      <td>1.740783</td>\n",
              "      <td>2.961942</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788</th>\n",
              "      <td>0.899960</td>\n",
              "      <td>-2.090265</td>\n",
              "      <td>0.508862</td>\n",
              "      <td>1.740783</td>\n",
              "      <td>-0.280800</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38eac862-7d6a-40ae-be67-e6aedc5fb28a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-38eac862-7d6a-40ae-be67-e6aedc5fb28a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-38eac862-7d6a-40ae-be67-e6aedc5fb28a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_data_val[numeric_columns] = (features_data_val[numeric_columns]-train_mean)/(train_std)\n",
        "features_data_val.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "TlQr2itX3u39",
        "outputId": "299ea6c6-3576-4b3a-dbe7-215f32b1f7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Pclass       Age     SibSp     Parch      Fare  female  male\n",
              "617  0.899960 -0.299182  0.508862 -0.527317 -0.356806       1     0\n",
              "769  0.899960  0.130678 -0.547323 -0.527317 -0.488222       0     1\n",
              "237 -0.285596 -1.588762 -0.547323  1.740783 -0.184414       1     0\n",
              "253  0.899960 -0.012609  0.508862 -0.527317 -0.356806       0     1\n",
              "441  0.899960 -0.729042 -0.547323 -0.527317 -0.468902       0     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa3d6edb-fc11-465b-8498-2d49fe94a270\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>female</th>\n",
              "      <th>male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>617</th>\n",
              "      <td>0.899960</td>\n",
              "      <td>-0.299182</td>\n",
              "      <td>0.508862</td>\n",
              "      <td>-0.527317</td>\n",
              "      <td>-0.356806</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>769</th>\n",
              "      <td>0.899960</td>\n",
              "      <td>0.130678</td>\n",
              "      <td>-0.547323</td>\n",
              "      <td>-0.527317</td>\n",
              "      <td>-0.488222</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>-0.285596</td>\n",
              "      <td>-1.588762</td>\n",
              "      <td>-0.547323</td>\n",
              "      <td>1.740783</td>\n",
              "      <td>-0.184414</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>0.899960</td>\n",
              "      <td>-0.012609</td>\n",
              "      <td>0.508862</td>\n",
              "      <td>-0.527317</td>\n",
              "      <td>-0.356806</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>0.899960</td>\n",
              "      <td>-0.729042</td>\n",
              "      <td>-0.547323</td>\n",
              "      <td>-0.527317</td>\n",
              "      <td>-0.468902</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa3d6edb-fc11-465b-8498-2d49fe94a270')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa3d6edb-fc11-465b-8498-2d49fe94a270 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa3d6edb-fc11-465b-8498-2d49fe94a270');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos ir agora para para a definição da rede neural usando tensorflow:"
      ],
      "metadata": {
        "id": "Jydk7MsX35y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class MyMLP(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MyMLP, self).__init__()\n",
        "    #definição das camadas dentro do construtor da classe\n",
        "    self.dense1 = tf.keras.layers.Dense(#escolha o numero de neuronios da primeira camada escondida, activation=tf.nn.relu)\n",
        "    self.dense2 = tf.keras.layers.Dense(#escolha o numero de neuronios da segunda camada escondida, activation=tf.nn.relu)\n",
        "    self.dense3 = tf.keras.layers.Dense(#escolha o numero de neuronios camada de saida, activation=tf.nn.softmax)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    #comportamento das camadas para processar o vetor de entrada dentro da função call\n",
        "    x = self.dense1(inputs)\n",
        "    x = self.dense2(x)\n",
        "    x = self.dense3(x)\n",
        "    return x\n",
        "\n",
        "#inicialização da rede com pesos aleatórios\n",
        "model = MyMLP()\n",
        "\n",
        "#vetor fictício dado como entrada a rede\n",
        "x = tf.constant([[0.1 for x in range(7)]]) #dimensionalidade igual a 18\n",
        "#gerando a saida y pela rede a partir da entrada x\n",
        "y = model(x)\n",
        "print('Entrada: {}'.format(x.numpy()))\n",
        "print('Saída: {}'.format(y.numpy()))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAnS-W_j35DY",
        "outputId": "081e158b-970d-4fc6-b91a-54997957d86a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrada: [[0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
            "Saída: [[0.49933493 0.5006651 ]]\n",
            "Model: \"my_mlp_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_30 (Dense)            multiple                  40        \n",
            "                                                                 \n",
            " dense_31 (Dense)            multiple                  18        \n",
            "                                                                 \n",
            " dense_32 (Dense)            multiple                  8         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66\n",
            "Trainable params: 66\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos agora os parâmetros de treinamento, e começamos a treinar a rede:"
      ],
      "metadata": {
        "id": "djbNmjZl4TVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=#escolha um learning rate), \n",
        "              loss=#escolha uma função de perda/loss function,\n",
        "              metrics=['accuracy'])\n",
        "EPOCHS = 4000\n",
        "history = model.fit(features_data_train,labels_data_train, validation_data=(features_data_val,labels_data_val), epochs=EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY4e6ObJ4ji2",
        "outputId": "7795f4d8-8b78-40ed-fa66-2d25e8d65d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4896 - accuracy: 0.7955 - val_loss: 0.5194 - val_accuracy: 0.7584\n",
            "Epoch 1502/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4895 - accuracy: 0.7955 - val_loss: 0.5193 - val_accuracy: 0.7584\n",
            "Epoch 1503/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4894 - accuracy: 0.7955 - val_loss: 0.5192 - val_accuracy: 0.7584\n",
            "Epoch 1504/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4893 - accuracy: 0.7983 - val_loss: 0.5191 - val_accuracy: 0.7584\n",
            "Epoch 1505/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4892 - accuracy: 0.7983 - val_loss: 0.5191 - val_accuracy: 0.7584\n",
            "Epoch 1506/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4891 - accuracy: 0.7955 - val_loss: 0.5190 - val_accuracy: 0.7584\n",
            "Epoch 1507/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4890 - accuracy: 0.7955 - val_loss: 0.5189 - val_accuracy: 0.7584\n",
            "Epoch 1508/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4889 - accuracy: 0.7955 - val_loss: 0.5188 - val_accuracy: 0.7584\n",
            "Epoch 1509/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4888 - accuracy: 0.7955 - val_loss: 0.5188 - val_accuracy: 0.7584\n",
            "Epoch 1510/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4887 - accuracy: 0.7955 - val_loss: 0.5187 - val_accuracy: 0.7584\n",
            "Epoch 1511/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4886 - accuracy: 0.7955 - val_loss: 0.5186 - val_accuracy: 0.7584\n",
            "Epoch 1512/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4885 - accuracy: 0.7955 - val_loss: 0.5186 - val_accuracy: 0.7584\n",
            "Epoch 1513/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4884 - accuracy: 0.7955 - val_loss: 0.5185 - val_accuracy: 0.7584\n",
            "Epoch 1514/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4883 - accuracy: 0.7955 - val_loss: 0.5184 - val_accuracy: 0.7584\n",
            "Epoch 1515/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4882 - accuracy: 0.7955 - val_loss: 0.5184 - val_accuracy: 0.7584\n",
            "Epoch 1516/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4881 - accuracy: 0.7955 - val_loss: 0.5183 - val_accuracy: 0.7584\n",
            "Epoch 1517/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4880 - accuracy: 0.7955 - val_loss: 0.5182 - val_accuracy: 0.7584\n",
            "Epoch 1518/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4879 - accuracy: 0.7955 - val_loss: 0.5182 - val_accuracy: 0.7584\n",
            "Epoch 1519/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4878 - accuracy: 0.7955 - val_loss: 0.5181 - val_accuracy: 0.7584\n",
            "Epoch 1520/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.7983 - val_loss: 0.5180 - val_accuracy: 0.7584\n",
            "Epoch 1521/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4876 - accuracy: 0.7955 - val_loss: 0.5180 - val_accuracy: 0.7584\n",
            "Epoch 1522/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4874 - accuracy: 0.7983 - val_loss: 0.5179 - val_accuracy: 0.7584\n",
            "Epoch 1523/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4873 - accuracy: 0.7955 - val_loss: 0.5178 - val_accuracy: 0.7584\n",
            "Epoch 1524/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4872 - accuracy: 0.7955 - val_loss: 0.5178 - val_accuracy: 0.7584\n",
            "Epoch 1525/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4871 - accuracy: 0.7955 - val_loss: 0.5177 - val_accuracy: 0.7584\n",
            "Epoch 1526/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4870 - accuracy: 0.7927 - val_loss: 0.5177 - val_accuracy: 0.7584\n",
            "Epoch 1527/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4869 - accuracy: 0.7927 - val_loss: 0.5176 - val_accuracy: 0.7584\n",
            "Epoch 1528/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4868 - accuracy: 0.7927 - val_loss: 0.5176 - val_accuracy: 0.7584\n",
            "Epoch 1529/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.7983 - val_loss: 0.5175 - val_accuracy: 0.7584\n",
            "Epoch 1530/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4866 - accuracy: 0.7983 - val_loss: 0.5175 - val_accuracy: 0.7584\n",
            "Epoch 1531/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4865 - accuracy: 0.7983 - val_loss: 0.5174 - val_accuracy: 0.7584\n",
            "Epoch 1532/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4864 - accuracy: 0.7955 - val_loss: 0.5173 - val_accuracy: 0.7584\n",
            "Epoch 1533/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4863 - accuracy: 0.7927 - val_loss: 0.5173 - val_accuracy: 0.7584\n",
            "Epoch 1534/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4862 - accuracy: 0.7927 - val_loss: 0.5172 - val_accuracy: 0.7584\n",
            "Epoch 1535/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4861 - accuracy: 0.7927 - val_loss: 0.5171 - val_accuracy: 0.7584\n",
            "Epoch 1536/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4860 - accuracy: 0.7927 - val_loss: 0.5171 - val_accuracy: 0.7584\n",
            "Epoch 1537/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4858 - accuracy: 0.7927 - val_loss: 0.5170 - val_accuracy: 0.7584\n",
            "Epoch 1538/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4857 - accuracy: 0.7927 - val_loss: 0.5169 - val_accuracy: 0.7584\n",
            "Epoch 1539/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4856 - accuracy: 0.7955 - val_loss: 0.5169 - val_accuracy: 0.7584\n",
            "Epoch 1540/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.7955 - val_loss: 0.5168 - val_accuracy: 0.7584\n",
            "Epoch 1541/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4854 - accuracy: 0.7955 - val_loss: 0.5167 - val_accuracy: 0.7584\n",
            "Epoch 1542/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4853 - accuracy: 0.7955 - val_loss: 0.5166 - val_accuracy: 0.7584\n",
            "Epoch 1543/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4852 - accuracy: 0.7955 - val_loss: 0.5166 - val_accuracy: 0.7584\n",
            "Epoch 1544/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4851 - accuracy: 0.7927 - val_loss: 0.5165 - val_accuracy: 0.7584\n",
            "Epoch 1545/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4850 - accuracy: 0.7927 - val_loss: 0.5165 - val_accuracy: 0.7584\n",
            "Epoch 1546/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4849 - accuracy: 0.7927 - val_loss: 0.5164 - val_accuracy: 0.7584\n",
            "Epoch 1547/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4847 - accuracy: 0.7927 - val_loss: 0.5163 - val_accuracy: 0.7584\n",
            "Epoch 1548/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4846 - accuracy: 0.7927 - val_loss: 0.5163 - val_accuracy: 0.7584\n",
            "Epoch 1549/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4845 - accuracy: 0.7955 - val_loss: 0.5162 - val_accuracy: 0.7584\n",
            "Epoch 1550/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4844 - accuracy: 0.7955 - val_loss: 0.5162 - val_accuracy: 0.7584\n",
            "Epoch 1551/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4843 - accuracy: 0.7955 - val_loss: 0.5161 - val_accuracy: 0.7584\n",
            "Epoch 1552/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4842 - accuracy: 0.7955 - val_loss: 0.5160 - val_accuracy: 0.7584\n",
            "Epoch 1553/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4841 - accuracy: 0.7955 - val_loss: 0.5160 - val_accuracy: 0.7584\n",
            "Epoch 1554/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4840 - accuracy: 0.7927 - val_loss: 0.5159 - val_accuracy: 0.7584\n",
            "Epoch 1555/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4839 - accuracy: 0.7927 - val_loss: 0.5158 - val_accuracy: 0.7640\n",
            "Epoch 1556/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4838 - accuracy: 0.7927 - val_loss: 0.5158 - val_accuracy: 0.7640\n",
            "Epoch 1557/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4837 - accuracy: 0.7927 - val_loss: 0.5157 - val_accuracy: 0.7640\n",
            "Epoch 1558/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4836 - accuracy: 0.7955 - val_loss: 0.5157 - val_accuracy: 0.7640\n",
            "Epoch 1559/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4835 - accuracy: 0.7955 - val_loss: 0.5156 - val_accuracy: 0.7640\n",
            "Epoch 1560/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4834 - accuracy: 0.7955 - val_loss: 0.5155 - val_accuracy: 0.7640\n",
            "Epoch 1561/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4833 - accuracy: 0.7955 - val_loss: 0.5155 - val_accuracy: 0.7640\n",
            "Epoch 1562/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4832 - accuracy: 0.7955 - val_loss: 0.5155 - val_accuracy: 0.7640\n",
            "Epoch 1563/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4831 - accuracy: 0.7955 - val_loss: 0.5154 - val_accuracy: 0.7640\n",
            "Epoch 1564/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4830 - accuracy: 0.7955 - val_loss: 0.5153 - val_accuracy: 0.7640\n",
            "Epoch 1565/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4828 - accuracy: 0.7955 - val_loss: 0.5153 - val_accuracy: 0.7640\n",
            "Epoch 1566/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4827 - accuracy: 0.7955 - val_loss: 0.5152 - val_accuracy: 0.7640\n",
            "Epoch 1567/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4826 - accuracy: 0.7955 - val_loss: 0.5152 - val_accuracy: 0.7640\n",
            "Epoch 1568/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4825 - accuracy: 0.7955 - val_loss: 0.5151 - val_accuracy: 0.7640\n",
            "Epoch 1569/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4824 - accuracy: 0.7955 - val_loss: 0.5151 - val_accuracy: 0.7640\n",
            "Epoch 1570/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4823 - accuracy: 0.7955 - val_loss: 0.5150 - val_accuracy: 0.7640\n",
            "Epoch 1571/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4822 - accuracy: 0.7955 - val_loss: 0.5150 - val_accuracy: 0.7640\n",
            "Epoch 1572/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4821 - accuracy: 0.7955 - val_loss: 0.5149 - val_accuracy: 0.7640\n",
            "Epoch 1573/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4819 - accuracy: 0.7955 - val_loss: 0.5148 - val_accuracy: 0.7640\n",
            "Epoch 1574/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4818 - accuracy: 0.7955 - val_loss: 0.5147 - val_accuracy: 0.7640\n",
            "Epoch 1575/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4817 - accuracy: 0.7955 - val_loss: 0.5147 - val_accuracy: 0.7640\n",
            "Epoch 1576/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4816 - accuracy: 0.7955 - val_loss: 0.5146 - val_accuracy: 0.7640\n",
            "Epoch 1577/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4815 - accuracy: 0.7955 - val_loss: 0.5145 - val_accuracy: 0.7640\n",
            "Epoch 1578/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4814 - accuracy: 0.7955 - val_loss: 0.5145 - val_accuracy: 0.7640\n",
            "Epoch 1579/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4813 - accuracy: 0.7955 - val_loss: 0.5144 - val_accuracy: 0.7640\n",
            "Epoch 1580/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4812 - accuracy: 0.7955 - val_loss: 0.5144 - val_accuracy: 0.7640\n",
            "Epoch 1581/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4811 - accuracy: 0.7955 - val_loss: 0.5143 - val_accuracy: 0.7640\n",
            "Epoch 1582/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4810 - accuracy: 0.7955 - val_loss: 0.5143 - val_accuracy: 0.7640\n",
            "Epoch 1583/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4808 - accuracy: 0.7955 - val_loss: 0.5142 - val_accuracy: 0.7640\n",
            "Epoch 1584/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4807 - accuracy: 0.7955 - val_loss: 0.5141 - val_accuracy: 0.7640\n",
            "Epoch 1585/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4806 - accuracy: 0.7955 - val_loss: 0.5141 - val_accuracy: 0.7640\n",
            "Epoch 1586/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4805 - accuracy: 0.7955 - val_loss: 0.5141 - val_accuracy: 0.7640\n",
            "Epoch 1587/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4804 - accuracy: 0.7955 - val_loss: 0.5140 - val_accuracy: 0.7640\n",
            "Epoch 1588/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4803 - accuracy: 0.7955 - val_loss: 0.5140 - val_accuracy: 0.7640\n",
            "Epoch 1589/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4802 - accuracy: 0.7955 - val_loss: 0.5139 - val_accuracy: 0.7640\n",
            "Epoch 1590/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4801 - accuracy: 0.7955 - val_loss: 0.5138 - val_accuracy: 0.7640\n",
            "Epoch 1591/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4800 - accuracy: 0.7955 - val_loss: 0.5138 - val_accuracy: 0.7640\n",
            "Epoch 1592/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4799 - accuracy: 0.7955 - val_loss: 0.5137 - val_accuracy: 0.7640\n",
            "Epoch 1593/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4798 - accuracy: 0.7955 - val_loss: 0.5137 - val_accuracy: 0.7640\n",
            "Epoch 1594/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.7955 - val_loss: 0.5136 - val_accuracy: 0.7640\n",
            "Epoch 1595/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4795 - accuracy: 0.7955 - val_loss: 0.5136 - val_accuracy: 0.7640\n",
            "Epoch 1596/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4794 - accuracy: 0.7955 - val_loss: 0.5135 - val_accuracy: 0.7640\n",
            "Epoch 1597/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4793 - accuracy: 0.7955 - val_loss: 0.5134 - val_accuracy: 0.7640\n",
            "Epoch 1598/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4792 - accuracy: 0.7955 - val_loss: 0.5134 - val_accuracy: 0.7640\n",
            "Epoch 1599/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4791 - accuracy: 0.7955 - val_loss: 0.5133 - val_accuracy: 0.7640\n",
            "Epoch 1600/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4790 - accuracy: 0.7955 - val_loss: 0.5132 - val_accuracy: 0.7640\n",
            "Epoch 1601/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4789 - accuracy: 0.7955 - val_loss: 0.5132 - val_accuracy: 0.7640\n",
            "Epoch 1602/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4788 - accuracy: 0.7955 - val_loss: 0.5131 - val_accuracy: 0.7640\n",
            "Epoch 1603/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4787 - accuracy: 0.7955 - val_loss: 0.5130 - val_accuracy: 0.7640\n",
            "Epoch 1604/4000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.4786 - accuracy: 0.7955 - val_loss: 0.5130 - val_accuracy: 0.7640\n",
            "Epoch 1605/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4785 - accuracy: 0.7955 - val_loss: 0.5129 - val_accuracy: 0.7640\n",
            "Epoch 1606/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4784 - accuracy: 0.7955 - val_loss: 0.5129 - val_accuracy: 0.7640\n",
            "Epoch 1607/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4783 - accuracy: 0.7955 - val_loss: 0.5128 - val_accuracy: 0.7640\n",
            "Epoch 1608/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4782 - accuracy: 0.7955 - val_loss: 0.5128 - val_accuracy: 0.7640\n",
            "Epoch 1609/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4781 - accuracy: 0.7955 - val_loss: 0.5127 - val_accuracy: 0.7640\n",
            "Epoch 1610/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.7955 - val_loss: 0.5126 - val_accuracy: 0.7640\n",
            "Epoch 1611/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4778 - accuracy: 0.7955 - val_loss: 0.5126 - val_accuracy: 0.7640\n",
            "Epoch 1612/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.7955 - val_loss: 0.5125 - val_accuracy: 0.7640\n",
            "Epoch 1613/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4776 - accuracy: 0.7955 - val_loss: 0.5125 - val_accuracy: 0.7640\n",
            "Epoch 1614/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4775 - accuracy: 0.7983 - val_loss: 0.5124 - val_accuracy: 0.7640\n",
            "Epoch 1615/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4774 - accuracy: 0.7983 - val_loss: 0.5123 - val_accuracy: 0.7640\n",
            "Epoch 1616/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4773 - accuracy: 0.7983 - val_loss: 0.5123 - val_accuracy: 0.7640\n",
            "Epoch 1617/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4772 - accuracy: 0.7983 - val_loss: 0.5122 - val_accuracy: 0.7640\n",
            "Epoch 1618/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4771 - accuracy: 0.7983 - val_loss: 0.5122 - val_accuracy: 0.7640\n",
            "Epoch 1619/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4770 - accuracy: 0.7983 - val_loss: 0.5122 - val_accuracy: 0.7640\n",
            "Epoch 1620/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4768 - accuracy: 0.7983 - val_loss: 0.5121 - val_accuracy: 0.7640\n",
            "Epoch 1621/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4767 - accuracy: 0.7983 - val_loss: 0.5121 - val_accuracy: 0.7640\n",
            "Epoch 1622/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4766 - accuracy: 0.7983 - val_loss: 0.5120 - val_accuracy: 0.7640\n",
            "Epoch 1623/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4765 - accuracy: 0.7983 - val_loss: 0.5119 - val_accuracy: 0.7640\n",
            "Epoch 1624/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4764 - accuracy: 0.7983 - val_loss: 0.5119 - val_accuracy: 0.7640\n",
            "Epoch 1625/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4763 - accuracy: 0.7983 - val_loss: 0.5118 - val_accuracy: 0.7640\n",
            "Epoch 1626/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4762 - accuracy: 0.7983 - val_loss: 0.5118 - val_accuracy: 0.7640\n",
            "Epoch 1627/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4761 - accuracy: 0.7983 - val_loss: 0.5117 - val_accuracy: 0.7640\n",
            "Epoch 1628/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4760 - accuracy: 0.7983 - val_loss: 0.5117 - val_accuracy: 0.7640\n",
            "Epoch 1629/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4758 - accuracy: 0.7983 - val_loss: 0.5116 - val_accuracy: 0.7640\n",
            "Epoch 1630/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4757 - accuracy: 0.7983 - val_loss: 0.5115 - val_accuracy: 0.7640\n",
            "Epoch 1631/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4756 - accuracy: 0.7983 - val_loss: 0.5115 - val_accuracy: 0.7640\n",
            "Epoch 1632/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4756 - accuracy: 0.7983 - val_loss: 0.5114 - val_accuracy: 0.7640\n",
            "Epoch 1633/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.7983 - val_loss: 0.5114 - val_accuracy: 0.7640\n",
            "Epoch 1634/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4753 - accuracy: 0.7983 - val_loss: 0.5114 - val_accuracy: 0.7640\n",
            "Epoch 1635/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4752 - accuracy: 0.7983 - val_loss: 0.5113 - val_accuracy: 0.7640\n",
            "Epoch 1636/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4751 - accuracy: 0.7983 - val_loss: 0.5113 - val_accuracy: 0.7640\n",
            "Epoch 1637/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.7983 - val_loss: 0.5112 - val_accuracy: 0.7640\n",
            "Epoch 1638/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4749 - accuracy: 0.7983 - val_loss: 0.5112 - val_accuracy: 0.7640\n",
            "Epoch 1639/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4748 - accuracy: 0.7983 - val_loss: 0.5111 - val_accuracy: 0.7640\n",
            "Epoch 1640/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4747 - accuracy: 0.7983 - val_loss: 0.5110 - val_accuracy: 0.7640\n",
            "Epoch 1641/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4746 - accuracy: 0.7983 - val_loss: 0.5110 - val_accuracy: 0.7640\n",
            "Epoch 1642/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4745 - accuracy: 0.7983 - val_loss: 0.5109 - val_accuracy: 0.7640\n",
            "Epoch 1643/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4744 - accuracy: 0.7983 - val_loss: 0.5109 - val_accuracy: 0.7640\n",
            "Epoch 1644/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4743 - accuracy: 0.7983 - val_loss: 0.5108 - val_accuracy: 0.7640\n",
            "Epoch 1645/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.7983 - val_loss: 0.5108 - val_accuracy: 0.7640\n",
            "Epoch 1646/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4740 - accuracy: 0.7983 - val_loss: 0.5107 - val_accuracy: 0.7640\n",
            "Epoch 1647/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4739 - accuracy: 0.7983 - val_loss: 0.5107 - val_accuracy: 0.7640\n",
            "Epoch 1648/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4738 - accuracy: 0.7983 - val_loss: 0.5106 - val_accuracy: 0.7640\n",
            "Epoch 1649/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4737 - accuracy: 0.7983 - val_loss: 0.5105 - val_accuracy: 0.7640\n",
            "Epoch 1650/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4736 - accuracy: 0.7983 - val_loss: 0.5105 - val_accuracy: 0.7640\n",
            "Epoch 1651/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4735 - accuracy: 0.7983 - val_loss: 0.5104 - val_accuracy: 0.7640\n",
            "Epoch 1652/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4734 - accuracy: 0.7983 - val_loss: 0.5104 - val_accuracy: 0.7640\n",
            "Epoch 1653/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4733 - accuracy: 0.7983 - val_loss: 0.5103 - val_accuracy: 0.7640\n",
            "Epoch 1654/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4732 - accuracy: 0.7983 - val_loss: 0.5103 - val_accuracy: 0.7640\n",
            "Epoch 1655/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4731 - accuracy: 0.7983 - val_loss: 0.5102 - val_accuracy: 0.7640\n",
            "Epoch 1656/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4730 - accuracy: 0.7983 - val_loss: 0.5102 - val_accuracy: 0.7640\n",
            "Epoch 1657/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4729 - accuracy: 0.7983 - val_loss: 0.5101 - val_accuracy: 0.7640\n",
            "Epoch 1658/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4728 - accuracy: 0.7983 - val_loss: 0.5101 - val_accuracy: 0.7640\n",
            "Epoch 1659/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4727 - accuracy: 0.7983 - val_loss: 0.5100 - val_accuracy: 0.7640\n",
            "Epoch 1660/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.7983 - val_loss: 0.5100 - val_accuracy: 0.7640\n",
            "Epoch 1661/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.7983 - val_loss: 0.5099 - val_accuracy: 0.7640\n",
            "Epoch 1662/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4724 - accuracy: 0.7983 - val_loss: 0.5099 - val_accuracy: 0.7640\n",
            "Epoch 1663/4000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4722 - accuracy: 0.7983 - val_loss: 0.5098 - val_accuracy: 0.7640\n",
            "Epoch 1664/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4721 - accuracy: 0.7983 - val_loss: 0.5098 - val_accuracy: 0.7640\n",
            "Epoch 1665/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.7983 - val_loss: 0.5097 - val_accuracy: 0.7640\n",
            "Epoch 1666/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4719 - accuracy: 0.7983 - val_loss: 0.5097 - val_accuracy: 0.7640\n",
            "Epoch 1667/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4718 - accuracy: 0.7983 - val_loss: 0.5096 - val_accuracy: 0.7640\n",
            "Epoch 1668/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7983 - val_loss: 0.5096 - val_accuracy: 0.7640\n",
            "Epoch 1669/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7983 - val_loss: 0.5095 - val_accuracy: 0.7640\n",
            "Epoch 1670/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4715 - accuracy: 0.7983 - val_loss: 0.5095 - val_accuracy: 0.7640\n",
            "Epoch 1671/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.7983 - val_loss: 0.5094 - val_accuracy: 0.7640\n",
            "Epoch 1672/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4713 - accuracy: 0.7983 - val_loss: 0.5094 - val_accuracy: 0.7640\n",
            "Epoch 1673/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.7983 - val_loss: 0.5093 - val_accuracy: 0.7640\n",
            "Epoch 1674/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4711 - accuracy: 0.7983 - val_loss: 0.5093 - val_accuracy: 0.7640\n",
            "Epoch 1675/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.7983 - val_loss: 0.5092 - val_accuracy: 0.7640\n",
            "Epoch 1676/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7983 - val_loss: 0.5092 - val_accuracy: 0.7640\n",
            "Epoch 1677/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4707 - accuracy: 0.7983 - val_loss: 0.5091 - val_accuracy: 0.7640\n",
            "Epoch 1678/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4706 - accuracy: 0.8011 - val_loss: 0.5091 - val_accuracy: 0.7640\n",
            "Epoch 1679/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4705 - accuracy: 0.8011 - val_loss: 0.5090 - val_accuracy: 0.7640\n",
            "Epoch 1680/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4704 - accuracy: 0.8011 - val_loss: 0.5090 - val_accuracy: 0.7640\n",
            "Epoch 1681/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4703 - accuracy: 0.8011 - val_loss: 0.5089 - val_accuracy: 0.7640\n",
            "Epoch 1682/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.8011 - val_loss: 0.5089 - val_accuracy: 0.7640\n",
            "Epoch 1683/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4701 - accuracy: 0.8011 - val_loss: 0.5088 - val_accuracy: 0.7640\n",
            "Epoch 1684/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.8011 - val_loss: 0.5088 - val_accuracy: 0.7640\n",
            "Epoch 1685/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.8011 - val_loss: 0.5088 - val_accuracy: 0.7640\n",
            "Epoch 1686/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.8011 - val_loss: 0.5087 - val_accuracy: 0.7640\n",
            "Epoch 1687/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4697 - accuracy: 0.8011 - val_loss: 0.5087 - val_accuracy: 0.7640\n",
            "Epoch 1688/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4696 - accuracy: 0.8011 - val_loss: 0.5086 - val_accuracy: 0.7640\n",
            "Epoch 1689/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.8011 - val_loss: 0.5086 - val_accuracy: 0.7640\n",
            "Epoch 1690/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4693 - accuracy: 0.8011 - val_loss: 0.5086 - val_accuracy: 0.7640\n",
            "Epoch 1691/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.8011 - val_loss: 0.5085 - val_accuracy: 0.7640\n",
            "Epoch 1692/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4691 - accuracy: 0.8011 - val_loss: 0.5085 - val_accuracy: 0.7640\n",
            "Epoch 1693/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.8011 - val_loss: 0.5085 - val_accuracy: 0.7640\n",
            "Epoch 1694/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.8011 - val_loss: 0.5084 - val_accuracy: 0.7640\n",
            "Epoch 1695/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.8011 - val_loss: 0.5084 - val_accuracy: 0.7640\n",
            "Epoch 1696/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4687 - accuracy: 0.8011 - val_loss: 0.5083 - val_accuracy: 0.7640\n",
            "Epoch 1697/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.8011 - val_loss: 0.5083 - val_accuracy: 0.7640\n",
            "Epoch 1698/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.8011 - val_loss: 0.5082 - val_accuracy: 0.7640\n",
            "Epoch 1699/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4684 - accuracy: 0.8011 - val_loss: 0.5082 - val_accuracy: 0.7640\n",
            "Epoch 1700/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4683 - accuracy: 0.8011 - val_loss: 0.5081 - val_accuracy: 0.7640\n",
            "Epoch 1701/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4682 - accuracy: 0.8011 - val_loss: 0.5081 - val_accuracy: 0.7640\n",
            "Epoch 1702/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4681 - accuracy: 0.8011 - val_loss: 0.5081 - val_accuracy: 0.7640\n",
            "Epoch 1703/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.8011 - val_loss: 0.5080 - val_accuracy: 0.7640\n",
            "Epoch 1704/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.8011 - val_loss: 0.5079 - val_accuracy: 0.7640\n",
            "Epoch 1705/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.8011 - val_loss: 0.5079 - val_accuracy: 0.7640\n",
            "Epoch 1706/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.8011 - val_loss: 0.5078 - val_accuracy: 0.7640\n",
            "Epoch 1707/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.8011 - val_loss: 0.5078 - val_accuracy: 0.7640\n",
            "Epoch 1708/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.8011 - val_loss: 0.5078 - val_accuracy: 0.7640\n",
            "Epoch 1709/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.8011 - val_loss: 0.5077 - val_accuracy: 0.7640\n",
            "Epoch 1710/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.8011 - val_loss: 0.5077 - val_accuracy: 0.7640\n",
            "Epoch 1711/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4672 - accuracy: 0.8011 - val_loss: 0.5076 - val_accuracy: 0.7640\n",
            "Epoch 1712/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.8011 - val_loss: 0.5076 - val_accuracy: 0.7640\n",
            "Epoch 1713/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.8011 - val_loss: 0.5076 - val_accuracy: 0.7640\n",
            "Epoch 1714/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4669 - accuracy: 0.8011 - val_loss: 0.5075 - val_accuracy: 0.7640\n",
            "Epoch 1715/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4668 - accuracy: 0.8011 - val_loss: 0.5075 - val_accuracy: 0.7640\n",
            "Epoch 1716/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4667 - accuracy: 0.8011 - val_loss: 0.5074 - val_accuracy: 0.7640\n",
            "Epoch 1717/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.8011 - val_loss: 0.5074 - val_accuracy: 0.7640\n",
            "Epoch 1718/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4665 - accuracy: 0.8011 - val_loss: 0.5074 - val_accuracy: 0.7640\n",
            "Epoch 1719/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.8011 - val_loss: 0.5073 - val_accuracy: 0.7640\n",
            "Epoch 1720/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4663 - accuracy: 0.8011 - val_loss: 0.5072 - val_accuracy: 0.7640\n",
            "Epoch 1721/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.8011 - val_loss: 0.5072 - val_accuracy: 0.7640\n",
            "Epoch 1722/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4661 - accuracy: 0.8011 - val_loss: 0.5071 - val_accuracy: 0.7640\n",
            "Epoch 1723/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4660 - accuracy: 0.8011 - val_loss: 0.5071 - val_accuracy: 0.7640\n",
            "Epoch 1724/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4659 - accuracy: 0.8011 - val_loss: 0.5070 - val_accuracy: 0.7640\n",
            "Epoch 1725/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.8011 - val_loss: 0.5070 - val_accuracy: 0.7640\n",
            "Epoch 1726/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4657 - accuracy: 0.8011 - val_loss: 0.5070 - val_accuracy: 0.7640\n",
            "Epoch 1727/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.8011 - val_loss: 0.5069 - val_accuracy: 0.7640\n",
            "Epoch 1728/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4655 - accuracy: 0.8011 - val_loss: 0.5069 - val_accuracy: 0.7640\n",
            "Epoch 1729/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.8011 - val_loss: 0.5068 - val_accuracy: 0.7640\n",
            "Epoch 1730/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.8011 - val_loss: 0.5068 - val_accuracy: 0.7640\n",
            "Epoch 1731/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.8011 - val_loss: 0.5068 - val_accuracy: 0.7640\n",
            "Epoch 1732/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4651 - accuracy: 0.8011 - val_loss: 0.5067 - val_accuracy: 0.7640\n",
            "Epoch 1733/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4650 - accuracy: 0.8011 - val_loss: 0.5067 - val_accuracy: 0.7640\n",
            "Epoch 1734/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4650 - accuracy: 0.8011 - val_loss: 0.5066 - val_accuracy: 0.7640\n",
            "Epoch 1735/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4649 - accuracy: 0.8011 - val_loss: 0.5066 - val_accuracy: 0.7640\n",
            "Epoch 1736/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4648 - accuracy: 0.8011 - val_loss: 0.5066 - val_accuracy: 0.7640\n",
            "Epoch 1737/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4647 - accuracy: 0.8011 - val_loss: 0.5065 - val_accuracy: 0.7640\n",
            "Epoch 1738/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4646 - accuracy: 0.8011 - val_loss: 0.5065 - val_accuracy: 0.7640\n",
            "Epoch 1739/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4645 - accuracy: 0.8011 - val_loss: 0.5065 - val_accuracy: 0.7640\n",
            "Epoch 1740/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4644 - accuracy: 0.8011 - val_loss: 0.5064 - val_accuracy: 0.7640\n",
            "Epoch 1741/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.8011 - val_loss: 0.5064 - val_accuracy: 0.7640\n",
            "Epoch 1742/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4642 - accuracy: 0.8011 - val_loss: 0.5063 - val_accuracy: 0.7640\n",
            "Epoch 1743/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4641 - accuracy: 0.8011 - val_loss: 0.5063 - val_accuracy: 0.7640\n",
            "Epoch 1744/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4640 - accuracy: 0.8011 - val_loss: 0.5063 - val_accuracy: 0.7640\n",
            "Epoch 1745/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4639 - accuracy: 0.8011 - val_loss: 0.5062 - val_accuracy: 0.7640\n",
            "Epoch 1746/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4638 - accuracy: 0.8011 - val_loss: 0.5062 - val_accuracy: 0.7640\n",
            "Epoch 1747/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4637 - accuracy: 0.8011 - val_loss: 0.5062 - val_accuracy: 0.7640\n",
            "Epoch 1748/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4636 - accuracy: 0.8011 - val_loss: 0.5061 - val_accuracy: 0.7640\n",
            "Epoch 1749/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4636 - accuracy: 0.8011 - val_loss: 0.5061 - val_accuracy: 0.7640\n",
            "Epoch 1750/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4635 - accuracy: 0.8011 - val_loss: 0.5061 - val_accuracy: 0.7640\n",
            "Epoch 1751/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4634 - accuracy: 0.8011 - val_loss: 0.5060 - val_accuracy: 0.7640\n",
            "Epoch 1752/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4633 - accuracy: 0.8011 - val_loss: 0.5060 - val_accuracy: 0.7640\n",
            "Epoch 1753/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4632 - accuracy: 0.8011 - val_loss: 0.5060 - val_accuracy: 0.7640\n",
            "Epoch 1754/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4631 - accuracy: 0.8011 - val_loss: 0.5059 - val_accuracy: 0.7640\n",
            "Epoch 1755/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4630 - accuracy: 0.8011 - val_loss: 0.5059 - val_accuracy: 0.7640\n",
            "Epoch 1756/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4629 - accuracy: 0.8039 - val_loss: 0.5058 - val_accuracy: 0.7640\n",
            "Epoch 1757/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.8039 - val_loss: 0.5058 - val_accuracy: 0.7640\n",
            "Epoch 1758/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4627 - accuracy: 0.8039 - val_loss: 0.5058 - val_accuracy: 0.7640\n",
            "Epoch 1759/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4626 - accuracy: 0.8039 - val_loss: 0.5057 - val_accuracy: 0.7697\n",
            "Epoch 1760/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4626 - accuracy: 0.8039 - val_loss: 0.5057 - val_accuracy: 0.7697\n",
            "Epoch 1761/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4625 - accuracy: 0.8039 - val_loss: 0.5057 - val_accuracy: 0.7697\n",
            "Epoch 1762/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4624 - accuracy: 0.8039 - val_loss: 0.5056 - val_accuracy: 0.7697\n",
            "Epoch 1763/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4623 - accuracy: 0.8039 - val_loss: 0.5056 - val_accuracy: 0.7697\n",
            "Epoch 1764/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4622 - accuracy: 0.8039 - val_loss: 0.5055 - val_accuracy: 0.7697\n",
            "Epoch 1765/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4621 - accuracy: 0.8039 - val_loss: 0.5055 - val_accuracy: 0.7697\n",
            "Epoch 1766/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4620 - accuracy: 0.8039 - val_loss: 0.5054 - val_accuracy: 0.7697\n",
            "Epoch 1767/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.8039 - val_loss: 0.5054 - val_accuracy: 0.7697\n",
            "Epoch 1768/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4618 - accuracy: 0.8039 - val_loss: 0.5054 - val_accuracy: 0.7697\n",
            "Epoch 1769/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4617 - accuracy: 0.8039 - val_loss: 0.5053 - val_accuracy: 0.7697\n",
            "Epoch 1770/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4616 - accuracy: 0.8039 - val_loss: 0.5053 - val_accuracy: 0.7697\n",
            "Epoch 1771/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4615 - accuracy: 0.8039 - val_loss: 0.5053 - val_accuracy: 0.7697\n",
            "Epoch 1772/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4614 - accuracy: 0.8039 - val_loss: 0.5052 - val_accuracy: 0.7697\n",
            "Epoch 1773/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4613 - accuracy: 0.8039 - val_loss: 0.5052 - val_accuracy: 0.7697\n",
            "Epoch 1774/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4613 - accuracy: 0.8039 - val_loss: 0.5051 - val_accuracy: 0.7697\n",
            "Epoch 1775/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4612 - accuracy: 0.8039 - val_loss: 0.5051 - val_accuracy: 0.7697\n",
            "Epoch 1776/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4611 - accuracy: 0.8039 - val_loss: 0.5051 - val_accuracy: 0.7697\n",
            "Epoch 1777/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4610 - accuracy: 0.8039 - val_loss: 0.5050 - val_accuracy: 0.7697\n",
            "Epoch 1778/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4609 - accuracy: 0.8039 - val_loss: 0.5050 - val_accuracy: 0.7697\n",
            "Epoch 1779/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4608 - accuracy: 0.8039 - val_loss: 0.5050 - val_accuracy: 0.7697\n",
            "Epoch 1780/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4607 - accuracy: 0.8039 - val_loss: 0.5049 - val_accuracy: 0.7697\n",
            "Epoch 1781/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4606 - accuracy: 0.8067 - val_loss: 0.5049 - val_accuracy: 0.7697\n",
            "Epoch 1782/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4605 - accuracy: 0.8067 - val_loss: 0.5049 - val_accuracy: 0.7697\n",
            "Epoch 1783/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4605 - accuracy: 0.8067 - val_loss: 0.5048 - val_accuracy: 0.7697\n",
            "Epoch 1784/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4604 - accuracy: 0.8067 - val_loss: 0.5048 - val_accuracy: 0.7697\n",
            "Epoch 1785/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.8067 - val_loss: 0.5047 - val_accuracy: 0.7697\n",
            "Epoch 1786/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4602 - accuracy: 0.8067 - val_loss: 0.5047 - val_accuracy: 0.7697\n",
            "Epoch 1787/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4601 - accuracy: 0.8067 - val_loss: 0.5047 - val_accuracy: 0.7697\n",
            "Epoch 1788/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4600 - accuracy: 0.8067 - val_loss: 0.5046 - val_accuracy: 0.7697\n",
            "Epoch 1789/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4599 - accuracy: 0.8067 - val_loss: 0.5046 - val_accuracy: 0.7697\n",
            "Epoch 1790/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4598 - accuracy: 0.8067 - val_loss: 0.5046 - val_accuracy: 0.7697\n",
            "Epoch 1791/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4597 - accuracy: 0.8067 - val_loss: 0.5045 - val_accuracy: 0.7697\n",
            "Epoch 1792/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4596 - accuracy: 0.8067 - val_loss: 0.5045 - val_accuracy: 0.7697\n",
            "Epoch 1793/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4595 - accuracy: 0.8067 - val_loss: 0.5045 - val_accuracy: 0.7697\n",
            "Epoch 1794/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4594 - accuracy: 0.8067 - val_loss: 0.5044 - val_accuracy: 0.7697\n",
            "Epoch 1795/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4593 - accuracy: 0.8067 - val_loss: 0.5044 - val_accuracy: 0.7697\n",
            "Epoch 1796/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4592 - accuracy: 0.8067 - val_loss: 0.5043 - val_accuracy: 0.7697\n",
            "Epoch 1797/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4592 - accuracy: 0.8067 - val_loss: 0.5043 - val_accuracy: 0.7697\n",
            "Epoch 1798/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.8067 - val_loss: 0.5043 - val_accuracy: 0.7697\n",
            "Epoch 1799/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4590 - accuracy: 0.8067 - val_loss: 0.5043 - val_accuracy: 0.7697\n",
            "Epoch 1800/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.8067 - val_loss: 0.5042 - val_accuracy: 0.7697\n",
            "Epoch 1801/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4588 - accuracy: 0.8067 - val_loss: 0.5042 - val_accuracy: 0.7697\n",
            "Epoch 1802/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4587 - accuracy: 0.8095 - val_loss: 0.5042 - val_accuracy: 0.7697\n",
            "Epoch 1803/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4586 - accuracy: 0.8095 - val_loss: 0.5041 - val_accuracy: 0.7697\n",
            "Epoch 1804/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4586 - accuracy: 0.8095 - val_loss: 0.5041 - val_accuracy: 0.7697\n",
            "Epoch 1805/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4585 - accuracy: 0.8095 - val_loss: 0.5041 - val_accuracy: 0.7697\n",
            "Epoch 1806/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4584 - accuracy: 0.8095 - val_loss: 0.5041 - val_accuracy: 0.7697\n",
            "Epoch 1807/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4583 - accuracy: 0.8095 - val_loss: 0.5041 - val_accuracy: 0.7697\n",
            "Epoch 1808/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.8095 - val_loss: 0.5041 - val_accuracy: 0.7697\n",
            "Epoch 1809/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.8095 - val_loss: 0.5040 - val_accuracy: 0.7697\n",
            "Epoch 1810/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4580 - accuracy: 0.8095 - val_loss: 0.5040 - val_accuracy: 0.7697\n",
            "Epoch 1811/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4579 - accuracy: 0.8095 - val_loss: 0.5040 - val_accuracy: 0.7697\n",
            "Epoch 1812/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4578 - accuracy: 0.8095 - val_loss: 0.5039 - val_accuracy: 0.7697\n",
            "Epoch 1813/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4577 - accuracy: 0.8095 - val_loss: 0.5039 - val_accuracy: 0.7697\n",
            "Epoch 1814/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4577 - accuracy: 0.8095 - val_loss: 0.5038 - val_accuracy: 0.7697\n",
            "Epoch 1815/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4576 - accuracy: 0.8095 - val_loss: 0.5038 - val_accuracy: 0.7697\n",
            "Epoch 1816/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4575 - accuracy: 0.8095 - val_loss: 0.5037 - val_accuracy: 0.7697\n",
            "Epoch 1817/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4574 - accuracy: 0.8095 - val_loss: 0.5037 - val_accuracy: 0.7697\n",
            "Epoch 1818/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4573 - accuracy: 0.8095 - val_loss: 0.5037 - val_accuracy: 0.7697\n",
            "Epoch 1819/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.8095 - val_loss: 0.5036 - val_accuracy: 0.7697\n",
            "Epoch 1820/4000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4571 - accuracy: 0.8095 - val_loss: 0.5036 - val_accuracy: 0.7697\n",
            "Epoch 1821/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4570 - accuracy: 0.8095 - val_loss: 0.5036 - val_accuracy: 0.7697\n",
            "Epoch 1822/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4570 - accuracy: 0.8095 - val_loss: 0.5035 - val_accuracy: 0.7697\n",
            "Epoch 1823/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.8095 - val_loss: 0.5035 - val_accuracy: 0.7697\n",
            "Epoch 1824/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4568 - accuracy: 0.8095 - val_loss: 0.5035 - val_accuracy: 0.7697\n",
            "Epoch 1825/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4567 - accuracy: 0.8095 - val_loss: 0.5034 - val_accuracy: 0.7697\n",
            "Epoch 1826/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4566 - accuracy: 0.8095 - val_loss: 0.5034 - val_accuracy: 0.7697\n",
            "Epoch 1827/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4565 - accuracy: 0.8095 - val_loss: 0.5034 - val_accuracy: 0.7697\n",
            "Epoch 1828/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4564 - accuracy: 0.8095 - val_loss: 0.5034 - val_accuracy: 0.7697\n",
            "Epoch 1829/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4563 - accuracy: 0.8095 - val_loss: 0.5033 - val_accuracy: 0.7697\n",
            "Epoch 1830/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4562 - accuracy: 0.8095 - val_loss: 0.5033 - val_accuracy: 0.7640\n",
            "Epoch 1831/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4561 - accuracy: 0.8095 - val_loss: 0.5033 - val_accuracy: 0.7640\n",
            "Epoch 1832/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4560 - accuracy: 0.8095 - val_loss: 0.5032 - val_accuracy: 0.7640\n",
            "Epoch 1833/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4560 - accuracy: 0.8095 - val_loss: 0.5032 - val_accuracy: 0.7640\n",
            "Epoch 1834/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4559 - accuracy: 0.8095 - val_loss: 0.5032 - val_accuracy: 0.7640\n",
            "Epoch 1835/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4558 - accuracy: 0.8095 - val_loss: 0.5032 - val_accuracy: 0.7640\n",
            "Epoch 1836/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4557 - accuracy: 0.8095 - val_loss: 0.5031 - val_accuracy: 0.7640\n",
            "Epoch 1837/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.8095 - val_loss: 0.5031 - val_accuracy: 0.7640\n",
            "Epoch 1838/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4555 - accuracy: 0.8095 - val_loss: 0.5031 - val_accuracy: 0.7640\n",
            "Epoch 1839/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4554 - accuracy: 0.8095 - val_loss: 0.5031 - val_accuracy: 0.7640\n",
            "Epoch 1840/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4553 - accuracy: 0.8095 - val_loss: 0.5031 - val_accuracy: 0.7640\n",
            "Epoch 1841/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4552 - accuracy: 0.8095 - val_loss: 0.5030 - val_accuracy: 0.7640\n",
            "Epoch 1842/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4552 - accuracy: 0.8095 - val_loss: 0.5030 - val_accuracy: 0.7640\n",
            "Epoch 1843/4000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4551 - accuracy: 0.8095 - val_loss: 0.5030 - val_accuracy: 0.7640\n",
            "Epoch 1844/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4550 - accuracy: 0.8095 - val_loss: 0.5030 - val_accuracy: 0.7640\n",
            "Epoch 1845/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4549 - accuracy: 0.8095 - val_loss: 0.5029 - val_accuracy: 0.7640\n",
            "Epoch 1846/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4548 - accuracy: 0.8095 - val_loss: 0.5029 - val_accuracy: 0.7640\n",
            "Epoch 1847/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4547 - accuracy: 0.8095 - val_loss: 0.5029 - val_accuracy: 0.7640\n",
            "Epoch 1848/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.8095 - val_loss: 0.5029 - val_accuracy: 0.7640\n",
            "Epoch 1849/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4545 - accuracy: 0.8095 - val_loss: 0.5028 - val_accuracy: 0.7640\n",
            "Epoch 1850/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4545 - accuracy: 0.8095 - val_loss: 0.5028 - val_accuracy: 0.7640\n",
            "Epoch 1851/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4544 - accuracy: 0.8095 - val_loss: 0.5028 - val_accuracy: 0.7640\n",
            "Epoch 1852/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4543 - accuracy: 0.8095 - val_loss: 0.5027 - val_accuracy: 0.7640\n",
            "Epoch 1853/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4542 - accuracy: 0.8095 - val_loss: 0.5027 - val_accuracy: 0.7640\n",
            "Epoch 1854/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4541 - accuracy: 0.8095 - val_loss: 0.5027 - val_accuracy: 0.7640\n",
            "Epoch 1855/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4540 - accuracy: 0.8095 - val_loss: 0.5027 - val_accuracy: 0.7640\n",
            "Epoch 1856/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4539 - accuracy: 0.8095 - val_loss: 0.5026 - val_accuracy: 0.7640\n",
            "Epoch 1857/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4539 - accuracy: 0.8095 - val_loss: 0.5026 - val_accuracy: 0.7640\n",
            "Epoch 1858/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4538 - accuracy: 0.8095 - val_loss: 0.5026 - val_accuracy: 0.7640\n",
            "Epoch 1859/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4537 - accuracy: 0.8095 - val_loss: 0.5025 - val_accuracy: 0.7640\n",
            "Epoch 1860/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4536 - accuracy: 0.8095 - val_loss: 0.5025 - val_accuracy: 0.7640\n",
            "Epoch 1861/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4535 - accuracy: 0.8095 - val_loss: 0.5025 - val_accuracy: 0.7640\n",
            "Epoch 1862/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4534 - accuracy: 0.8095 - val_loss: 0.5025 - val_accuracy: 0.7640\n",
            "Epoch 1863/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4534 - accuracy: 0.8095 - val_loss: 0.5025 - val_accuracy: 0.7640\n",
            "Epoch 1864/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.8095 - val_loss: 0.5025 - val_accuracy: 0.7640\n",
            "Epoch 1865/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4532 - accuracy: 0.8095 - val_loss: 0.5024 - val_accuracy: 0.7640\n",
            "Epoch 1866/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4531 - accuracy: 0.8095 - val_loss: 0.5024 - val_accuracy: 0.7640\n",
            "Epoch 1867/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.8095 - val_loss: 0.5024 - val_accuracy: 0.7640\n",
            "Epoch 1868/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.8095 - val_loss: 0.5024 - val_accuracy: 0.7640\n",
            "Epoch 1869/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4529 - accuracy: 0.8095 - val_loss: 0.5023 - val_accuracy: 0.7640\n",
            "Epoch 1870/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.8095 - val_loss: 0.5023 - val_accuracy: 0.7640\n",
            "Epoch 1871/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4527 - accuracy: 0.8095 - val_loss: 0.5023 - val_accuracy: 0.7640\n",
            "Epoch 1872/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4526 - accuracy: 0.8095 - val_loss: 0.5022 - val_accuracy: 0.7640\n",
            "Epoch 1873/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4526 - accuracy: 0.8095 - val_loss: 0.5022 - val_accuracy: 0.7640\n",
            "Epoch 1874/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.8095 - val_loss: 0.5022 - val_accuracy: 0.7640\n",
            "Epoch 1875/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.8095 - val_loss: 0.5022 - val_accuracy: 0.7640\n",
            "Epoch 1876/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4523 - accuracy: 0.8095 - val_loss: 0.5022 - val_accuracy: 0.7640\n",
            "Epoch 1877/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.8095 - val_loss: 0.5021 - val_accuracy: 0.7640\n",
            "Epoch 1878/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.8095 - val_loss: 0.5021 - val_accuracy: 0.7640\n",
            "Epoch 1879/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4520 - accuracy: 0.8095 - val_loss: 0.5021 - val_accuracy: 0.7640\n",
            "Epoch 1880/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4520 - accuracy: 0.8095 - val_loss: 0.5021 - val_accuracy: 0.7640\n",
            "Epoch 1881/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.8095 - val_loss: 0.5020 - val_accuracy: 0.7640\n",
            "Epoch 1882/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.8095 - val_loss: 0.5020 - val_accuracy: 0.7640\n",
            "Epoch 1883/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.8095 - val_loss: 0.5020 - val_accuracy: 0.7640\n",
            "Epoch 1884/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4516 - accuracy: 0.8095 - val_loss: 0.5020 - val_accuracy: 0.7640\n",
            "Epoch 1885/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4516 - accuracy: 0.8095 - val_loss: 0.5019 - val_accuracy: 0.7640\n",
            "Epoch 1886/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4515 - accuracy: 0.8095 - val_loss: 0.5019 - val_accuracy: 0.7640\n",
            "Epoch 1887/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4514 - accuracy: 0.8095 - val_loss: 0.5019 - val_accuracy: 0.7640\n",
            "Epoch 1888/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.8095 - val_loss: 0.5018 - val_accuracy: 0.7640\n",
            "Epoch 1889/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4512 - accuracy: 0.8095 - val_loss: 0.5018 - val_accuracy: 0.7640\n",
            "Epoch 1890/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4512 - accuracy: 0.8095 - val_loss: 0.5018 - val_accuracy: 0.7640\n",
            "Epoch 1891/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4511 - accuracy: 0.8095 - val_loss: 0.5018 - val_accuracy: 0.7640\n",
            "Epoch 1892/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4510 - accuracy: 0.8095 - val_loss: 0.5017 - val_accuracy: 0.7640\n",
            "Epoch 1893/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.8095 - val_loss: 0.5017 - val_accuracy: 0.7640\n",
            "Epoch 1894/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4508 - accuracy: 0.8095 - val_loss: 0.5017 - val_accuracy: 0.7640\n",
            "Epoch 1895/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4507 - accuracy: 0.8095 - val_loss: 0.5017 - val_accuracy: 0.7640\n",
            "Epoch 1896/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4507 - accuracy: 0.8095 - val_loss: 0.5017 - val_accuracy: 0.7640\n",
            "Epoch 1897/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.8095 - val_loss: 0.5016 - val_accuracy: 0.7640\n",
            "Epoch 1898/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4505 - accuracy: 0.8095 - val_loss: 0.5016 - val_accuracy: 0.7640\n",
            "Epoch 1899/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4504 - accuracy: 0.8095 - val_loss: 0.5016 - val_accuracy: 0.7640\n",
            "Epoch 1900/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4503 - accuracy: 0.8095 - val_loss: 0.5016 - val_accuracy: 0.7640\n",
            "Epoch 1901/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4502 - accuracy: 0.8095 - val_loss: 0.5016 - val_accuracy: 0.7640\n",
            "Epoch 1902/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.8095 - val_loss: 0.5016 - val_accuracy: 0.7584\n",
            "Epoch 1903/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4501 - accuracy: 0.8095 - val_loss: 0.5015 - val_accuracy: 0.7584\n",
            "Epoch 1904/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.8095 - val_loss: 0.5015 - val_accuracy: 0.7584\n",
            "Epoch 1905/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4499 - accuracy: 0.8095 - val_loss: 0.5015 - val_accuracy: 0.7584\n",
            "Epoch 1906/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4498 - accuracy: 0.8095 - val_loss: 0.5014 - val_accuracy: 0.7584\n",
            "Epoch 1907/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4497 - accuracy: 0.8095 - val_loss: 0.5014 - val_accuracy: 0.7584\n",
            "Epoch 1908/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.8095 - val_loss: 0.5014 - val_accuracy: 0.7584\n",
            "Epoch 1909/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4496 - accuracy: 0.8095 - val_loss: 0.5014 - val_accuracy: 0.7584\n",
            "Epoch 1910/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4495 - accuracy: 0.8095 - val_loss: 0.5013 - val_accuracy: 0.7584\n",
            "Epoch 1911/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4494 - accuracy: 0.8095 - val_loss: 0.5013 - val_accuracy: 0.7584\n",
            "Epoch 1912/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4493 - accuracy: 0.8095 - val_loss: 0.5012 - val_accuracy: 0.7584\n",
            "Epoch 1913/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4493 - accuracy: 0.8095 - val_loss: 0.5012 - val_accuracy: 0.7584\n",
            "Epoch 1914/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4492 - accuracy: 0.8095 - val_loss: 0.5012 - val_accuracy: 0.7584\n",
            "Epoch 1915/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4491 - accuracy: 0.8095 - val_loss: 0.5012 - val_accuracy: 0.7584\n",
            "Epoch 1916/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4490 - accuracy: 0.8095 - val_loss: 0.5011 - val_accuracy: 0.7584\n",
            "Epoch 1917/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4489 - accuracy: 0.8095 - val_loss: 0.5011 - val_accuracy: 0.7584\n",
            "Epoch 1918/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.8095 - val_loss: 0.5010 - val_accuracy: 0.7584\n",
            "Epoch 1919/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4488 - accuracy: 0.8095 - val_loss: 0.5010 - val_accuracy: 0.7584\n",
            "Epoch 1920/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4487 - accuracy: 0.8095 - val_loss: 0.5009 - val_accuracy: 0.7584\n",
            "Epoch 1921/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4486 - accuracy: 0.8095 - val_loss: 0.5009 - val_accuracy: 0.7584\n",
            "Epoch 1922/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4485 - accuracy: 0.8095 - val_loss: 0.5009 - val_accuracy: 0.7584\n",
            "Epoch 1923/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.8095 - val_loss: 0.5009 - val_accuracy: 0.7584\n",
            "Epoch 1924/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4483 - accuracy: 0.8095 - val_loss: 0.5008 - val_accuracy: 0.7584\n",
            "Epoch 1925/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4483 - accuracy: 0.8095 - val_loss: 0.5008 - val_accuracy: 0.7584\n",
            "Epoch 1926/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4482 - accuracy: 0.8095 - val_loss: 0.5007 - val_accuracy: 0.7584\n",
            "Epoch 1927/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4481 - accuracy: 0.8095 - val_loss: 0.5007 - val_accuracy: 0.7584\n",
            "Epoch 1928/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4480 - accuracy: 0.8095 - val_loss: 0.5007 - val_accuracy: 0.7584\n",
            "Epoch 1929/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4479 - accuracy: 0.8095 - val_loss: 0.5006 - val_accuracy: 0.7584\n",
            "Epoch 1930/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4479 - accuracy: 0.8095 - val_loss: 0.5006 - val_accuracy: 0.7584\n",
            "Epoch 1931/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4478 - accuracy: 0.8095 - val_loss: 0.5005 - val_accuracy: 0.7584\n",
            "Epoch 1932/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4477 - accuracy: 0.8095 - val_loss: 0.5005 - val_accuracy: 0.7584\n",
            "Epoch 1933/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4476 - accuracy: 0.8095 - val_loss: 0.5005 - val_accuracy: 0.7584\n",
            "Epoch 1934/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4475 - accuracy: 0.8095 - val_loss: 0.5004 - val_accuracy: 0.7584\n",
            "Epoch 1935/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4475 - accuracy: 0.8095 - val_loss: 0.5004 - val_accuracy: 0.7584\n",
            "Epoch 1936/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.8095 - val_loss: 0.5004 - val_accuracy: 0.7584\n",
            "Epoch 1937/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.8095 - val_loss: 0.5003 - val_accuracy: 0.7584\n",
            "Epoch 1938/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4472 - accuracy: 0.8095 - val_loss: 0.5003 - val_accuracy: 0.7584\n",
            "Epoch 1939/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.8095 - val_loss: 0.5003 - val_accuracy: 0.7584\n",
            "Epoch 1940/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4470 - accuracy: 0.8095 - val_loss: 0.5003 - val_accuracy: 0.7584\n",
            "Epoch 1941/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4470 - accuracy: 0.8095 - val_loss: 0.5002 - val_accuracy: 0.7584\n",
            "Epoch 1942/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4469 - accuracy: 0.8095 - val_loss: 0.5002 - val_accuracy: 0.7584\n",
            "Epoch 1943/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4468 - accuracy: 0.8095 - val_loss: 0.5002 - val_accuracy: 0.7584\n",
            "Epoch 1944/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.8123 - val_loss: 0.5001 - val_accuracy: 0.7584\n",
            "Epoch 1945/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4467 - accuracy: 0.8123 - val_loss: 0.5001 - val_accuracy: 0.7584\n",
            "Epoch 1946/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4466 - accuracy: 0.8123 - val_loss: 0.5001 - val_accuracy: 0.7584\n",
            "Epoch 1947/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4465 - accuracy: 0.8123 - val_loss: 0.5001 - val_accuracy: 0.7584\n",
            "Epoch 1948/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4464 - accuracy: 0.8123 - val_loss: 0.5000 - val_accuracy: 0.7584\n",
            "Epoch 1949/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4463 - accuracy: 0.8123 - val_loss: 0.5000 - val_accuracy: 0.7584\n",
            "Epoch 1950/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4462 - accuracy: 0.8123 - val_loss: 0.5000 - val_accuracy: 0.7584\n",
            "Epoch 1951/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.8123 - val_loss: 0.4999 - val_accuracy: 0.7584\n",
            "Epoch 1952/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.8123 - val_loss: 0.4999 - val_accuracy: 0.7584\n",
            "Epoch 1953/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4460 - accuracy: 0.8123 - val_loss: 0.4999 - val_accuracy: 0.7584\n",
            "Epoch 1954/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4459 - accuracy: 0.8123 - val_loss: 0.4999 - val_accuracy: 0.7584\n",
            "Epoch 1955/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4458 - accuracy: 0.8123 - val_loss: 0.4998 - val_accuracy: 0.7584\n",
            "Epoch 1956/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4458 - accuracy: 0.8123 - val_loss: 0.4998 - val_accuracy: 0.7584\n",
            "Epoch 1957/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4457 - accuracy: 0.8123 - val_loss: 0.4998 - val_accuracy: 0.7584\n",
            "Epoch 1958/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4456 - accuracy: 0.8123 - val_loss: 0.4998 - val_accuracy: 0.7584\n",
            "Epoch 1959/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.8123 - val_loss: 0.4998 - val_accuracy: 0.7584\n",
            "Epoch 1960/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4455 - accuracy: 0.8123 - val_loss: 0.4998 - val_accuracy: 0.7584\n",
            "Epoch 1961/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.8151 - val_loss: 0.4998 - val_accuracy: 0.7584\n",
            "Epoch 1962/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4453 - accuracy: 0.8151 - val_loss: 0.4997 - val_accuracy: 0.7584\n",
            "Epoch 1963/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4452 - accuracy: 0.8151 - val_loss: 0.4997 - val_accuracy: 0.7584\n",
            "Epoch 1964/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4451 - accuracy: 0.8151 - val_loss: 0.4997 - val_accuracy: 0.7584\n",
            "Epoch 1965/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4451 - accuracy: 0.8151 - val_loss: 0.4997 - val_accuracy: 0.7584\n",
            "Epoch 1966/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4450 - accuracy: 0.8151 - val_loss: 0.4996 - val_accuracy: 0.7584\n",
            "Epoch 1967/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4449 - accuracy: 0.8151 - val_loss: 0.4996 - val_accuracy: 0.7584\n",
            "Epoch 1968/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.8151 - val_loss: 0.4996 - val_accuracy: 0.7584\n",
            "Epoch 1969/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4447 - accuracy: 0.8151 - val_loss: 0.4995 - val_accuracy: 0.7640\n",
            "Epoch 1970/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4447 - accuracy: 0.8151 - val_loss: 0.4995 - val_accuracy: 0.7640\n",
            "Epoch 1971/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4446 - accuracy: 0.8151 - val_loss: 0.4995 - val_accuracy: 0.7640\n",
            "Epoch 1972/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4445 - accuracy: 0.8151 - val_loss: 0.4994 - val_accuracy: 0.7640\n",
            "Epoch 1973/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.8151 - val_loss: 0.4994 - val_accuracy: 0.7640\n",
            "Epoch 1974/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4444 - accuracy: 0.8151 - val_loss: 0.4993 - val_accuracy: 0.7640\n",
            "Epoch 1975/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4443 - accuracy: 0.8151 - val_loss: 0.4993 - val_accuracy: 0.7640\n",
            "Epoch 1976/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4442 - accuracy: 0.8151 - val_loss: 0.4993 - val_accuracy: 0.7640\n",
            "Epoch 1977/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4442 - accuracy: 0.8179 - val_loss: 0.4993 - val_accuracy: 0.7640\n",
            "Epoch 1978/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4441 - accuracy: 0.8179 - val_loss: 0.4992 - val_accuracy: 0.7640\n",
            "Epoch 1979/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4440 - accuracy: 0.8179 - val_loss: 0.4992 - val_accuracy: 0.7640\n",
            "Epoch 1980/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.8179 - val_loss: 0.4992 - val_accuracy: 0.7640\n",
            "Epoch 1981/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4439 - accuracy: 0.8179 - val_loss: 0.4992 - val_accuracy: 0.7640\n",
            "Epoch 1982/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4438 - accuracy: 0.8179 - val_loss: 0.4991 - val_accuracy: 0.7640\n",
            "Epoch 1983/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.8179 - val_loss: 0.4991 - val_accuracy: 0.7697\n",
            "Epoch 1984/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4436 - accuracy: 0.8179 - val_loss: 0.4991 - val_accuracy: 0.7697\n",
            "Epoch 1985/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.8179 - val_loss: 0.4991 - val_accuracy: 0.7697\n",
            "Epoch 1986/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.8179 - val_loss: 0.4990 - val_accuracy: 0.7697\n",
            "Epoch 1987/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4434 - accuracy: 0.8179 - val_loss: 0.4990 - val_accuracy: 0.7697\n",
            "Epoch 1988/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4433 - accuracy: 0.8179 - val_loss: 0.4990 - val_accuracy: 0.7697\n",
            "Epoch 1989/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4433 - accuracy: 0.8207 - val_loss: 0.4989 - val_accuracy: 0.7697\n",
            "Epoch 1990/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.8207 - val_loss: 0.4989 - val_accuracy: 0.7697\n",
            "Epoch 1991/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4431 - accuracy: 0.8207 - val_loss: 0.4989 - val_accuracy: 0.7697\n",
            "Epoch 1992/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.8207 - val_loss: 0.4989 - val_accuracy: 0.7697\n",
            "Epoch 1993/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.8207 - val_loss: 0.4988 - val_accuracy: 0.7697\n",
            "Epoch 1994/4000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4429 - accuracy: 0.8207 - val_loss: 0.4988 - val_accuracy: 0.7697\n",
            "Epoch 1995/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4428 - accuracy: 0.8207 - val_loss: 0.4988 - val_accuracy: 0.7697\n",
            "Epoch 1996/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4428 - accuracy: 0.8207 - val_loss: 0.4987 - val_accuracy: 0.7697\n",
            "Epoch 1997/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.8207 - val_loss: 0.4987 - val_accuracy: 0.7697\n",
            "Epoch 1998/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4426 - accuracy: 0.8207 - val_loss: 0.4987 - val_accuracy: 0.7697\n",
            "Epoch 1999/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.8207 - val_loss: 0.4986 - val_accuracy: 0.7697\n",
            "Epoch 2000/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4424 - accuracy: 0.8207 - val_loss: 0.4986 - val_accuracy: 0.7697\n",
            "Epoch 2001/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.8207 - val_loss: 0.4985 - val_accuracy: 0.7697\n",
            "Epoch 2002/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4423 - accuracy: 0.8207 - val_loss: 0.4985 - val_accuracy: 0.7697\n",
            "Epoch 2003/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4422 - accuracy: 0.8207 - val_loss: 0.4985 - val_accuracy: 0.7697\n",
            "Epoch 2004/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4421 - accuracy: 0.8207 - val_loss: 0.4985 - val_accuracy: 0.7697\n",
            "Epoch 2005/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4421 - accuracy: 0.8207 - val_loss: 0.4985 - val_accuracy: 0.7697\n",
            "Epoch 2006/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.8207 - val_loss: 0.4984 - val_accuracy: 0.7697\n",
            "Epoch 2007/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4419 - accuracy: 0.8207 - val_loss: 0.4984 - val_accuracy: 0.7697\n",
            "Epoch 2008/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4419 - accuracy: 0.8207 - val_loss: 0.4984 - val_accuracy: 0.7697\n",
            "Epoch 2009/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4418 - accuracy: 0.8207 - val_loss: 0.4984 - val_accuracy: 0.7697\n",
            "Epoch 2010/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.8207 - val_loss: 0.4984 - val_accuracy: 0.7697\n",
            "Epoch 2011/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.8235 - val_loss: 0.4983 - val_accuracy: 0.7697\n",
            "Epoch 2012/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.8235 - val_loss: 0.4983 - val_accuracy: 0.7697\n",
            "Epoch 2013/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4415 - accuracy: 0.8235 - val_loss: 0.4983 - val_accuracy: 0.7697\n",
            "Epoch 2014/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4414 - accuracy: 0.8235 - val_loss: 0.4983 - val_accuracy: 0.7697\n",
            "Epoch 2015/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4414 - accuracy: 0.8235 - val_loss: 0.4982 - val_accuracy: 0.7697\n",
            "Epoch 2016/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.8235 - val_loss: 0.4982 - val_accuracy: 0.7697\n",
            "Epoch 2017/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4412 - accuracy: 0.8235 - val_loss: 0.4982 - val_accuracy: 0.7697\n",
            "Epoch 2018/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4412 - accuracy: 0.8235 - val_loss: 0.4982 - val_accuracy: 0.7697\n",
            "Epoch 2019/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4411 - accuracy: 0.8235 - val_loss: 0.4982 - val_accuracy: 0.7697\n",
            "Epoch 2020/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4410 - accuracy: 0.8235 - val_loss: 0.4982 - val_accuracy: 0.7697\n",
            "Epoch 2021/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4409 - accuracy: 0.8235 - val_loss: 0.4981 - val_accuracy: 0.7697\n",
            "Epoch 2022/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.8235 - val_loss: 0.4981 - val_accuracy: 0.7697\n",
            "Epoch 2023/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.8263 - val_loss: 0.4981 - val_accuracy: 0.7697\n",
            "Epoch 2024/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4407 - accuracy: 0.8263 - val_loss: 0.4981 - val_accuracy: 0.7697\n",
            "Epoch 2025/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.8235 - val_loss: 0.4981 - val_accuracy: 0.7697\n",
            "Epoch 2026/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4406 - accuracy: 0.8235 - val_loss: 0.4980 - val_accuracy: 0.7753\n",
            "Epoch 2027/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.8207 - val_loss: 0.4980 - val_accuracy: 0.7753\n",
            "Epoch 2028/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.8235 - val_loss: 0.4980 - val_accuracy: 0.7753\n",
            "Epoch 2029/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.8207 - val_loss: 0.4980 - val_accuracy: 0.7753\n",
            "Epoch 2030/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.8207 - val_loss: 0.4980 - val_accuracy: 0.7753\n",
            "Epoch 2031/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4402 - accuracy: 0.8235 - val_loss: 0.4980 - val_accuracy: 0.7753\n",
            "Epoch 2032/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4401 - accuracy: 0.8235 - val_loss: 0.4979 - val_accuracy: 0.7753\n",
            "Epoch 2033/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4401 - accuracy: 0.8235 - val_loss: 0.4979 - val_accuracy: 0.7753\n",
            "Epoch 2034/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4400 - accuracy: 0.8235 - val_loss: 0.4979 - val_accuracy: 0.7753\n",
            "Epoch 2035/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4399 - accuracy: 0.8235 - val_loss: 0.4978 - val_accuracy: 0.7753\n",
            "Epoch 2036/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4398 - accuracy: 0.8235 - val_loss: 0.4978 - val_accuracy: 0.7753\n",
            "Epoch 2037/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4398 - accuracy: 0.8207 - val_loss: 0.4978 - val_accuracy: 0.7753\n",
            "Epoch 2038/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4397 - accuracy: 0.8207 - val_loss: 0.4978 - val_accuracy: 0.7753\n",
            "Epoch 2039/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.8235 - val_loss: 0.4978 - val_accuracy: 0.7753\n",
            "Epoch 2040/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.8235 - val_loss: 0.4978 - val_accuracy: 0.7753\n",
            "Epoch 2041/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4395 - accuracy: 0.8235 - val_loss: 0.4977 - val_accuracy: 0.7753\n",
            "Epoch 2042/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4394 - accuracy: 0.8235 - val_loss: 0.4977 - val_accuracy: 0.7753\n",
            "Epoch 2043/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4393 - accuracy: 0.8263 - val_loss: 0.4977 - val_accuracy: 0.7753\n",
            "Epoch 2044/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.8263 - val_loss: 0.4977 - val_accuracy: 0.7753\n",
            "Epoch 2045/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4392 - accuracy: 0.8263 - val_loss: 0.4977 - val_accuracy: 0.7753\n",
            "Epoch 2046/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4391 - accuracy: 0.8263 - val_loss: 0.4977 - val_accuracy: 0.7753\n",
            "Epoch 2047/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4391 - accuracy: 0.8263 - val_loss: 0.4976 - val_accuracy: 0.7753\n",
            "Epoch 2048/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4390 - accuracy: 0.8263 - val_loss: 0.4976 - val_accuracy: 0.7753\n",
            "Epoch 2049/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4389 - accuracy: 0.8263 - val_loss: 0.4976 - val_accuracy: 0.7753\n",
            "Epoch 2050/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4388 - accuracy: 0.8263 - val_loss: 0.4976 - val_accuracy: 0.7753\n",
            "Epoch 2051/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4388 - accuracy: 0.8263 - val_loss: 0.4975 - val_accuracy: 0.7753\n",
            "Epoch 2052/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.8263 - val_loss: 0.4975 - val_accuracy: 0.7753\n",
            "Epoch 2053/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4386 - accuracy: 0.8263 - val_loss: 0.4975 - val_accuracy: 0.7753\n",
            "Epoch 2054/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4386 - accuracy: 0.8263 - val_loss: 0.4975 - val_accuracy: 0.7753\n",
            "Epoch 2055/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4385 - accuracy: 0.8235 - val_loss: 0.4974 - val_accuracy: 0.7753\n",
            "Epoch 2056/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4384 - accuracy: 0.8263 - val_loss: 0.4975 - val_accuracy: 0.7753\n",
            "Epoch 2057/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4384 - accuracy: 0.8263 - val_loss: 0.4974 - val_accuracy: 0.7753\n",
            "Epoch 2058/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4383 - accuracy: 0.8263 - val_loss: 0.4974 - val_accuracy: 0.7753\n",
            "Epoch 2059/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4382 - accuracy: 0.8263 - val_loss: 0.4974 - val_accuracy: 0.7753\n",
            "Epoch 2060/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4381 - accuracy: 0.8235 - val_loss: 0.4974 - val_accuracy: 0.7753\n",
            "Epoch 2061/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4380 - accuracy: 0.8235 - val_loss: 0.4974 - val_accuracy: 0.7753\n",
            "Epoch 2062/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4380 - accuracy: 0.8235 - val_loss: 0.4974 - val_accuracy: 0.7753\n",
            "Epoch 2063/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4379 - accuracy: 0.8235 - val_loss: 0.4973 - val_accuracy: 0.7753\n",
            "Epoch 2064/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4378 - accuracy: 0.8235 - val_loss: 0.4973 - val_accuracy: 0.7753\n",
            "Epoch 2065/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.8235 - val_loss: 0.4973 - val_accuracy: 0.7753\n",
            "Epoch 2066/4000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4377 - accuracy: 0.8235 - val_loss: 0.4972 - val_accuracy: 0.7753\n",
            "Epoch 2067/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.8235 - val_loss: 0.4972 - val_accuracy: 0.7753\n",
            "Epoch 2068/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4375 - accuracy: 0.8235 - val_loss: 0.4972 - val_accuracy: 0.7753\n",
            "Epoch 2069/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4375 - accuracy: 0.8235 - val_loss: 0.4972 - val_accuracy: 0.7753\n",
            "Epoch 2070/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4374 - accuracy: 0.8235 - val_loss: 0.4972 - val_accuracy: 0.7753\n",
            "Epoch 2071/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4373 - accuracy: 0.8235 - val_loss: 0.4971 - val_accuracy: 0.7753\n",
            "Epoch 2072/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4372 - accuracy: 0.8235 - val_loss: 0.4971 - val_accuracy: 0.7753\n",
            "Epoch 2073/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4372 - accuracy: 0.8235 - val_loss: 0.4971 - val_accuracy: 0.7753\n",
            "Epoch 2074/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4371 - accuracy: 0.8235 - val_loss: 0.4971 - val_accuracy: 0.7753\n",
            "Epoch 2075/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4370 - accuracy: 0.8235 - val_loss: 0.4971 - val_accuracy: 0.7753\n",
            "Epoch 2076/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4370 - accuracy: 0.8235 - val_loss: 0.4971 - val_accuracy: 0.7753\n",
            "Epoch 2077/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4369 - accuracy: 0.8235 - val_loss: 0.4971 - val_accuracy: 0.7753\n",
            "Epoch 2078/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4368 - accuracy: 0.8235 - val_loss: 0.4971 - val_accuracy: 0.7753\n",
            "Epoch 2079/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4367 - accuracy: 0.8235 - val_loss: 0.4971 - val_accuracy: 0.7753\n",
            "Epoch 2080/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4367 - accuracy: 0.8235 - val_loss: 0.4971 - val_accuracy: 0.7753\n",
            "Epoch 2081/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4366 - accuracy: 0.8235 - val_loss: 0.4970 - val_accuracy: 0.7753\n",
            "Epoch 2082/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4365 - accuracy: 0.8235 - val_loss: 0.4970 - val_accuracy: 0.7753\n",
            "Epoch 2083/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4365 - accuracy: 0.8235 - val_loss: 0.4970 - val_accuracy: 0.7753\n",
            "Epoch 2084/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4364 - accuracy: 0.8235 - val_loss: 0.4970 - val_accuracy: 0.7753\n",
            "Epoch 2085/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4363 - accuracy: 0.8235 - val_loss: 0.4970 - val_accuracy: 0.7753\n",
            "Epoch 2086/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4362 - accuracy: 0.8235 - val_loss: 0.4969 - val_accuracy: 0.7753\n",
            "Epoch 2087/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4362 - accuracy: 0.8235 - val_loss: 0.4969 - val_accuracy: 0.7753\n",
            "Epoch 2088/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4361 - accuracy: 0.8235 - val_loss: 0.4969 - val_accuracy: 0.7809\n",
            "Epoch 2089/4000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4360 - accuracy: 0.8235 - val_loss: 0.4969 - val_accuracy: 0.7809\n",
            "Epoch 2090/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4360 - accuracy: 0.8235 - val_loss: 0.4968 - val_accuracy: 0.7809\n",
            "Epoch 2091/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.8235 - val_loss: 0.4968 - val_accuracy: 0.7809\n",
            "Epoch 2092/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4358 - accuracy: 0.8235 - val_loss: 0.4968 - val_accuracy: 0.7809\n",
            "Epoch 2093/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4358 - accuracy: 0.8235 - val_loss: 0.4968 - val_accuracy: 0.7809\n",
            "Epoch 2094/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4357 - accuracy: 0.8235 - val_loss: 0.4968 - val_accuracy: 0.7809\n",
            "Epoch 2095/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4356 - accuracy: 0.8235 - val_loss: 0.4968 - val_accuracy: 0.7809\n",
            "Epoch 2096/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4356 - accuracy: 0.8235 - val_loss: 0.4968 - val_accuracy: 0.7809\n",
            "Epoch 2097/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.8235 - val_loss: 0.4968 - val_accuracy: 0.7809\n",
            "Epoch 2098/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4354 - accuracy: 0.8263 - val_loss: 0.4967 - val_accuracy: 0.7809\n",
            "Epoch 2099/4000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4354 - accuracy: 0.8263 - val_loss: 0.4967 - val_accuracy: 0.7809\n",
            "Epoch 2100/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.8263 - val_loss: 0.4967 - val_accuracy: 0.7809\n",
            "Epoch 2101/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4352 - accuracy: 0.8235 - val_loss: 0.4967 - val_accuracy: 0.7809\n",
            "Epoch 2102/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4352 - accuracy: 0.8235 - val_loss: 0.4967 - val_accuracy: 0.7809\n",
            "Epoch 2103/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4351 - accuracy: 0.8263 - val_loss: 0.4967 - val_accuracy: 0.7809\n",
            "Epoch 2104/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4351 - accuracy: 0.8235 - val_loss: 0.4966 - val_accuracy: 0.7809\n",
            "Epoch 2105/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4350 - accuracy: 0.8235 - val_loss: 0.4966 - val_accuracy: 0.7809\n",
            "Epoch 2106/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.8235 - val_loss: 0.4966 - val_accuracy: 0.7809\n",
            "Epoch 2107/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4348 - accuracy: 0.8235 - val_loss: 0.4966 - val_accuracy: 0.7809\n",
            "Epoch 2108/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4348 - accuracy: 0.8235 - val_loss: 0.4966 - val_accuracy: 0.7809\n",
            "Epoch 2109/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4347 - accuracy: 0.8235 - val_loss: 0.4965 - val_accuracy: 0.7809\n",
            "Epoch 2110/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4347 - accuracy: 0.8235 - val_loss: 0.4965 - val_accuracy: 0.7809\n",
            "Epoch 2111/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4346 - accuracy: 0.8235 - val_loss: 0.4965 - val_accuracy: 0.7809\n",
            "Epoch 2112/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4345 - accuracy: 0.8235 - val_loss: 0.4965 - val_accuracy: 0.7809\n",
            "Epoch 2113/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4344 - accuracy: 0.8235 - val_loss: 0.4965 - val_accuracy: 0.7809\n",
            "Epoch 2114/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4344 - accuracy: 0.8235 - val_loss: 0.4965 - val_accuracy: 0.7809\n",
            "Epoch 2115/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4343 - accuracy: 0.8235 - val_loss: 0.4964 - val_accuracy: 0.7809\n",
            "Epoch 2116/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4343 - accuracy: 0.8235 - val_loss: 0.4964 - val_accuracy: 0.7809\n",
            "Epoch 2117/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4342 - accuracy: 0.8235 - val_loss: 0.4964 - val_accuracy: 0.7809\n",
            "Epoch 2118/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4341 - accuracy: 0.8235 - val_loss: 0.4964 - val_accuracy: 0.7809\n",
            "Epoch 2119/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4340 - accuracy: 0.8235 - val_loss: 0.4963 - val_accuracy: 0.7809\n",
            "Epoch 2120/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4340 - accuracy: 0.8235 - val_loss: 0.4963 - val_accuracy: 0.7809\n",
            "Epoch 2121/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4339 - accuracy: 0.8235 - val_loss: 0.4963 - val_accuracy: 0.7809\n",
            "Epoch 2122/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4339 - accuracy: 0.8235 - val_loss: 0.4963 - val_accuracy: 0.7809\n",
            "Epoch 2123/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4338 - accuracy: 0.8235 - val_loss: 0.4963 - val_accuracy: 0.7809\n",
            "Epoch 2124/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4337 - accuracy: 0.8235 - val_loss: 0.4962 - val_accuracy: 0.7809\n",
            "Epoch 2125/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4337 - accuracy: 0.8235 - val_loss: 0.4962 - val_accuracy: 0.7809\n",
            "Epoch 2126/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4336 - accuracy: 0.8235 - val_loss: 0.4962 - val_accuracy: 0.7809\n",
            "Epoch 2127/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.8235 - val_loss: 0.4962 - val_accuracy: 0.7809\n",
            "Epoch 2128/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4335 - accuracy: 0.8235 - val_loss: 0.4962 - val_accuracy: 0.7809\n",
            "Epoch 2129/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.8235 - val_loss: 0.4962 - val_accuracy: 0.7809\n",
            "Epoch 2130/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.8235 - val_loss: 0.4961 - val_accuracy: 0.7809\n",
            "Epoch 2131/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4333 - accuracy: 0.8235 - val_loss: 0.4961 - val_accuracy: 0.7809\n",
            "Epoch 2132/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4332 - accuracy: 0.8235 - val_loss: 0.4961 - val_accuracy: 0.7809\n",
            "Epoch 2133/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4331 - accuracy: 0.8235 - val_loss: 0.4961 - val_accuracy: 0.7809\n",
            "Epoch 2134/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4330 - accuracy: 0.8235 - val_loss: 0.4961 - val_accuracy: 0.7809\n",
            "Epoch 2135/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4330 - accuracy: 0.8235 - val_loss: 0.4961 - val_accuracy: 0.7809\n",
            "Epoch 2136/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4329 - accuracy: 0.8235 - val_loss: 0.4961 - val_accuracy: 0.7809\n",
            "Epoch 2137/4000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4329 - accuracy: 0.8235 - val_loss: 0.4961 - val_accuracy: 0.7809\n",
            "Epoch 2138/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4328 - accuracy: 0.8235 - val_loss: 0.4960 - val_accuracy: 0.7809\n",
            "Epoch 2139/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4327 - accuracy: 0.8235 - val_loss: 0.4960 - val_accuracy: 0.7809\n",
            "Epoch 2140/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4327 - accuracy: 0.8235 - val_loss: 0.4960 - val_accuracy: 0.7809\n",
            "Epoch 2141/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4326 - accuracy: 0.8235 - val_loss: 0.4959 - val_accuracy: 0.7809\n",
            "Epoch 2142/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4325 - accuracy: 0.8235 - val_loss: 0.4959 - val_accuracy: 0.7809\n",
            "Epoch 2143/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4325 - accuracy: 0.8235 - val_loss: 0.4958 - val_accuracy: 0.7809\n",
            "Epoch 2144/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4324 - accuracy: 0.8263 - val_loss: 0.4958 - val_accuracy: 0.7809\n",
            "Epoch 2145/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4323 - accuracy: 0.8235 - val_loss: 0.4958 - val_accuracy: 0.7809\n",
            "Epoch 2146/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4323 - accuracy: 0.8235 - val_loss: 0.4958 - val_accuracy: 0.7809\n",
            "Epoch 2147/4000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.4322 - accuracy: 0.8235 - val_loss: 0.4958 - val_accuracy: 0.7809\n",
            "Epoch 2148/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4321 - accuracy: 0.8235 - val_loss: 0.4957 - val_accuracy: 0.7809\n",
            "Epoch 2149/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4321 - accuracy: 0.8263 - val_loss: 0.4958 - val_accuracy: 0.7809\n",
            "Epoch 2150/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4320 - accuracy: 0.8235 - val_loss: 0.4957 - val_accuracy: 0.7809\n",
            "Epoch 2151/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4319 - accuracy: 0.8235 - val_loss: 0.4957 - val_accuracy: 0.7809\n",
            "Epoch 2152/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4319 - accuracy: 0.8235 - val_loss: 0.4956 - val_accuracy: 0.7809\n",
            "Epoch 2153/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4318 - accuracy: 0.8235 - val_loss: 0.4956 - val_accuracy: 0.7809\n",
            "Epoch 2154/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4317 - accuracy: 0.8235 - val_loss: 0.4956 - val_accuracy: 0.7809\n",
            "Epoch 2155/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4317 - accuracy: 0.8235 - val_loss: 0.4956 - val_accuracy: 0.7809\n",
            "Epoch 2156/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4316 - accuracy: 0.8235 - val_loss: 0.4956 - val_accuracy: 0.7809\n",
            "Epoch 2157/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4315 - accuracy: 0.8235 - val_loss: 0.4956 - val_accuracy: 0.7809\n",
            "Epoch 2158/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4315 - accuracy: 0.8235 - val_loss: 0.4955 - val_accuracy: 0.7809\n",
            "Epoch 2159/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4314 - accuracy: 0.8235 - val_loss: 0.4955 - val_accuracy: 0.7809\n",
            "Epoch 2160/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4313 - accuracy: 0.8235 - val_loss: 0.4955 - val_accuracy: 0.7809\n",
            "Epoch 2161/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4313 - accuracy: 0.8235 - val_loss: 0.4954 - val_accuracy: 0.7809\n",
            "Epoch 2162/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4312 - accuracy: 0.8235 - val_loss: 0.4954 - val_accuracy: 0.7809\n",
            "Epoch 2163/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4311 - accuracy: 0.8235 - val_loss: 0.4954 - val_accuracy: 0.7809\n",
            "Epoch 2164/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4311 - accuracy: 0.8235 - val_loss: 0.4954 - val_accuracy: 0.7809\n",
            "Epoch 2165/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4310 - accuracy: 0.8235 - val_loss: 0.4954 - val_accuracy: 0.7809\n",
            "Epoch 2166/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4309 - accuracy: 0.8235 - val_loss: 0.4954 - val_accuracy: 0.7809\n",
            "Epoch 2167/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4309 - accuracy: 0.8235 - val_loss: 0.4954 - val_accuracy: 0.7809\n",
            "Epoch 2168/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4308 - accuracy: 0.8235 - val_loss: 0.4954 - val_accuracy: 0.7809\n",
            "Epoch 2169/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4307 - accuracy: 0.8235 - val_loss: 0.4953 - val_accuracy: 0.7809\n",
            "Epoch 2170/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4307 - accuracy: 0.8235 - val_loss: 0.4953 - val_accuracy: 0.7809\n",
            "Epoch 2171/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4306 - accuracy: 0.8235 - val_loss: 0.4953 - val_accuracy: 0.7809\n",
            "Epoch 2172/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.8235 - val_loss: 0.4953 - val_accuracy: 0.7809\n",
            "Epoch 2173/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4304 - accuracy: 0.8263 - val_loss: 0.4952 - val_accuracy: 0.7809\n",
            "Epoch 2174/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4304 - accuracy: 0.8263 - val_loss: 0.4952 - val_accuracy: 0.7809\n",
            "Epoch 2175/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4303 - accuracy: 0.8235 - val_loss: 0.4952 - val_accuracy: 0.7809\n",
            "Epoch 2176/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4302 - accuracy: 0.8235 - val_loss: 0.4952 - val_accuracy: 0.7809\n",
            "Epoch 2177/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4302 - accuracy: 0.8235 - val_loss: 0.4952 - val_accuracy: 0.7809\n",
            "Epoch 2178/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4301 - accuracy: 0.8235 - val_loss: 0.4952 - val_accuracy: 0.7809\n",
            "Epoch 2179/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4301 - accuracy: 0.8235 - val_loss: 0.4952 - val_accuracy: 0.7809\n",
            "Epoch 2180/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4300 - accuracy: 0.8235 - val_loss: 0.4952 - val_accuracy: 0.7809\n",
            "Epoch 2181/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.8235 - val_loss: 0.4952 - val_accuracy: 0.7809\n",
            "Epoch 2182/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4299 - accuracy: 0.8263 - val_loss: 0.4952 - val_accuracy: 0.7809\n",
            "Epoch 2183/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4298 - accuracy: 0.8263 - val_loss: 0.4952 - val_accuracy: 0.7809\n",
            "Epoch 2184/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4297 - accuracy: 0.8263 - val_loss: 0.4952 - val_accuracy: 0.7809\n",
            "Epoch 2185/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4297 - accuracy: 0.8263 - val_loss: 0.4951 - val_accuracy: 0.7809\n",
            "Epoch 2186/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4296 - accuracy: 0.8263 - val_loss: 0.4951 - val_accuracy: 0.7809\n",
            "Epoch 2187/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4296 - accuracy: 0.8263 - val_loss: 0.4951 - val_accuracy: 0.7809\n",
            "Epoch 2188/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4295 - accuracy: 0.8263 - val_loss: 0.4951 - val_accuracy: 0.7809\n",
            "Epoch 2189/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4294 - accuracy: 0.8263 - val_loss: 0.4951 - val_accuracy: 0.7809\n",
            "Epoch 2190/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4294 - accuracy: 0.8263 - val_loss: 0.4950 - val_accuracy: 0.7753\n",
            "Epoch 2191/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4293 - accuracy: 0.8263 - val_loss: 0.4950 - val_accuracy: 0.7753\n",
            "Epoch 2192/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4292 - accuracy: 0.8263 - val_loss: 0.4949 - val_accuracy: 0.7753\n",
            "Epoch 2193/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4292 - accuracy: 0.8263 - val_loss: 0.4949 - val_accuracy: 0.7753\n",
            "Epoch 2194/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.8263 - val_loss: 0.4949 - val_accuracy: 0.7753\n",
            "Epoch 2195/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4290 - accuracy: 0.8291 - val_loss: 0.4949 - val_accuracy: 0.7753\n",
            "Epoch 2196/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4290 - accuracy: 0.8291 - val_loss: 0.4949 - val_accuracy: 0.7753\n",
            "Epoch 2197/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4289 - accuracy: 0.8291 - val_loss: 0.4949 - val_accuracy: 0.7753\n",
            "Epoch 2198/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4289 - accuracy: 0.8291 - val_loss: 0.4949 - val_accuracy: 0.7753\n",
            "Epoch 2199/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4288 - accuracy: 0.8291 - val_loss: 0.4948 - val_accuracy: 0.7753\n",
            "Epoch 2200/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4287 - accuracy: 0.8291 - val_loss: 0.4949 - val_accuracy: 0.7753\n",
            "Epoch 2201/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4287 - accuracy: 0.8291 - val_loss: 0.4948 - val_accuracy: 0.7753\n",
            "Epoch 2202/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4286 - accuracy: 0.8291 - val_loss: 0.4948 - val_accuracy: 0.7753\n",
            "Epoch 2203/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4286 - accuracy: 0.8291 - val_loss: 0.4948 - val_accuracy: 0.7753\n",
            "Epoch 2204/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4285 - accuracy: 0.8291 - val_loss: 0.4947 - val_accuracy: 0.7753\n",
            "Epoch 2205/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4284 - accuracy: 0.8291 - val_loss: 0.4947 - val_accuracy: 0.7753\n",
            "Epoch 2206/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4284 - accuracy: 0.8291 - val_loss: 0.4947 - val_accuracy: 0.7753\n",
            "Epoch 2207/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4283 - accuracy: 0.8291 - val_loss: 0.4947 - val_accuracy: 0.7753\n",
            "Epoch 2208/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.8291 - val_loss: 0.4947 - val_accuracy: 0.7753\n",
            "Epoch 2209/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.8319 - val_loss: 0.4947 - val_accuracy: 0.7753\n",
            "Epoch 2210/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4281 - accuracy: 0.8319 - val_loss: 0.4946 - val_accuracy: 0.7753\n",
            "Epoch 2211/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4281 - accuracy: 0.8319 - val_loss: 0.4946 - val_accuracy: 0.7753\n",
            "Epoch 2212/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.8319 - val_loss: 0.4946 - val_accuracy: 0.7753\n",
            "Epoch 2213/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4279 - accuracy: 0.8319 - val_loss: 0.4946 - val_accuracy: 0.7753\n",
            "Epoch 2214/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4279 - accuracy: 0.8319 - val_loss: 0.4946 - val_accuracy: 0.7753\n",
            "Epoch 2215/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.8319 - val_loss: 0.4946 - val_accuracy: 0.7753\n",
            "Epoch 2216/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4277 - accuracy: 0.8319 - val_loss: 0.4945 - val_accuracy: 0.7753\n",
            "Epoch 2217/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4277 - accuracy: 0.8319 - val_loss: 0.4945 - val_accuracy: 0.7753\n",
            "Epoch 2218/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4276 - accuracy: 0.8319 - val_loss: 0.4945 - val_accuracy: 0.7753\n",
            "Epoch 2219/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.8319 - val_loss: 0.4945 - val_accuracy: 0.7753\n",
            "Epoch 2220/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4275 - accuracy: 0.8319 - val_loss: 0.4945 - val_accuracy: 0.7753\n",
            "Epoch 2221/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.8319 - val_loss: 0.4944 - val_accuracy: 0.7753\n",
            "Epoch 2222/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4274 - accuracy: 0.8319 - val_loss: 0.4944 - val_accuracy: 0.7753\n",
            "Epoch 2223/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4273 - accuracy: 0.8319 - val_loss: 0.4944 - val_accuracy: 0.7753\n",
            "Epoch 2224/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4272 - accuracy: 0.8319 - val_loss: 0.4944 - val_accuracy: 0.7753\n",
            "Epoch 2225/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4272 - accuracy: 0.8319 - val_loss: 0.4944 - val_accuracy: 0.7753\n",
            "Epoch 2226/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4271 - accuracy: 0.8319 - val_loss: 0.4944 - val_accuracy: 0.7753\n",
            "Epoch 2227/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4271 - accuracy: 0.8319 - val_loss: 0.4943 - val_accuracy: 0.7753\n",
            "Epoch 2228/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4270 - accuracy: 0.8319 - val_loss: 0.4943 - val_accuracy: 0.7753\n",
            "Epoch 2229/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4269 - accuracy: 0.8319 - val_loss: 0.4943 - val_accuracy: 0.7753\n",
            "Epoch 2230/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4269 - accuracy: 0.8319 - val_loss: 0.4943 - val_accuracy: 0.7753\n",
            "Epoch 2231/4000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4268 - accuracy: 0.8319 - val_loss: 0.4943 - val_accuracy: 0.7753\n",
            "Epoch 2232/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4268 - accuracy: 0.8319 - val_loss: 0.4943 - val_accuracy: 0.7753\n",
            "Epoch 2233/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4267 - accuracy: 0.8319 - val_loss: 0.4942 - val_accuracy: 0.7753\n",
            "Epoch 2234/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.8319 - val_loss: 0.4942 - val_accuracy: 0.7753\n",
            "Epoch 2235/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4266 - accuracy: 0.8319 - val_loss: 0.4942 - val_accuracy: 0.7753\n",
            "Epoch 2236/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4265 - accuracy: 0.8319 - val_loss: 0.4942 - val_accuracy: 0.7753\n",
            "Epoch 2237/4000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4265 - accuracy: 0.8319 - val_loss: 0.4942 - val_accuracy: 0.7753\n",
            "Epoch 2238/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4264 - accuracy: 0.8319 - val_loss: 0.4942 - val_accuracy: 0.7753\n",
            "Epoch 2239/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.8319 - val_loss: 0.4941 - val_accuracy: 0.7753\n",
            "Epoch 2240/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4263 - accuracy: 0.8319 - val_loss: 0.4941 - val_accuracy: 0.7753\n",
            "Epoch 2241/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4262 - accuracy: 0.8319 - val_loss: 0.4941 - val_accuracy: 0.7753\n",
            "Epoch 2242/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4262 - accuracy: 0.8319 - val_loss: 0.4941 - val_accuracy: 0.7753\n",
            "Epoch 2243/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4261 - accuracy: 0.8319 - val_loss: 0.4941 - val_accuracy: 0.7753\n",
            "Epoch 2244/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4261 - accuracy: 0.8319 - val_loss: 0.4941 - val_accuracy: 0.7753\n",
            "Epoch 2245/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4260 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2246/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4259 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2247/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4259 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2248/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4258 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2249/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4257 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2250/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4257 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2251/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4256 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2252/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4256 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2253/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4255 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2254/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4255 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2255/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4254 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2256/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4253 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2257/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4253 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2258/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4252 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2259/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4252 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2260/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4251 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2261/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4250 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2262/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4250 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2263/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4249 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2264/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4249 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2265/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4248 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2266/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4248 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2267/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4247 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2268/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4247 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2269/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4246 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2270/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4245 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2271/4000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4245 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2272/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4244 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2273/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4244 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2274/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4243 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2275/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4243 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2276/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4242 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2277/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2278/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4241 - accuracy: 0.8319 - val_loss: 0.4940 - val_accuracy: 0.7753\n",
            "Epoch 2279/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4240 - accuracy: 0.8319 - val_loss: 0.4939 - val_accuracy: 0.7753\n",
            "Epoch 2280/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4240 - accuracy: 0.8319 - val_loss: 0.4939 - val_accuracy: 0.7753\n",
            "Epoch 2281/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4239 - accuracy: 0.8319 - val_loss: 0.4939 - val_accuracy: 0.7753\n",
            "Epoch 2282/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.8319 - val_loss: 0.4939 - val_accuracy: 0.7753\n",
            "Epoch 2283/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4238 - accuracy: 0.8319 - val_loss: 0.4939 - val_accuracy: 0.7753\n",
            "Epoch 2284/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4237 - accuracy: 0.8319 - val_loss: 0.4939 - val_accuracy: 0.7753\n",
            "Epoch 2285/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4237 - accuracy: 0.8319 - val_loss: 0.4939 - val_accuracy: 0.7753\n",
            "Epoch 2286/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4236 - accuracy: 0.8319 - val_loss: 0.4939 - val_accuracy: 0.7753\n",
            "Epoch 2287/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.8319 - val_loss: 0.4939 - val_accuracy: 0.7753\n",
            "Epoch 2288/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4235 - accuracy: 0.8319 - val_loss: 0.4939 - val_accuracy: 0.7753\n",
            "Epoch 2289/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4234 - accuracy: 0.8319 - val_loss: 0.4938 - val_accuracy: 0.7753\n",
            "Epoch 2290/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4234 - accuracy: 0.8319 - val_loss: 0.4938 - val_accuracy: 0.7753\n",
            "Epoch 2291/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4233 - accuracy: 0.8319 - val_loss: 0.4938 - val_accuracy: 0.7753\n",
            "Epoch 2292/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4232 - accuracy: 0.8319 - val_loss: 0.4938 - val_accuracy: 0.7753\n",
            "Epoch 2293/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4232 - accuracy: 0.8319 - val_loss: 0.4938 - val_accuracy: 0.7753\n",
            "Epoch 2294/4000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4231 - accuracy: 0.8319 - val_loss: 0.4937 - val_accuracy: 0.7753\n",
            "Epoch 2295/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4230 - accuracy: 0.8347 - val_loss: 0.4937 - val_accuracy: 0.7753\n",
            "Epoch 2296/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4229 - accuracy: 0.8347 - val_loss: 0.4937 - val_accuracy: 0.7753\n",
            "Epoch 2297/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4229 - accuracy: 0.8347 - val_loss: 0.4937 - val_accuracy: 0.7753\n",
            "Epoch 2298/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4228 - accuracy: 0.8347 - val_loss: 0.4936 - val_accuracy: 0.7753\n",
            "Epoch 2299/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.8347 - val_loss: 0.4936 - val_accuracy: 0.7753\n",
            "Epoch 2300/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8347 - val_loss: 0.4936 - val_accuracy: 0.7753\n",
            "Epoch 2301/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4226 - accuracy: 0.8347 - val_loss: 0.4936 - val_accuracy: 0.7753\n",
            "Epoch 2302/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.8347 - val_loss: 0.4935 - val_accuracy: 0.7753\n",
            "Epoch 2303/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4225 - accuracy: 0.8347 - val_loss: 0.4935 - val_accuracy: 0.7753\n",
            "Epoch 2304/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4224 - accuracy: 0.8347 - val_loss: 0.4935 - val_accuracy: 0.7753\n",
            "Epoch 2305/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4224 - accuracy: 0.8347 - val_loss: 0.4935 - val_accuracy: 0.7753\n",
            "Epoch 2306/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4223 - accuracy: 0.8347 - val_loss: 0.4934 - val_accuracy: 0.7753\n",
            "Epoch 2307/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4223 - accuracy: 0.8347 - val_loss: 0.4934 - val_accuracy: 0.7753\n",
            "Epoch 2308/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4222 - accuracy: 0.8347 - val_loss: 0.4934 - val_accuracy: 0.7753\n",
            "Epoch 2309/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.8347 - val_loss: 0.4934 - val_accuracy: 0.7753\n",
            "Epoch 2310/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4221 - accuracy: 0.8347 - val_loss: 0.4934 - val_accuracy: 0.7753\n",
            "Epoch 2311/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4220 - accuracy: 0.8347 - val_loss: 0.4934 - val_accuracy: 0.7753\n",
            "Epoch 2312/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4220 - accuracy: 0.8347 - val_loss: 0.4934 - val_accuracy: 0.7753\n",
            "Epoch 2313/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4219 - accuracy: 0.8347 - val_loss: 0.4933 - val_accuracy: 0.7753\n",
            "Epoch 2314/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.8347 - val_loss: 0.4933 - val_accuracy: 0.7753\n",
            "Epoch 2315/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4218 - accuracy: 0.8347 - val_loss: 0.4933 - val_accuracy: 0.7753\n",
            "Epoch 2316/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4217 - accuracy: 0.8347 - val_loss: 0.4933 - val_accuracy: 0.7753\n",
            "Epoch 2317/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4216 - accuracy: 0.8347 - val_loss: 0.4933 - val_accuracy: 0.7753\n",
            "Epoch 2318/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4216 - accuracy: 0.8347 - val_loss: 0.4932 - val_accuracy: 0.7753\n",
            "Epoch 2319/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.8347 - val_loss: 0.4932 - val_accuracy: 0.7753\n",
            "Epoch 2320/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4214 - accuracy: 0.8347 - val_loss: 0.4932 - val_accuracy: 0.7753\n",
            "Epoch 2321/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4214 - accuracy: 0.8347 - val_loss: 0.4932 - val_accuracy: 0.7753\n",
            "Epoch 2322/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.8347 - val_loss: 0.4931 - val_accuracy: 0.7753\n",
            "Epoch 2323/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4213 - accuracy: 0.8347 - val_loss: 0.4931 - val_accuracy: 0.7753\n",
            "Epoch 2324/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4212 - accuracy: 0.8347 - val_loss: 0.4931 - val_accuracy: 0.7753\n",
            "Epoch 2325/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.8347 - val_loss: 0.4932 - val_accuracy: 0.7753\n",
            "Epoch 2326/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.8347 - val_loss: 0.4931 - val_accuracy: 0.7753\n",
            "Epoch 2327/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4210 - accuracy: 0.8347 - val_loss: 0.4931 - val_accuracy: 0.7753\n",
            "Epoch 2328/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4210 - accuracy: 0.8347 - val_loss: 0.4932 - val_accuracy: 0.7753\n",
            "Epoch 2329/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4209 - accuracy: 0.8347 - val_loss: 0.4931 - val_accuracy: 0.7753\n",
            "Epoch 2330/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4208 - accuracy: 0.8347 - val_loss: 0.4931 - val_accuracy: 0.7753\n",
            "Epoch 2331/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.8347 - val_loss: 0.4931 - val_accuracy: 0.7753\n",
            "Epoch 2332/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.8347 - val_loss: 0.4931 - val_accuracy: 0.7753\n",
            "Epoch 2333/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4207 - accuracy: 0.8347 - val_loss: 0.4931 - val_accuracy: 0.7753\n",
            "Epoch 2334/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4206 - accuracy: 0.8347 - val_loss: 0.4931 - val_accuracy: 0.7753\n",
            "Epoch 2335/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4205 - accuracy: 0.8347 - val_loss: 0.4930 - val_accuracy: 0.7753\n",
            "Epoch 2336/4000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4205 - accuracy: 0.8347 - val_loss: 0.4930 - val_accuracy: 0.7753\n",
            "Epoch 2337/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4204 - accuracy: 0.8347 - val_loss: 0.4930 - val_accuracy: 0.7753\n",
            "Epoch 2338/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.8347 - val_loss: 0.4930 - val_accuracy: 0.7753\n",
            "Epoch 2339/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4203 - accuracy: 0.8347 - val_loss: 0.4930 - val_accuracy: 0.7753\n",
            "Epoch 2340/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.8347 - val_loss: 0.4930 - val_accuracy: 0.7753\n",
            "Epoch 2341/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4202 - accuracy: 0.8347 - val_loss: 0.4930 - val_accuracy: 0.7753\n",
            "Epoch 2342/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4201 - accuracy: 0.8347 - val_loss: 0.4930 - val_accuracy: 0.7753\n",
            "Epoch 2343/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4200 - accuracy: 0.8347 - val_loss: 0.4930 - val_accuracy: 0.7753\n",
            "Epoch 2344/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.8347 - val_loss: 0.4930 - val_accuracy: 0.7753\n",
            "Epoch 2345/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.8347 - val_loss: 0.4930 - val_accuracy: 0.7753\n",
            "Epoch 2346/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4199 - accuracy: 0.8347 - val_loss: 0.4930 - val_accuracy: 0.7753\n",
            "Epoch 2347/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.8347 - val_loss: 0.4930 - val_accuracy: 0.7753\n",
            "Epoch 2348/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4197 - accuracy: 0.8347 - val_loss: 0.4930 - val_accuracy: 0.7753\n",
            "Epoch 2349/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4197 - accuracy: 0.8347 - val_loss: 0.4929 - val_accuracy: 0.7753\n",
            "Epoch 2350/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.8347 - val_loss: 0.4929 - val_accuracy: 0.7753\n",
            "Epoch 2351/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.8347 - val_loss: 0.4929 - val_accuracy: 0.7753\n",
            "Epoch 2352/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.8347 - val_loss: 0.4929 - val_accuracy: 0.7753\n",
            "Epoch 2353/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4194 - accuracy: 0.8347 - val_loss: 0.4929 - val_accuracy: 0.7753\n",
            "Epoch 2354/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4194 - accuracy: 0.8347 - val_loss: 0.4929 - val_accuracy: 0.7753\n",
            "Epoch 2355/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4193 - accuracy: 0.8347 - val_loss: 0.4929 - val_accuracy: 0.7753\n",
            "Epoch 2356/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4193 - accuracy: 0.8347 - val_loss: 0.4929 - val_accuracy: 0.7753\n",
            "Epoch 2357/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4192 - accuracy: 0.8347 - val_loss: 0.4929 - val_accuracy: 0.7753\n",
            "Epoch 2358/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.8347 - val_loss: 0.4928 - val_accuracy: 0.7753\n",
            "Epoch 2359/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.8347 - val_loss: 0.4928 - val_accuracy: 0.7753\n",
            "Epoch 2360/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4190 - accuracy: 0.8347 - val_loss: 0.4928 - val_accuracy: 0.7753\n",
            "Epoch 2361/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4190 - accuracy: 0.8347 - val_loss: 0.4928 - val_accuracy: 0.7753\n",
            "Epoch 2362/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8347 - val_loss: 0.4928 - val_accuracy: 0.7753\n",
            "Epoch 2363/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8347 - val_loss: 0.4927 - val_accuracy: 0.7753\n",
            "Epoch 2364/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4188 - accuracy: 0.8347 - val_loss: 0.4927 - val_accuracy: 0.7753\n",
            "Epoch 2365/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.8347 - val_loss: 0.4927 - val_accuracy: 0.7753\n",
            "Epoch 2366/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4187 - accuracy: 0.8347 - val_loss: 0.4926 - val_accuracy: 0.7809\n",
            "Epoch 2367/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4186 - accuracy: 0.8347 - val_loss: 0.4926 - val_accuracy: 0.7809\n",
            "Epoch 2368/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4186 - accuracy: 0.8347 - val_loss: 0.4926 - val_accuracy: 0.7809\n",
            "Epoch 2369/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8347 - val_loss: 0.4926 - val_accuracy: 0.7809\n",
            "Epoch 2370/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4185 - accuracy: 0.8347 - val_loss: 0.4926 - val_accuracy: 0.7809\n",
            "Epoch 2371/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8347 - val_loss: 0.4926 - val_accuracy: 0.7809\n",
            "Epoch 2372/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4183 - accuracy: 0.8347 - val_loss: 0.4925 - val_accuracy: 0.7809\n",
            "Epoch 2373/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8347 - val_loss: 0.4925 - val_accuracy: 0.7809\n",
            "Epoch 2374/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.8347 - val_loss: 0.4925 - val_accuracy: 0.7809\n",
            "Epoch 2375/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.8347 - val_loss: 0.4925 - val_accuracy: 0.7809\n",
            "Epoch 2376/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4181 - accuracy: 0.8347 - val_loss: 0.4925 - val_accuracy: 0.7809\n",
            "Epoch 2377/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4180 - accuracy: 0.8347 - val_loss: 0.4924 - val_accuracy: 0.7809\n",
            "Epoch 2378/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4180 - accuracy: 0.8347 - val_loss: 0.4924 - val_accuracy: 0.7809\n",
            "Epoch 2379/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8347 - val_loss: 0.4924 - val_accuracy: 0.7809\n",
            "Epoch 2380/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8347 - val_loss: 0.4924 - val_accuracy: 0.7809\n",
            "Epoch 2381/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4178 - accuracy: 0.8347 - val_loss: 0.4924 - val_accuracy: 0.7809\n",
            "Epoch 2382/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4177 - accuracy: 0.8347 - val_loss: 0.4924 - val_accuracy: 0.7809\n",
            "Epoch 2383/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.8347 - val_loss: 0.4923 - val_accuracy: 0.7809\n",
            "Epoch 2384/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4176 - accuracy: 0.8347 - val_loss: 0.4923 - val_accuracy: 0.7809\n",
            "Epoch 2385/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4176 - accuracy: 0.8347 - val_loss: 0.4923 - val_accuracy: 0.7809\n",
            "Epoch 2386/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.8347 - val_loss: 0.4923 - val_accuracy: 0.7809\n",
            "Epoch 2387/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4175 - accuracy: 0.8347 - val_loss: 0.4923 - val_accuracy: 0.7809\n",
            "Epoch 2388/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.8347 - val_loss: 0.4923 - val_accuracy: 0.7809\n",
            "Epoch 2389/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4174 - accuracy: 0.8347 - val_loss: 0.4923 - val_accuracy: 0.7809\n",
            "Epoch 2390/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.8347 - val_loss: 0.4922 - val_accuracy: 0.7809\n",
            "Epoch 2391/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4172 - accuracy: 0.8347 - val_loss: 0.4922 - val_accuracy: 0.7809\n",
            "Epoch 2392/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4172 - accuracy: 0.8347 - val_loss: 0.4922 - val_accuracy: 0.7809\n",
            "Epoch 2393/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.8347 - val_loss: 0.4922 - val_accuracy: 0.7809\n",
            "Epoch 2394/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.8347 - val_loss: 0.4922 - val_accuracy: 0.7809\n",
            "Epoch 2395/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.8347 - val_loss: 0.4922 - val_accuracy: 0.7809\n",
            "Epoch 2396/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.8347 - val_loss: 0.4922 - val_accuracy: 0.7809\n",
            "Epoch 2397/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4169 - accuracy: 0.8347 - val_loss: 0.4922 - val_accuracy: 0.7809\n",
            "Epoch 2398/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4168 - accuracy: 0.8347 - val_loss: 0.4922 - val_accuracy: 0.7753\n",
            "Epoch 2399/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4168 - accuracy: 0.8347 - val_loss: 0.4922 - val_accuracy: 0.7753\n",
            "Epoch 2400/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4167 - accuracy: 0.8347 - val_loss: 0.4921 - val_accuracy: 0.7753\n",
            "Epoch 2401/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8347 - val_loss: 0.4921 - val_accuracy: 0.7753\n",
            "Epoch 2402/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4166 - accuracy: 0.8347 - val_loss: 0.4921 - val_accuracy: 0.7753\n",
            "Epoch 2403/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4166 - accuracy: 0.8347 - val_loss: 0.4921 - val_accuracy: 0.7753\n",
            "Epoch 2404/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4165 - accuracy: 0.8347 - val_loss: 0.4921 - val_accuracy: 0.7753\n",
            "Epoch 2405/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8347 - val_loss: 0.4921 - val_accuracy: 0.7753\n",
            "Epoch 2406/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4164 - accuracy: 0.8347 - val_loss: 0.4921 - val_accuracy: 0.7753\n",
            "Epoch 2407/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4163 - accuracy: 0.8347 - val_loss: 0.4921 - val_accuracy: 0.7753\n",
            "Epoch 2408/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4163 - accuracy: 0.8347 - val_loss: 0.4921 - val_accuracy: 0.7753\n",
            "Epoch 2409/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4162 - accuracy: 0.8347 - val_loss: 0.4920 - val_accuracy: 0.7753\n",
            "Epoch 2410/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4161 - accuracy: 0.8347 - val_loss: 0.4920 - val_accuracy: 0.7753\n",
            "Epoch 2411/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4161 - accuracy: 0.8347 - val_loss: 0.4920 - val_accuracy: 0.7753\n",
            "Epoch 2412/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4160 - accuracy: 0.8347 - val_loss: 0.4920 - val_accuracy: 0.7753\n",
            "Epoch 2413/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8347 - val_loss: 0.4920 - val_accuracy: 0.7753\n",
            "Epoch 2414/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4159 - accuracy: 0.8347 - val_loss: 0.4920 - val_accuracy: 0.7753\n",
            "Epoch 2415/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8347 - val_loss: 0.4920 - val_accuracy: 0.7753\n",
            "Epoch 2416/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4158 - accuracy: 0.8347 - val_loss: 0.4920 - val_accuracy: 0.7753\n",
            "Epoch 2417/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4157 - accuracy: 0.8347 - val_loss: 0.4920 - val_accuracy: 0.7753\n",
            "Epoch 2418/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4157 - accuracy: 0.8347 - val_loss: 0.4920 - val_accuracy: 0.7753\n",
            "Epoch 2419/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4156 - accuracy: 0.8347 - val_loss: 0.4919 - val_accuracy: 0.7753\n",
            "Epoch 2420/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4156 - accuracy: 0.8347 - val_loss: 0.4919 - val_accuracy: 0.7753\n",
            "Epoch 2421/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.8347 - val_loss: 0.4919 - val_accuracy: 0.7753\n",
            "Epoch 2422/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4155 - accuracy: 0.8347 - val_loss: 0.4919 - val_accuracy: 0.7753\n",
            "Epoch 2423/4000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4154 - accuracy: 0.8347 - val_loss: 0.4918 - val_accuracy: 0.7753\n",
            "Epoch 2424/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8347 - val_loss: 0.4918 - val_accuracy: 0.7753\n",
            "Epoch 2425/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4153 - accuracy: 0.8347 - val_loss: 0.4918 - val_accuracy: 0.7753\n",
            "Epoch 2426/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8347 - val_loss: 0.4918 - val_accuracy: 0.7753\n",
            "Epoch 2427/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4152 - accuracy: 0.8347 - val_loss: 0.4918 - val_accuracy: 0.7753\n",
            "Epoch 2428/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4151 - accuracy: 0.8347 - val_loss: 0.4918 - val_accuracy: 0.7753\n",
            "Epoch 2429/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4150 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2430/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4150 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2431/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4149 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2432/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2433/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4148 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2434/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4148 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2435/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4147 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2436/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2437/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4146 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2438/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4146 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2439/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4145 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2440/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2441/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4144 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2442/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2443/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4143 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2444/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2445/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4142 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2446/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2447/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4141 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2448/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4140 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2449/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4140 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2450/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4139 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2451/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4138 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2452/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2453/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4137 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2454/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2455/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2456/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4136 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2457/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2458/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2459/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4134 - accuracy: 0.8347 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2460/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4133 - accuracy: 0.8319 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2461/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4133 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2462/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2463/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4132 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2464/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4131 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2465/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4131 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2466/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2467/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4130 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2468/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2469/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2470/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2471/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4128 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2472/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4127 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2473/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4127 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2474/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4126 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2475/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2476/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2477/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4125 - accuracy: 0.8291 - val_loss: 0.4918 - val_accuracy: 0.7753\n",
            "Epoch 2478/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8291 - val_loss: 0.4918 - val_accuracy: 0.7753\n",
            "Epoch 2479/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4124 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2480/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4123 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2481/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2482/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2483/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2484/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4121 - accuracy: 0.8291 - val_loss: 0.4917 - val_accuracy: 0.7753\n",
            "Epoch 2485/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.8263 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2486/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4120 - accuracy: 0.8263 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2487/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8263 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2488/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8263 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2489/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8263 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2490/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8263 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2491/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8263 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2492/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4117 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2493/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4116 - accuracy: 0.8291 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2494/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8291 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2495/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4115 - accuracy: 0.8291 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2496/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4115 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2497/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2498/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2499/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2500/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4113 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2501/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2502/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2503/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2504/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4110 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2505/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4110 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2506/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2507/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4109 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2508/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2509/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4108 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2510/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2511/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4107 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2512/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4106 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2513/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2514/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4105 - accuracy: 0.8291 - val_loss: 0.4916 - val_accuracy: 0.7753\n",
            "Epoch 2515/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8291 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2516/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8291 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2517/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8291 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2518/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8291 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2519/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4103 - accuracy: 0.8291 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2520/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4102 - accuracy: 0.8291 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2521/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4102 - accuracy: 0.8291 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2522/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4101 - accuracy: 0.8291 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2523/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4101 - accuracy: 0.8291 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2524/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4100 - accuracy: 0.8319 - val_loss: 0.4914 - val_accuracy: 0.7753\n",
            "Epoch 2525/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4100 - accuracy: 0.8319 - val_loss: 0.4914 - val_accuracy: 0.7753\n",
            "Epoch 2526/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4099 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2527/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4099 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2528/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4098 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2529/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4098 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2530/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2531/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4097 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2532/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2533/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4096 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2534/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4095 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2535/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4095 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2536/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2537/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4094 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2538/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4093 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2539/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4093 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2540/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4092 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2541/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4092 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2542/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4091 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2543/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4091 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2544/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2545/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4090 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2546/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2547/4000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4089 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2548/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4088 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2549/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4088 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2550/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2551/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2552/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4086 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2553/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4086 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2554/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4085 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2555/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2556/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4084 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2557/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4084 - accuracy: 0.8319 - val_loss: 0.4914 - val_accuracy: 0.7753\n",
            "Epoch 2558/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4083 - accuracy: 0.8319 - val_loss: 0.4914 - val_accuracy: 0.7753\n",
            "Epoch 2559/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4083 - accuracy: 0.8319 - val_loss: 0.4914 - val_accuracy: 0.7753\n",
            "Epoch 2560/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4082 - accuracy: 0.8319 - val_loss: 0.4914 - val_accuracy: 0.7753\n",
            "Epoch 2561/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4082 - accuracy: 0.8319 - val_loss: 0.4914 - val_accuracy: 0.7753\n",
            "Epoch 2562/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4081 - accuracy: 0.8319 - val_loss: 0.4914 - val_accuracy: 0.7753\n",
            "Epoch 2563/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4081 - accuracy: 0.8319 - val_loss: 0.4914 - val_accuracy: 0.7753\n",
            "Epoch 2564/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4080 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2565/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4080 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2566/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4079 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2567/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4079 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2568/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4078 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2569/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4078 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2570/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4077 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2571/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4077 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2572/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4076 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2573/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4075 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2574/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2575/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4074 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2576/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4074 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2577/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4073 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2578/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4073 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2579/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4072 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2580/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4072 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2581/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4071 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2582/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2583/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4070 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2584/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4070 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2585/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2586/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4069 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2587/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4068 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2588/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4068 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2589/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2590/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4067 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2591/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4066 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2592/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4066 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2593/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4065 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2594/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4065 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2595/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4064 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2596/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4064 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2597/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2598/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2599/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4062 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2600/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4062 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2601/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4061 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2602/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2603/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4060 - accuracy: 0.8319 - val_loss: 0.4915 - val_accuracy: 0.7753\n",
            "Epoch 2604/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4060 - accuracy: 0.8319 - val_loss: 0.4914 - val_accuracy: 0.7753\n",
            "Epoch 2605/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8319 - val_loss: 0.4914 - val_accuracy: 0.7753\n",
            "Epoch 2606/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4059 - accuracy: 0.8319 - val_loss: 0.4914 - val_accuracy: 0.7753\n",
            "Epoch 2607/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4058 - accuracy: 0.8319 - val_loss: 0.4914 - val_accuracy: 0.7753\n",
            "Epoch 2608/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8319 - val_loss: 0.4914 - val_accuracy: 0.7753\n",
            "Epoch 2609/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.8319 - val_loss: 0.4914 - val_accuracy: 0.7753\n",
            "Epoch 2610/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8319 - val_loss: 0.4914 - val_accuracy: 0.7753\n",
            "Epoch 2611/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8319 - val_loss: 0.4914 - val_accuracy: 0.7753\n",
            "Epoch 2612/4000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4055 - accuracy: 0.8319 - val_loss: 0.4914 - val_accuracy: 0.7753\n",
            "Epoch 2613/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4055 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2614/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4054 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2615/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4054 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2616/4000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.4053 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2617/4000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.4052 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2618/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2619/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4051 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2620/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4051 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2621/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2622/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4050 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2623/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2624/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4048 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2625/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4048 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2626/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2627/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4046 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2628/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4046 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2629/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4045 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2630/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4045 - accuracy: 0.8319 - val_loss: 0.4912 - val_accuracy: 0.7753\n",
            "Epoch 2631/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4044 - accuracy: 0.8319 - val_loss: 0.4912 - val_accuracy: 0.7753\n",
            "Epoch 2632/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4044 - accuracy: 0.8319 - val_loss: 0.4912 - val_accuracy: 0.7753\n",
            "Epoch 2633/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4043 - accuracy: 0.8319 - val_loss: 0.4912 - val_accuracy: 0.7753\n",
            "Epoch 2634/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4043 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2635/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4042 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2636/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4041 - accuracy: 0.8319 - val_loss: 0.4913 - val_accuracy: 0.7753\n",
            "Epoch 2637/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4041 - accuracy: 0.8319 - val_loss: 0.4912 - val_accuracy: 0.7753\n",
            "Epoch 2638/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4040 - accuracy: 0.8319 - val_loss: 0.4912 - val_accuracy: 0.7753\n",
            "Epoch 2639/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4040 - accuracy: 0.8319 - val_loss: 0.4912 - val_accuracy: 0.7753\n",
            "Epoch 2640/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.8319 - val_loss: 0.4912 - val_accuracy: 0.7753\n",
            "Epoch 2641/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4039 - accuracy: 0.8347 - val_loss: 0.4912 - val_accuracy: 0.7753\n",
            "Epoch 2642/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4038 - accuracy: 0.8347 - val_loss: 0.4912 - val_accuracy: 0.7753\n",
            "Epoch 2643/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4038 - accuracy: 0.8347 - val_loss: 0.4912 - val_accuracy: 0.7753\n",
            "Epoch 2644/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4037 - accuracy: 0.8347 - val_loss: 0.4912 - val_accuracy: 0.7753\n",
            "Epoch 2645/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4037 - accuracy: 0.8347 - val_loss: 0.4912 - val_accuracy: 0.7753\n",
            "Epoch 2646/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8347 - val_loss: 0.4912 - val_accuracy: 0.7753\n",
            "Epoch 2647/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4035 - accuracy: 0.8347 - val_loss: 0.4911 - val_accuracy: 0.7753\n",
            "Epoch 2648/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4035 - accuracy: 0.8319 - val_loss: 0.4910 - val_accuracy: 0.7809\n",
            "Epoch 2649/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4034 - accuracy: 0.8319 - val_loss: 0.4910 - val_accuracy: 0.7809\n",
            "Epoch 2650/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8319 - val_loss: 0.4910 - val_accuracy: 0.7809\n",
            "Epoch 2651/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4033 - accuracy: 0.8319 - val_loss: 0.4910 - val_accuracy: 0.7809\n",
            "Epoch 2652/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4033 - accuracy: 0.8319 - val_loss: 0.4910 - val_accuracy: 0.7809\n",
            "Epoch 2653/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4032 - accuracy: 0.8319 - val_loss: 0.4910 - val_accuracy: 0.7809\n",
            "Epoch 2654/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4032 - accuracy: 0.8319 - val_loss: 0.4910 - val_accuracy: 0.7809\n",
            "Epoch 2655/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.8319 - val_loss: 0.4910 - val_accuracy: 0.7809\n",
            "Epoch 2656/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4031 - accuracy: 0.8319 - val_loss: 0.4909 - val_accuracy: 0.7809\n",
            "Epoch 2657/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4030 - accuracy: 0.8319 - val_loss: 0.4909 - val_accuracy: 0.7809\n",
            "Epoch 2658/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4030 - accuracy: 0.8319 - val_loss: 0.4909 - val_accuracy: 0.7809\n",
            "Epoch 2659/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4029 - accuracy: 0.8319 - val_loss: 0.4909 - val_accuracy: 0.7809\n",
            "Epoch 2660/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4029 - accuracy: 0.8319 - val_loss: 0.4909 - val_accuracy: 0.7809\n",
            "Epoch 2661/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4028 - accuracy: 0.8319 - val_loss: 0.4908 - val_accuracy: 0.7809\n",
            "Epoch 2662/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8319 - val_loss: 0.4909 - val_accuracy: 0.7809\n",
            "Epoch 2663/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4027 - accuracy: 0.8319 - val_loss: 0.4908 - val_accuracy: 0.7809\n",
            "Epoch 2664/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4027 - accuracy: 0.8319 - val_loss: 0.4908 - val_accuracy: 0.7809\n",
            "Epoch 2665/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4026 - accuracy: 0.8319 - val_loss: 0.4908 - val_accuracy: 0.7809\n",
            "Epoch 2666/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4026 - accuracy: 0.8319 - val_loss: 0.4908 - val_accuracy: 0.7809\n",
            "Epoch 2667/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4025 - accuracy: 0.8319 - val_loss: 0.4907 - val_accuracy: 0.7809\n",
            "Epoch 2668/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4024 - accuracy: 0.8319 - val_loss: 0.4907 - val_accuracy: 0.7809\n",
            "Epoch 2669/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4024 - accuracy: 0.8319 - val_loss: 0.4907 - val_accuracy: 0.7809\n",
            "Epoch 2670/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8319 - val_loss: 0.4907 - val_accuracy: 0.7809\n",
            "Epoch 2671/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4023 - accuracy: 0.8319 - val_loss: 0.4906 - val_accuracy: 0.7809\n",
            "Epoch 2672/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4022 - accuracy: 0.8319 - val_loss: 0.4906 - val_accuracy: 0.7809\n",
            "Epoch 2673/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4022 - accuracy: 0.8319 - val_loss: 0.4906 - val_accuracy: 0.7809\n",
            "Epoch 2674/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4021 - accuracy: 0.8319 - val_loss: 0.4906 - val_accuracy: 0.7809\n",
            "Epoch 2675/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4021 - accuracy: 0.8319 - val_loss: 0.4906 - val_accuracy: 0.7809\n",
            "Epoch 2676/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4020 - accuracy: 0.8319 - val_loss: 0.4906 - val_accuracy: 0.7809\n",
            "Epoch 2677/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4020 - accuracy: 0.8319 - val_loss: 0.4906 - val_accuracy: 0.7809\n",
            "Epoch 2678/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.8319 - val_loss: 0.4906 - val_accuracy: 0.7809\n",
            "Epoch 2679/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4019 - accuracy: 0.8319 - val_loss: 0.4906 - val_accuracy: 0.7809\n",
            "Epoch 2680/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4018 - accuracy: 0.8319 - val_loss: 0.4905 - val_accuracy: 0.7809\n",
            "Epoch 2681/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4018 - accuracy: 0.8319 - val_loss: 0.4905 - val_accuracy: 0.7809\n",
            "Epoch 2682/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4017 - accuracy: 0.8319 - val_loss: 0.4905 - val_accuracy: 0.7809\n",
            "Epoch 2683/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4017 - accuracy: 0.8319 - val_loss: 0.4905 - val_accuracy: 0.7809\n",
            "Epoch 2684/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4016 - accuracy: 0.8319 - val_loss: 0.4905 - val_accuracy: 0.7809\n",
            "Epoch 2685/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4016 - accuracy: 0.8319 - val_loss: 0.4905 - val_accuracy: 0.7809\n",
            "Epoch 2686/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.8319 - val_loss: 0.4905 - val_accuracy: 0.7809\n",
            "Epoch 2687/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.8319 - val_loss: 0.4905 - val_accuracy: 0.7809\n",
            "Epoch 2688/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4014 - accuracy: 0.8319 - val_loss: 0.4905 - val_accuracy: 0.7809\n",
            "Epoch 2689/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4014 - accuracy: 0.8319 - val_loss: 0.4904 - val_accuracy: 0.7809\n",
            "Epoch 2690/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4013 - accuracy: 0.8319 - val_loss: 0.4904 - val_accuracy: 0.7809\n",
            "Epoch 2691/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.8319 - val_loss: 0.4904 - val_accuracy: 0.7809\n",
            "Epoch 2692/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4012 - accuracy: 0.8319 - val_loss: 0.4904 - val_accuracy: 0.7809\n",
            "Epoch 2693/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8319 - val_loss: 0.4904 - val_accuracy: 0.7809\n",
            "Epoch 2694/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.8319 - val_loss: 0.4904 - val_accuracy: 0.7809\n",
            "Epoch 2695/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.8319 - val_loss: 0.4903 - val_accuracy: 0.7809\n",
            "Epoch 2696/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8319 - val_loss: 0.4903 - val_accuracy: 0.7809\n",
            "Epoch 2697/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8319 - val_loss: 0.4903 - val_accuracy: 0.7809\n",
            "Epoch 2698/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4009 - accuracy: 0.8319 - val_loss: 0.4903 - val_accuracy: 0.7809\n",
            "Epoch 2699/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4009 - accuracy: 0.8319 - val_loss: 0.4903 - val_accuracy: 0.7809\n",
            "Epoch 2700/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4008 - accuracy: 0.8319 - val_loss: 0.4903 - val_accuracy: 0.7809\n",
            "Epoch 2701/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4007 - accuracy: 0.8319 - val_loss: 0.4903 - val_accuracy: 0.7809\n",
            "Epoch 2702/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8319 - val_loss: 0.4902 - val_accuracy: 0.7809\n",
            "Epoch 2703/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8319 - val_loss: 0.4902 - val_accuracy: 0.7809\n",
            "Epoch 2704/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.8319 - val_loss: 0.4902 - val_accuracy: 0.7809\n",
            "Epoch 2705/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.8319 - val_loss: 0.4901 - val_accuracy: 0.7809\n",
            "Epoch 2706/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8319 - val_loss: 0.4901 - val_accuracy: 0.7809\n",
            "Epoch 2707/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4004 - accuracy: 0.8319 - val_loss: 0.4901 - val_accuracy: 0.7809\n",
            "Epoch 2708/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4003 - accuracy: 0.8319 - val_loss: 0.4901 - val_accuracy: 0.7809\n",
            "Epoch 2709/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8319 - val_loss: 0.4900 - val_accuracy: 0.7809\n",
            "Epoch 2710/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4002 - accuracy: 0.8319 - val_loss: 0.4900 - val_accuracy: 0.7809\n",
            "Epoch 2711/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4002 - accuracy: 0.8319 - val_loss: 0.4900 - val_accuracy: 0.7809\n",
            "Epoch 2712/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4001 - accuracy: 0.8319 - val_loss: 0.4900 - val_accuracy: 0.7809\n",
            "Epoch 2713/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.4000 - accuracy: 0.8319 - val_loss: 0.4900 - val_accuracy: 0.7809\n",
            "Epoch 2714/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.4000 - accuracy: 0.8319 - val_loss: 0.4900 - val_accuracy: 0.7809\n",
            "Epoch 2715/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3999 - accuracy: 0.8319 - val_loss: 0.4899 - val_accuracy: 0.7809\n",
            "Epoch 2716/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3999 - accuracy: 0.8319 - val_loss: 0.4899 - val_accuracy: 0.7809\n",
            "Epoch 2717/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3998 - accuracy: 0.8319 - val_loss: 0.4899 - val_accuracy: 0.7809\n",
            "Epoch 2718/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3997 - accuracy: 0.8319 - val_loss: 0.4899 - val_accuracy: 0.7809\n",
            "Epoch 2719/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3996 - accuracy: 0.8319 - val_loss: 0.4898 - val_accuracy: 0.7809\n",
            "Epoch 2720/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3996 - accuracy: 0.8319 - val_loss: 0.4898 - val_accuracy: 0.7809\n",
            "Epoch 2721/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3995 - accuracy: 0.8319 - val_loss: 0.4898 - val_accuracy: 0.7809\n",
            "Epoch 2722/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8319 - val_loss: 0.4898 - val_accuracy: 0.7809\n",
            "Epoch 2723/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3994 - accuracy: 0.8319 - val_loss: 0.4898 - val_accuracy: 0.7809\n",
            "Epoch 2724/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3994 - accuracy: 0.8319 - val_loss: 0.4898 - val_accuracy: 0.7809\n",
            "Epoch 2725/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3993 - accuracy: 0.8319 - val_loss: 0.4897 - val_accuracy: 0.7809\n",
            "Epoch 2726/4000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3992 - accuracy: 0.8319 - val_loss: 0.4897 - val_accuracy: 0.7809\n",
            "Epoch 2727/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3992 - accuracy: 0.8319 - val_loss: 0.4897 - val_accuracy: 0.7809\n",
            "Epoch 2728/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8319 - val_loss: 0.4897 - val_accuracy: 0.7809\n",
            "Epoch 2729/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3991 - accuracy: 0.8319 - val_loss: 0.4897 - val_accuracy: 0.7809\n",
            "Epoch 2730/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8319 - val_loss: 0.4897 - val_accuracy: 0.7809\n",
            "Epoch 2731/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8319 - val_loss: 0.4896 - val_accuracy: 0.7809\n",
            "Epoch 2732/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8319 - val_loss: 0.4896 - val_accuracy: 0.7809\n",
            "Epoch 2733/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8319 - val_loss: 0.4896 - val_accuracy: 0.7809\n",
            "Epoch 2734/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8319 - val_loss: 0.4896 - val_accuracy: 0.7809\n",
            "Epoch 2735/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8319 - val_loss: 0.4895 - val_accuracy: 0.7809\n",
            "Epoch 2736/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8319 - val_loss: 0.4895 - val_accuracy: 0.7809\n",
            "Epoch 2737/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3986 - accuracy: 0.8319 - val_loss: 0.4895 - val_accuracy: 0.7809\n",
            "Epoch 2738/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3985 - accuracy: 0.8319 - val_loss: 0.4895 - val_accuracy: 0.7809\n",
            "Epoch 2739/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3985 - accuracy: 0.8319 - val_loss: 0.4895 - val_accuracy: 0.7809\n",
            "Epoch 2740/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3984 - accuracy: 0.8319 - val_loss: 0.4895 - val_accuracy: 0.7809\n",
            "Epoch 2741/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3984 - accuracy: 0.8319 - val_loss: 0.4895 - val_accuracy: 0.7865\n",
            "Epoch 2742/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3983 - accuracy: 0.8319 - val_loss: 0.4895 - val_accuracy: 0.7865\n",
            "Epoch 2743/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3982 - accuracy: 0.8319 - val_loss: 0.4894 - val_accuracy: 0.7865\n",
            "Epoch 2744/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3982 - accuracy: 0.8319 - val_loss: 0.4894 - val_accuracy: 0.7865\n",
            "Epoch 2745/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3981 - accuracy: 0.8319 - val_loss: 0.4894 - val_accuracy: 0.7865\n",
            "Epoch 2746/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3981 - accuracy: 0.8319 - val_loss: 0.4893 - val_accuracy: 0.7865\n",
            "Epoch 2747/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3980 - accuracy: 0.8319 - val_loss: 0.4893 - val_accuracy: 0.7865\n",
            "Epoch 2748/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3979 - accuracy: 0.8319 - val_loss: 0.4893 - val_accuracy: 0.7865\n",
            "Epoch 2749/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3979 - accuracy: 0.8319 - val_loss: 0.4893 - val_accuracy: 0.7865\n",
            "Epoch 2750/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8319 - val_loss: 0.4892 - val_accuracy: 0.7865\n",
            "Epoch 2751/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3978 - accuracy: 0.8319 - val_loss: 0.4892 - val_accuracy: 0.7865\n",
            "Epoch 2752/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8319 - val_loss: 0.4892 - val_accuracy: 0.7865\n",
            "Epoch 2753/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3976 - accuracy: 0.8319 - val_loss: 0.4891 - val_accuracy: 0.7865\n",
            "Epoch 2754/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3976 - accuracy: 0.8319 - val_loss: 0.4891 - val_accuracy: 0.7865\n",
            "Epoch 2755/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3975 - accuracy: 0.8319 - val_loss: 0.4891 - val_accuracy: 0.7865\n",
            "Epoch 2756/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3975 - accuracy: 0.8319 - val_loss: 0.4891 - val_accuracy: 0.7809\n",
            "Epoch 2757/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.8319 - val_loss: 0.4891 - val_accuracy: 0.7865\n",
            "Epoch 2758/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.8319 - val_loss: 0.4891 - val_accuracy: 0.7865\n",
            "Epoch 2759/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.8319 - val_loss: 0.4891 - val_accuracy: 0.7865\n",
            "Epoch 2760/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3972 - accuracy: 0.8319 - val_loss: 0.4891 - val_accuracy: 0.7865\n",
            "Epoch 2761/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3972 - accuracy: 0.8319 - val_loss: 0.4890 - val_accuracy: 0.7809\n",
            "Epoch 2762/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8319 - val_loss: 0.4890 - val_accuracy: 0.7865\n",
            "Epoch 2763/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8319 - val_loss: 0.4890 - val_accuracy: 0.7865\n",
            "Epoch 2764/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3970 - accuracy: 0.8319 - val_loss: 0.4889 - val_accuracy: 0.7865\n",
            "Epoch 2765/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3970 - accuracy: 0.8319 - val_loss: 0.4889 - val_accuracy: 0.7865\n",
            "Epoch 2766/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8319 - val_loss: 0.4889 - val_accuracy: 0.7865\n",
            "Epoch 2767/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.8319 - val_loss: 0.4889 - val_accuracy: 0.7809\n",
            "Epoch 2768/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.8319 - val_loss: 0.4889 - val_accuracy: 0.7809\n",
            "Epoch 2769/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8319 - val_loss: 0.4889 - val_accuracy: 0.7809\n",
            "Epoch 2770/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8319 - val_loss: 0.4888 - val_accuracy: 0.7809\n",
            "Epoch 2771/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8319 - val_loss: 0.4888 - val_accuracy: 0.7809\n",
            "Epoch 2772/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3965 - accuracy: 0.8319 - val_loss: 0.4888 - val_accuracy: 0.7809\n",
            "Epoch 2773/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8319 - val_loss: 0.4887 - val_accuracy: 0.7809\n",
            "Epoch 2774/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8319 - val_loss: 0.4887 - val_accuracy: 0.7809\n",
            "Epoch 2775/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8319 - val_loss: 0.4887 - val_accuracy: 0.7809\n",
            "Epoch 2776/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8319 - val_loss: 0.4886 - val_accuracy: 0.7809\n",
            "Epoch 2777/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8319 - val_loss: 0.4886 - val_accuracy: 0.7809\n",
            "Epoch 2778/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8319 - val_loss: 0.4885 - val_accuracy: 0.7809\n",
            "Epoch 2779/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8319 - val_loss: 0.4885 - val_accuracy: 0.7809\n",
            "Epoch 2780/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8319 - val_loss: 0.4885 - val_accuracy: 0.7809\n",
            "Epoch 2781/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8319 - val_loss: 0.4884 - val_accuracy: 0.7809\n",
            "Epoch 2782/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8319 - val_loss: 0.4884 - val_accuracy: 0.7809\n",
            "Epoch 2783/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8319 - val_loss: 0.4884 - val_accuracy: 0.7809\n",
            "Epoch 2784/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3958 - accuracy: 0.8319 - val_loss: 0.4884 - val_accuracy: 0.7809\n",
            "Epoch 2785/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8319 - val_loss: 0.4883 - val_accuracy: 0.7809\n",
            "Epoch 2786/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.8319 - val_loss: 0.4883 - val_accuracy: 0.7809\n",
            "Epoch 2787/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.8319 - val_loss: 0.4883 - val_accuracy: 0.7809\n",
            "Epoch 2788/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8319 - val_loss: 0.4882 - val_accuracy: 0.7809\n",
            "Epoch 2789/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8319 - val_loss: 0.4882 - val_accuracy: 0.7809\n",
            "Epoch 2790/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3954 - accuracy: 0.8319 - val_loss: 0.4882 - val_accuracy: 0.7809\n",
            "Epoch 2791/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3953 - accuracy: 0.8319 - val_loss: 0.4881 - val_accuracy: 0.7809\n",
            "Epoch 2792/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8347 - val_loss: 0.4881 - val_accuracy: 0.7809\n",
            "Epoch 2793/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3951 - accuracy: 0.8347 - val_loss: 0.4881 - val_accuracy: 0.7809\n",
            "Epoch 2794/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3951 - accuracy: 0.8347 - val_loss: 0.4881 - val_accuracy: 0.7809\n",
            "Epoch 2795/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3950 - accuracy: 0.8347 - val_loss: 0.4881 - val_accuracy: 0.7809\n",
            "Epoch 2796/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3949 - accuracy: 0.8347 - val_loss: 0.4881 - val_accuracy: 0.7809\n",
            "Epoch 2797/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3949 - accuracy: 0.8347 - val_loss: 0.4880 - val_accuracy: 0.7809\n",
            "Epoch 2798/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8347 - val_loss: 0.4880 - val_accuracy: 0.7809\n",
            "Epoch 2799/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3947 - accuracy: 0.8347 - val_loss: 0.4880 - val_accuracy: 0.7809\n",
            "Epoch 2800/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8347 - val_loss: 0.4880 - val_accuracy: 0.7809\n",
            "Epoch 2801/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8347 - val_loss: 0.4879 - val_accuracy: 0.7809\n",
            "Epoch 2802/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3945 - accuracy: 0.8347 - val_loss: 0.4879 - val_accuracy: 0.7809\n",
            "Epoch 2803/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3945 - accuracy: 0.8347 - val_loss: 0.4879 - val_accuracy: 0.7809\n",
            "Epoch 2804/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3944 - accuracy: 0.8347 - val_loss: 0.4879 - val_accuracy: 0.7809\n",
            "Epoch 2805/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3943 - accuracy: 0.8347 - val_loss: 0.4878 - val_accuracy: 0.7809\n",
            "Epoch 2806/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8347 - val_loss: 0.4878 - val_accuracy: 0.7809\n",
            "Epoch 2807/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3941 - accuracy: 0.8347 - val_loss: 0.4878 - val_accuracy: 0.7809\n",
            "Epoch 2808/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3941 - accuracy: 0.8347 - val_loss: 0.4877 - val_accuracy: 0.7809\n",
            "Epoch 2809/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8347 - val_loss: 0.4877 - val_accuracy: 0.7809\n",
            "Epoch 2810/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8347 - val_loss: 0.4877 - val_accuracy: 0.7809\n",
            "Epoch 2811/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8347 - val_loss: 0.4877 - val_accuracy: 0.7809\n",
            "Epoch 2812/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3938 - accuracy: 0.8347 - val_loss: 0.4876 - val_accuracy: 0.7809\n",
            "Epoch 2813/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3937 - accuracy: 0.8347 - val_loss: 0.4876 - val_accuracy: 0.7809\n",
            "Epoch 2814/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3937 - accuracy: 0.8347 - val_loss: 0.4876 - val_accuracy: 0.7809\n",
            "Epoch 2815/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3936 - accuracy: 0.8347 - val_loss: 0.4876 - val_accuracy: 0.7809\n",
            "Epoch 2816/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8347 - val_loss: 0.4876 - val_accuracy: 0.7809\n",
            "Epoch 2817/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8347 - val_loss: 0.4875 - val_accuracy: 0.7809\n",
            "Epoch 2818/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8347 - val_loss: 0.4875 - val_accuracy: 0.7809\n",
            "Epoch 2819/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8347 - val_loss: 0.4875 - val_accuracy: 0.7809\n",
            "Epoch 2820/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3933 - accuracy: 0.8347 - val_loss: 0.4875 - val_accuracy: 0.7809\n",
            "Epoch 2821/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8347 - val_loss: 0.4875 - val_accuracy: 0.7809\n",
            "Epoch 2822/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8347 - val_loss: 0.4875 - val_accuracy: 0.7809\n",
            "Epoch 2823/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8347 - val_loss: 0.4874 - val_accuracy: 0.7809\n",
            "Epoch 2824/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8347 - val_loss: 0.4874 - val_accuracy: 0.7809\n",
            "Epoch 2825/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8347 - val_loss: 0.4874 - val_accuracy: 0.7809\n",
            "Epoch 2826/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3929 - accuracy: 0.8347 - val_loss: 0.4874 - val_accuracy: 0.7809\n",
            "Epoch 2827/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3928 - accuracy: 0.8347 - val_loss: 0.4874 - val_accuracy: 0.7809\n",
            "Epoch 2828/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8347 - val_loss: 0.4874 - val_accuracy: 0.7809\n",
            "Epoch 2829/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3927 - accuracy: 0.8347 - val_loss: 0.4873 - val_accuracy: 0.7809\n",
            "Epoch 2830/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3926 - accuracy: 0.8347 - val_loss: 0.4873 - val_accuracy: 0.7809\n",
            "Epoch 2831/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3926 - accuracy: 0.8347 - val_loss: 0.4873 - val_accuracy: 0.7809\n",
            "Epoch 2832/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3925 - accuracy: 0.8347 - val_loss: 0.4873 - val_accuracy: 0.7809\n",
            "Epoch 2833/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8347 - val_loss: 0.4873 - val_accuracy: 0.7809\n",
            "Epoch 2834/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.8347 - val_loss: 0.4873 - val_accuracy: 0.7809\n",
            "Epoch 2835/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3923 - accuracy: 0.8347 - val_loss: 0.4872 - val_accuracy: 0.7809\n",
            "Epoch 2836/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8347 - val_loss: 0.4872 - val_accuracy: 0.7809\n",
            "Epoch 2837/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3922 - accuracy: 0.8347 - val_loss: 0.4872 - val_accuracy: 0.7809\n",
            "Epoch 2838/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.8347 - val_loss: 0.4872 - val_accuracy: 0.7809\n",
            "Epoch 2839/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3920 - accuracy: 0.8347 - val_loss: 0.4872 - val_accuracy: 0.7809\n",
            "Epoch 2840/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8347 - val_loss: 0.4872 - val_accuracy: 0.7809\n",
            "Epoch 2841/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8347 - val_loss: 0.4871 - val_accuracy: 0.7809\n",
            "Epoch 2842/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8347 - val_loss: 0.4871 - val_accuracy: 0.7809\n",
            "Epoch 2843/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8347 - val_loss: 0.4870 - val_accuracy: 0.7809\n",
            "Epoch 2844/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.8347 - val_loss: 0.4870 - val_accuracy: 0.7809\n",
            "Epoch 2845/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.8347 - val_loss: 0.4870 - val_accuracy: 0.7809\n",
            "Epoch 2846/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.8347 - val_loss: 0.4870 - val_accuracy: 0.7809\n",
            "Epoch 2847/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8347 - val_loss: 0.4870 - val_accuracy: 0.7809\n",
            "Epoch 2848/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.8347 - val_loss: 0.4870 - val_accuracy: 0.7809\n",
            "Epoch 2849/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.8347 - val_loss: 0.4869 - val_accuracy: 0.7809\n",
            "Epoch 2850/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3913 - accuracy: 0.8347 - val_loss: 0.4869 - val_accuracy: 0.7809\n",
            "Epoch 2851/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3912 - accuracy: 0.8347 - val_loss: 0.4868 - val_accuracy: 0.7809\n",
            "Epoch 2852/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3912 - accuracy: 0.8347 - val_loss: 0.4868 - val_accuracy: 0.7809\n",
            "Epoch 2853/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3911 - accuracy: 0.8347 - val_loss: 0.4867 - val_accuracy: 0.7809\n",
            "Epoch 2854/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.8347 - val_loss: 0.4867 - val_accuracy: 0.7809\n",
            "Epoch 2855/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3910 - accuracy: 0.8347 - val_loss: 0.4867 - val_accuracy: 0.7809\n",
            "Epoch 2856/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3909 - accuracy: 0.8347 - val_loss: 0.4867 - val_accuracy: 0.7809\n",
            "Epoch 2857/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8347 - val_loss: 0.4867 - val_accuracy: 0.7809\n",
            "Epoch 2858/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3908 - accuracy: 0.8347 - val_loss: 0.4867 - val_accuracy: 0.7809\n",
            "Epoch 2859/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3907 - accuracy: 0.8347 - val_loss: 0.4866 - val_accuracy: 0.7809\n",
            "Epoch 2860/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3907 - accuracy: 0.8347 - val_loss: 0.4866 - val_accuracy: 0.7809\n",
            "Epoch 2861/4000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3906 - accuracy: 0.8347 - val_loss: 0.4866 - val_accuracy: 0.7809\n",
            "Epoch 2862/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3905 - accuracy: 0.8347 - val_loss: 0.4865 - val_accuracy: 0.7809\n",
            "Epoch 2863/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3905 - accuracy: 0.8347 - val_loss: 0.4865 - val_accuracy: 0.7809\n",
            "Epoch 2864/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3904 - accuracy: 0.8347 - val_loss: 0.4865 - val_accuracy: 0.7809\n",
            "Epoch 2865/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3903 - accuracy: 0.8347 - val_loss: 0.4865 - val_accuracy: 0.7809\n",
            "Epoch 2866/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3903 - accuracy: 0.8347 - val_loss: 0.4864 - val_accuracy: 0.7809\n",
            "Epoch 2867/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3902 - accuracy: 0.8347 - val_loss: 0.4864 - val_accuracy: 0.7809\n",
            "Epoch 2868/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3901 - accuracy: 0.8347 - val_loss: 0.4864 - val_accuracy: 0.7809\n",
            "Epoch 2869/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3901 - accuracy: 0.8347 - val_loss: 0.4863 - val_accuracy: 0.7809\n",
            "Epoch 2870/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3900 - accuracy: 0.8347 - val_loss: 0.4863 - val_accuracy: 0.7809\n",
            "Epoch 2871/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3899 - accuracy: 0.8347 - val_loss: 0.4863 - val_accuracy: 0.7809\n",
            "Epoch 2872/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3899 - accuracy: 0.8347 - val_loss: 0.4863 - val_accuracy: 0.7809\n",
            "Epoch 2873/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3898 - accuracy: 0.8347 - val_loss: 0.4862 - val_accuracy: 0.7809\n",
            "Epoch 2874/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.8347 - val_loss: 0.4862 - val_accuracy: 0.7809\n",
            "Epoch 2875/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3896 - accuracy: 0.8347 - val_loss: 0.4862 - val_accuracy: 0.7809\n",
            "Epoch 2876/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3896 - accuracy: 0.8347 - val_loss: 0.4861 - val_accuracy: 0.7809\n",
            "Epoch 2877/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3895 - accuracy: 0.8347 - val_loss: 0.4861 - val_accuracy: 0.7809\n",
            "Epoch 2878/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3895 - accuracy: 0.8347 - val_loss: 0.4861 - val_accuracy: 0.7809\n",
            "Epoch 2879/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8347 - val_loss: 0.4861 - val_accuracy: 0.7809\n",
            "Epoch 2880/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3893 - accuracy: 0.8347 - val_loss: 0.4860 - val_accuracy: 0.7809\n",
            "Epoch 2881/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3893 - accuracy: 0.8347 - val_loss: 0.4860 - val_accuracy: 0.7809\n",
            "Epoch 2882/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3892 - accuracy: 0.8347 - val_loss: 0.4860 - val_accuracy: 0.7809\n",
            "Epoch 2883/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3891 - accuracy: 0.8347 - val_loss: 0.4859 - val_accuracy: 0.7809\n",
            "Epoch 2884/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3891 - accuracy: 0.8347 - val_loss: 0.4859 - val_accuracy: 0.7809\n",
            "Epoch 2885/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3890 - accuracy: 0.8347 - val_loss: 0.4859 - val_accuracy: 0.7809\n",
            "Epoch 2886/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.8347 - val_loss: 0.4858 - val_accuracy: 0.7809\n",
            "Epoch 2887/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.8347 - val_loss: 0.4858 - val_accuracy: 0.7809\n",
            "Epoch 2888/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3888 - accuracy: 0.8347 - val_loss: 0.4858 - val_accuracy: 0.7809\n",
            "Epoch 2889/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3887 - accuracy: 0.8347 - val_loss: 0.4857 - val_accuracy: 0.7809\n",
            "Epoch 2890/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3887 - accuracy: 0.8347 - val_loss: 0.4857 - val_accuracy: 0.7809\n",
            "Epoch 2891/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3886 - accuracy: 0.8347 - val_loss: 0.4856 - val_accuracy: 0.7809\n",
            "Epoch 2892/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8347 - val_loss: 0.4856 - val_accuracy: 0.7809\n",
            "Epoch 2893/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3885 - accuracy: 0.8347 - val_loss: 0.4856 - val_accuracy: 0.7809\n",
            "Epoch 2894/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3884 - accuracy: 0.8347 - val_loss: 0.4855 - val_accuracy: 0.7809\n",
            "Epoch 2895/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3883 - accuracy: 0.8347 - val_loss: 0.4855 - val_accuracy: 0.7809\n",
            "Epoch 2896/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8347 - val_loss: 0.4855 - val_accuracy: 0.7809\n",
            "Epoch 2897/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3882 - accuracy: 0.8347 - val_loss: 0.4855 - val_accuracy: 0.7809\n",
            "Epoch 2898/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3882 - accuracy: 0.8347 - val_loss: 0.4855 - val_accuracy: 0.7809\n",
            "Epoch 2899/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3881 - accuracy: 0.8347 - val_loss: 0.4854 - val_accuracy: 0.7809\n",
            "Epoch 2900/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3880 - accuracy: 0.8347 - val_loss: 0.4854 - val_accuracy: 0.7809\n",
            "Epoch 2901/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3880 - accuracy: 0.8347 - val_loss: 0.4854 - val_accuracy: 0.7809\n",
            "Epoch 2902/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3879 - accuracy: 0.8347 - val_loss: 0.4854 - val_accuracy: 0.7809\n",
            "Epoch 2903/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3878 - accuracy: 0.8347 - val_loss: 0.4853 - val_accuracy: 0.7809\n",
            "Epoch 2904/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.8347 - val_loss: 0.4852 - val_accuracy: 0.7809\n",
            "Epoch 2905/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3877 - accuracy: 0.8347 - val_loss: 0.4852 - val_accuracy: 0.7809\n",
            "Epoch 2906/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3877 - accuracy: 0.8347 - val_loss: 0.4852 - val_accuracy: 0.7809\n",
            "Epoch 2907/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3876 - accuracy: 0.8347 - val_loss: 0.4852 - val_accuracy: 0.7809\n",
            "Epoch 2908/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3876 - accuracy: 0.8347 - val_loss: 0.4852 - val_accuracy: 0.7809\n",
            "Epoch 2909/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3875 - accuracy: 0.8347 - val_loss: 0.4852 - val_accuracy: 0.7809\n",
            "Epoch 2910/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3874 - accuracy: 0.8347 - val_loss: 0.4851 - val_accuracy: 0.7809\n",
            "Epoch 2911/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3874 - accuracy: 0.8347 - val_loss: 0.4851 - val_accuracy: 0.7809\n",
            "Epoch 2912/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3873 - accuracy: 0.8347 - val_loss: 0.4850 - val_accuracy: 0.7809\n",
            "Epoch 2913/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3872 - accuracy: 0.8347 - val_loss: 0.4850 - val_accuracy: 0.7809\n",
            "Epoch 2914/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3872 - accuracy: 0.8347 - val_loss: 0.4850 - val_accuracy: 0.7809\n",
            "Epoch 2915/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3871 - accuracy: 0.8347 - val_loss: 0.4850 - val_accuracy: 0.7809\n",
            "Epoch 2916/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3871 - accuracy: 0.8347 - val_loss: 0.4850 - val_accuracy: 0.7809\n",
            "Epoch 2917/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8347 - val_loss: 0.4849 - val_accuracy: 0.7809\n",
            "Epoch 2918/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3869 - accuracy: 0.8347 - val_loss: 0.4849 - val_accuracy: 0.7809\n",
            "Epoch 2919/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3869 - accuracy: 0.8347 - val_loss: 0.4849 - val_accuracy: 0.7809\n",
            "Epoch 2920/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3868 - accuracy: 0.8347 - val_loss: 0.4849 - val_accuracy: 0.7809\n",
            "Epoch 2921/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3868 - accuracy: 0.8347 - val_loss: 0.4848 - val_accuracy: 0.7809\n",
            "Epoch 2922/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3867 - accuracy: 0.8347 - val_loss: 0.4848 - val_accuracy: 0.7809\n",
            "Epoch 2923/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3866 - accuracy: 0.8347 - val_loss: 0.4848 - val_accuracy: 0.7809\n",
            "Epoch 2924/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3866 - accuracy: 0.8347 - val_loss: 0.4848 - val_accuracy: 0.7809\n",
            "Epoch 2925/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.8347 - val_loss: 0.4847 - val_accuracy: 0.7809\n",
            "Epoch 2926/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3864 - accuracy: 0.8347 - val_loss: 0.4847 - val_accuracy: 0.7809\n",
            "Epoch 2927/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.8347 - val_loss: 0.4847 - val_accuracy: 0.7809\n",
            "Epoch 2928/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.8347 - val_loss: 0.4847 - val_accuracy: 0.7809\n",
            "Epoch 2929/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3863 - accuracy: 0.8347 - val_loss: 0.4847 - val_accuracy: 0.7809\n",
            "Epoch 2930/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3862 - accuracy: 0.8347 - val_loss: 0.4846 - val_accuracy: 0.7809\n",
            "Epoch 2931/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3861 - accuracy: 0.8347 - val_loss: 0.4846 - val_accuracy: 0.7809\n",
            "Epoch 2932/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3861 - accuracy: 0.8347 - val_loss: 0.4846 - val_accuracy: 0.7809\n",
            "Epoch 2933/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.8347 - val_loss: 0.4845 - val_accuracy: 0.7809\n",
            "Epoch 2934/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.8347 - val_loss: 0.4845 - val_accuracy: 0.7809\n",
            "Epoch 2935/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3859 - accuracy: 0.8347 - val_loss: 0.4845 - val_accuracy: 0.7809\n",
            "Epoch 2936/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3859 - accuracy: 0.8347 - val_loss: 0.4845 - val_accuracy: 0.7809\n",
            "Epoch 2937/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3858 - accuracy: 0.8347 - val_loss: 0.4845 - val_accuracy: 0.7809\n",
            "Epoch 2938/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3857 - accuracy: 0.8347 - val_loss: 0.4844 - val_accuracy: 0.7809\n",
            "Epoch 2939/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3857 - accuracy: 0.8347 - val_loss: 0.4844 - val_accuracy: 0.7809\n",
            "Epoch 2940/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3856 - accuracy: 0.8375 - val_loss: 0.4843 - val_accuracy: 0.7809\n",
            "Epoch 2941/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3855 - accuracy: 0.8375 - val_loss: 0.4843 - val_accuracy: 0.7809\n",
            "Epoch 2942/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.8375 - val_loss: 0.4843 - val_accuracy: 0.7809\n",
            "Epoch 2943/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3854 - accuracy: 0.8375 - val_loss: 0.4843 - val_accuracy: 0.7809\n",
            "Epoch 2944/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3854 - accuracy: 0.8375 - val_loss: 0.4843 - val_accuracy: 0.7809\n",
            "Epoch 2945/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.8375 - val_loss: 0.4843 - val_accuracy: 0.7809\n",
            "Epoch 2946/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3852 - accuracy: 0.8375 - val_loss: 0.4843 - val_accuracy: 0.7809\n",
            "Epoch 2947/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8375 - val_loss: 0.4842 - val_accuracy: 0.7809\n",
            "Epoch 2948/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3851 - accuracy: 0.8375 - val_loss: 0.4842 - val_accuracy: 0.7809\n",
            "Epoch 2949/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.8375 - val_loss: 0.4842 - val_accuracy: 0.7809\n",
            "Epoch 2950/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3850 - accuracy: 0.8375 - val_loss: 0.4842 - val_accuracy: 0.7809\n",
            "Epoch 2951/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3849 - accuracy: 0.8375 - val_loss: 0.4842 - val_accuracy: 0.7809\n",
            "Epoch 2952/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3849 - accuracy: 0.8375 - val_loss: 0.4841 - val_accuracy: 0.7809\n",
            "Epoch 2953/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8375 - val_loss: 0.4841 - val_accuracy: 0.7809\n",
            "Epoch 2954/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8375 - val_loss: 0.4841 - val_accuracy: 0.7809\n",
            "Epoch 2955/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.8375 - val_loss: 0.4841 - val_accuracy: 0.7809\n",
            "Epoch 2956/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3846 - accuracy: 0.8375 - val_loss: 0.4840 - val_accuracy: 0.7809\n",
            "Epoch 2957/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3846 - accuracy: 0.8375 - val_loss: 0.4840 - val_accuracy: 0.7809\n",
            "Epoch 2958/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3845 - accuracy: 0.8375 - val_loss: 0.4840 - val_accuracy: 0.7809\n",
            "Epoch 2959/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.8375 - val_loss: 0.4840 - val_accuracy: 0.7809\n",
            "Epoch 2960/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3844 - accuracy: 0.8375 - val_loss: 0.4839 - val_accuracy: 0.7809\n",
            "Epoch 2961/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3843 - accuracy: 0.8375 - val_loss: 0.4839 - val_accuracy: 0.7809\n",
            "Epoch 2962/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.8375 - val_loss: 0.4839 - val_accuracy: 0.7809\n",
            "Epoch 2963/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3842 - accuracy: 0.8375 - val_loss: 0.4839 - val_accuracy: 0.7809\n",
            "Epoch 2964/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3841 - accuracy: 0.8375 - val_loss: 0.4839 - val_accuracy: 0.7809\n",
            "Epoch 2965/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.8375 - val_loss: 0.4838 - val_accuracy: 0.7809\n",
            "Epoch 2966/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3840 - accuracy: 0.8375 - val_loss: 0.4838 - val_accuracy: 0.7865\n",
            "Epoch 2967/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3839 - accuracy: 0.8375 - val_loss: 0.4838 - val_accuracy: 0.7865\n",
            "Epoch 2968/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3839 - accuracy: 0.8375 - val_loss: 0.4838 - val_accuracy: 0.7865\n",
            "Epoch 2969/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3838 - accuracy: 0.8375 - val_loss: 0.4837 - val_accuracy: 0.7865\n",
            "Epoch 2970/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3838 - accuracy: 0.8375 - val_loss: 0.4837 - val_accuracy: 0.7865\n",
            "Epoch 2971/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3837 - accuracy: 0.8375 - val_loss: 0.4837 - val_accuracy: 0.7865\n",
            "Epoch 2972/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3837 - accuracy: 0.8375 - val_loss: 0.4836 - val_accuracy: 0.7865\n",
            "Epoch 2973/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.8375 - val_loss: 0.4836 - val_accuracy: 0.7865\n",
            "Epoch 2974/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3836 - accuracy: 0.8375 - val_loss: 0.4835 - val_accuracy: 0.7865\n",
            "Epoch 2975/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3835 - accuracy: 0.8375 - val_loss: 0.4835 - val_accuracy: 0.7865\n",
            "Epoch 2976/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3834 - accuracy: 0.8375 - val_loss: 0.4835 - val_accuracy: 0.7865\n",
            "Epoch 2977/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3834 - accuracy: 0.8375 - val_loss: 0.4834 - val_accuracy: 0.7865\n",
            "Epoch 2978/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3833 - accuracy: 0.8375 - val_loss: 0.4834 - val_accuracy: 0.7865\n",
            "Epoch 2979/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3833 - accuracy: 0.8375 - val_loss: 0.4834 - val_accuracy: 0.7865\n",
            "Epoch 2980/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3832 - accuracy: 0.8375 - val_loss: 0.4833 - val_accuracy: 0.7865\n",
            "Epoch 2981/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3832 - accuracy: 0.8375 - val_loss: 0.4833 - val_accuracy: 0.7865\n",
            "Epoch 2982/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3831 - accuracy: 0.8375 - val_loss: 0.4833 - val_accuracy: 0.7865\n",
            "Epoch 2983/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3830 - accuracy: 0.8375 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 2984/4000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3830 - accuracy: 0.8375 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 2985/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3829 - accuracy: 0.8375 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 2986/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3829 - accuracy: 0.8375 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 2987/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.8375 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 2988/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3827 - accuracy: 0.8375 - val_loss: 0.4832 - val_accuracy: 0.7865\n",
            "Epoch 2989/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.8375 - val_loss: 0.4831 - val_accuracy: 0.7865\n",
            "Epoch 2990/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3826 - accuracy: 0.8375 - val_loss: 0.4831 - val_accuracy: 0.7865\n",
            "Epoch 2991/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3826 - accuracy: 0.8375 - val_loss: 0.4831 - val_accuracy: 0.7865\n",
            "Epoch 2992/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3825 - accuracy: 0.8375 - val_loss: 0.4831 - val_accuracy: 0.7865\n",
            "Epoch 2993/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.8375 - val_loss: 0.4831 - val_accuracy: 0.7865\n",
            "Epoch 2994/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.8375 - val_loss: 0.4830 - val_accuracy: 0.7865\n",
            "Epoch 2995/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.8375 - val_loss: 0.4829 - val_accuracy: 0.7865\n",
            "Epoch 2996/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3823 - accuracy: 0.8375 - val_loss: 0.4829 - val_accuracy: 0.7865\n",
            "Epoch 2997/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3822 - accuracy: 0.8375 - val_loss: 0.4829 - val_accuracy: 0.7865\n",
            "Epoch 2998/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8375 - val_loss: 0.4828 - val_accuracy: 0.7865\n",
            "Epoch 2999/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3821 - accuracy: 0.8375 - val_loss: 0.4828 - val_accuracy: 0.7865\n",
            "Epoch 3000/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3820 - accuracy: 0.8375 - val_loss: 0.4828 - val_accuracy: 0.7865\n",
            "Epoch 3001/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3820 - accuracy: 0.8375 - val_loss: 0.4828 - val_accuracy: 0.7865\n",
            "Epoch 3002/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3819 - accuracy: 0.8375 - val_loss: 0.4828 - val_accuracy: 0.7865\n",
            "Epoch 3003/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3818 - accuracy: 0.8375 - val_loss: 0.4828 - val_accuracy: 0.7865\n",
            "Epoch 3004/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3818 - accuracy: 0.8375 - val_loss: 0.4827 - val_accuracy: 0.7865\n",
            "Epoch 3005/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3817 - accuracy: 0.8375 - val_loss: 0.4827 - val_accuracy: 0.7865\n",
            "Epoch 3006/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8375 - val_loss: 0.4827 - val_accuracy: 0.7865\n",
            "Epoch 3007/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3816 - accuracy: 0.8375 - val_loss: 0.4826 - val_accuracy: 0.7865\n",
            "Epoch 3008/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3816 - accuracy: 0.8375 - val_loss: 0.4826 - val_accuracy: 0.7865\n",
            "Epoch 3009/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3815 - accuracy: 0.8375 - val_loss: 0.4826 - val_accuracy: 0.7865\n",
            "Epoch 3010/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.8375 - val_loss: 0.4826 - val_accuracy: 0.7865\n",
            "Epoch 3011/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3814 - accuracy: 0.8375 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 3012/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3813 - accuracy: 0.8375 - val_loss: 0.4825 - val_accuracy: 0.7865\n",
            "Epoch 3013/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3813 - accuracy: 0.8375 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 3014/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3812 - accuracy: 0.8375 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 3015/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3812 - accuracy: 0.8375 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 3016/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3811 - accuracy: 0.8375 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 3017/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.8375 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 3018/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3810 - accuracy: 0.8375 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 3019/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3809 - accuracy: 0.8375 - val_loss: 0.4824 - val_accuracy: 0.7865\n",
            "Epoch 3020/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3809 - accuracy: 0.8375 - val_loss: 0.4823 - val_accuracy: 0.7865\n",
            "Epoch 3021/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3808 - accuracy: 0.8375 - val_loss: 0.4823 - val_accuracy: 0.7865\n",
            "Epoch 3022/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.8375 - val_loss: 0.4823 - val_accuracy: 0.7865\n",
            "Epoch 3023/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.8375 - val_loss: 0.4823 - val_accuracy: 0.7865\n",
            "Epoch 3024/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3806 - accuracy: 0.8375 - val_loss: 0.4822 - val_accuracy: 0.7865\n",
            "Epoch 3025/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8375 - val_loss: 0.4822 - val_accuracy: 0.7865\n",
            "Epoch 3026/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.8375 - val_loss: 0.4822 - val_accuracy: 0.7865\n",
            "Epoch 3027/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3805 - accuracy: 0.8375 - val_loss: 0.4822 - val_accuracy: 0.7865\n",
            "Epoch 3028/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8375 - val_loss: 0.4821 - val_accuracy: 0.7865\n",
            "Epoch 3029/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3803 - accuracy: 0.8375 - val_loss: 0.4822 - val_accuracy: 0.7865\n",
            "Epoch 3030/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3803 - accuracy: 0.8375 - val_loss: 0.4821 - val_accuracy: 0.7865\n",
            "Epoch 3031/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.8375 - val_loss: 0.4821 - val_accuracy: 0.7865\n",
            "Epoch 3032/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3802 - accuracy: 0.8375 - val_loss: 0.4821 - val_accuracy: 0.7865\n",
            "Epoch 3033/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3801 - accuracy: 0.8375 - val_loss: 0.4821 - val_accuracy: 0.7865\n",
            "Epoch 3034/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3801 - accuracy: 0.8375 - val_loss: 0.4821 - val_accuracy: 0.7865\n",
            "Epoch 3035/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3800 - accuracy: 0.8375 - val_loss: 0.4821 - val_accuracy: 0.7865\n",
            "Epoch 3036/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8375 - val_loss: 0.4821 - val_accuracy: 0.7865\n",
            "Epoch 3037/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3799 - accuracy: 0.8375 - val_loss: 0.4820 - val_accuracy: 0.7865\n",
            "Epoch 3038/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8375 - val_loss: 0.4820 - val_accuracy: 0.7865\n",
            "Epoch 3039/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8375 - val_loss: 0.4820 - val_accuracy: 0.7865\n",
            "Epoch 3040/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.8375 - val_loss: 0.4819 - val_accuracy: 0.7865\n",
            "Epoch 3041/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.8375 - val_loss: 0.4819 - val_accuracy: 0.7865\n",
            "Epoch 3042/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3796 - accuracy: 0.8375 - val_loss: 0.4819 - val_accuracy: 0.7865\n",
            "Epoch 3043/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8375 - val_loss: 0.4818 - val_accuracy: 0.7865\n",
            "Epoch 3044/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8375 - val_loss: 0.4818 - val_accuracy: 0.7865\n",
            "Epoch 3045/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3794 - accuracy: 0.8375 - val_loss: 0.4818 - val_accuracy: 0.7865\n",
            "Epoch 3046/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.8375 - val_loss: 0.4818 - val_accuracy: 0.7865\n",
            "Epoch 3047/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.8375 - val_loss: 0.4818 - val_accuracy: 0.7865\n",
            "Epoch 3048/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8375 - val_loss: 0.4818 - val_accuracy: 0.7865\n",
            "Epoch 3049/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3792 - accuracy: 0.8375 - val_loss: 0.4818 - val_accuracy: 0.7865\n",
            "Epoch 3050/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3791 - accuracy: 0.8375 - val_loss: 0.4817 - val_accuracy: 0.7865\n",
            "Epoch 3051/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8375 - val_loss: 0.4817 - val_accuracy: 0.7865\n",
            "Epoch 3052/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8375 - val_loss: 0.4817 - val_accuracy: 0.7865\n",
            "Epoch 3053/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3790 - accuracy: 0.8375 - val_loss: 0.4816 - val_accuracy: 0.7865\n",
            "Epoch 3054/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3789 - accuracy: 0.8375 - val_loss: 0.4816 - val_accuracy: 0.7865\n",
            "Epoch 3055/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3788 - accuracy: 0.8375 - val_loss: 0.4816 - val_accuracy: 0.7865\n",
            "Epoch 3056/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3788 - accuracy: 0.8375 - val_loss: 0.4816 - val_accuracy: 0.7865\n",
            "Epoch 3057/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.8375 - val_loss: 0.4815 - val_accuracy: 0.7865\n",
            "Epoch 3058/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.8375 - val_loss: 0.4815 - val_accuracy: 0.7865\n",
            "Epoch 3059/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.8375 - val_loss: 0.4815 - val_accuracy: 0.7865\n",
            "Epoch 3060/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3786 - accuracy: 0.8375 - val_loss: 0.4815 - val_accuracy: 0.7865\n",
            "Epoch 3061/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3785 - accuracy: 0.8375 - val_loss: 0.4814 - val_accuracy: 0.7865\n",
            "Epoch 3062/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3785 - accuracy: 0.8375 - val_loss: 0.4814 - val_accuracy: 0.7865\n",
            "Epoch 3063/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3784 - accuracy: 0.8375 - val_loss: 0.4814 - val_accuracy: 0.7865\n",
            "Epoch 3064/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3783 - accuracy: 0.8375 - val_loss: 0.4814 - val_accuracy: 0.7865\n",
            "Epoch 3065/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8375 - val_loss: 0.4814 - val_accuracy: 0.7865\n",
            "Epoch 3066/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3782 - accuracy: 0.8375 - val_loss: 0.4814 - val_accuracy: 0.7865\n",
            "Epoch 3067/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3782 - accuracy: 0.8375 - val_loss: 0.4814 - val_accuracy: 0.7865\n",
            "Epoch 3068/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.8375 - val_loss: 0.4814 - val_accuracy: 0.7865\n",
            "Epoch 3069/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.8375 - val_loss: 0.4814 - val_accuracy: 0.7865\n",
            "Epoch 3070/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3780 - accuracy: 0.8375 - val_loss: 0.4814 - val_accuracy: 0.7865\n",
            "Epoch 3071/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.8375 - val_loss: 0.4814 - val_accuracy: 0.7865\n",
            "Epoch 3072/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.8375 - val_loss: 0.4813 - val_accuracy: 0.7865\n",
            "Epoch 3073/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.8375 - val_loss: 0.4813 - val_accuracy: 0.7865\n",
            "Epoch 3074/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3778 - accuracy: 0.8375 - val_loss: 0.4813 - val_accuracy: 0.7865\n",
            "Epoch 3075/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3778 - accuracy: 0.8375 - val_loss: 0.4813 - val_accuracy: 0.7865\n",
            "Epoch 3076/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3777 - accuracy: 0.8375 - val_loss: 0.4812 - val_accuracy: 0.7865\n",
            "Epoch 3077/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3776 - accuracy: 0.8375 - val_loss: 0.4812 - val_accuracy: 0.7865\n",
            "Epoch 3078/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.8375 - val_loss: 0.4812 - val_accuracy: 0.7865\n",
            "Epoch 3079/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3775 - accuracy: 0.8375 - val_loss: 0.4812 - val_accuracy: 0.7865\n",
            "Epoch 3080/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8375 - val_loss: 0.4812 - val_accuracy: 0.7865\n",
            "Epoch 3081/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3775 - accuracy: 0.8375 - val_loss: 0.4811 - val_accuracy: 0.7865\n",
            "Epoch 3082/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8347 - val_loss: 0.4811 - val_accuracy: 0.7865\n",
            "Epoch 3083/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8347 - val_loss: 0.4810 - val_accuracy: 0.7865\n",
            "Epoch 3084/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8347 - val_loss: 0.4810 - val_accuracy: 0.7865\n",
            "Epoch 3085/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.8347 - val_loss: 0.4809 - val_accuracy: 0.7865\n",
            "Epoch 3086/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3772 - accuracy: 0.8347 - val_loss: 0.4809 - val_accuracy: 0.7865\n",
            "Epoch 3087/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3771 - accuracy: 0.8347 - val_loss: 0.4809 - val_accuracy: 0.7865\n",
            "Epoch 3088/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3771 - accuracy: 0.8347 - val_loss: 0.4809 - val_accuracy: 0.7865\n",
            "Epoch 3089/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3770 - accuracy: 0.8347 - val_loss: 0.4809 - val_accuracy: 0.7865\n",
            "Epoch 3090/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3770 - accuracy: 0.8347 - val_loss: 0.4809 - val_accuracy: 0.7865\n",
            "Epoch 3091/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8347 - val_loss: 0.4810 - val_accuracy: 0.7865\n",
            "Epoch 3092/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3768 - accuracy: 0.8347 - val_loss: 0.4809 - val_accuracy: 0.7865\n",
            "Epoch 3093/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3768 - accuracy: 0.8347 - val_loss: 0.4809 - val_accuracy: 0.7865\n",
            "Epoch 3094/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8375 - val_loss: 0.4809 - val_accuracy: 0.7865\n",
            "Epoch 3095/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8375 - val_loss: 0.4809 - val_accuracy: 0.7865\n",
            "Epoch 3096/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8375 - val_loss: 0.4809 - val_accuracy: 0.7865\n",
            "Epoch 3097/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3766 - accuracy: 0.8347 - val_loss: 0.4809 - val_accuracy: 0.7865\n",
            "Epoch 3098/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8347 - val_loss: 0.4809 - val_accuracy: 0.7865\n",
            "Epoch 3099/4000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3765 - accuracy: 0.8347 - val_loss: 0.4808 - val_accuracy: 0.7865\n",
            "Epoch 3100/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.8347 - val_loss: 0.4808 - val_accuracy: 0.7865\n",
            "Epoch 3101/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3764 - accuracy: 0.8347 - val_loss: 0.4808 - val_accuracy: 0.7865\n",
            "Epoch 3102/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8347 - val_loss: 0.4807 - val_accuracy: 0.7865\n",
            "Epoch 3103/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3763 - accuracy: 0.8347 - val_loss: 0.4807 - val_accuracy: 0.7865\n",
            "Epoch 3104/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3762 - accuracy: 0.8347 - val_loss: 0.4807 - val_accuracy: 0.7865\n",
            "Epoch 3105/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8347 - val_loss: 0.4807 - val_accuracy: 0.7865\n",
            "Epoch 3106/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3761 - accuracy: 0.8347 - val_loss: 0.4807 - val_accuracy: 0.7865\n",
            "Epoch 3107/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3761 - accuracy: 0.8347 - val_loss: 0.4807 - val_accuracy: 0.7865\n",
            "Epoch 3108/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3760 - accuracy: 0.8347 - val_loss: 0.4807 - val_accuracy: 0.7865\n",
            "Epoch 3109/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3759 - accuracy: 0.8347 - val_loss: 0.4807 - val_accuracy: 0.7865\n",
            "Epoch 3110/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3759 - accuracy: 0.8347 - val_loss: 0.4807 - val_accuracy: 0.7865\n",
            "Epoch 3111/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8347 - val_loss: 0.4807 - val_accuracy: 0.7865\n",
            "Epoch 3112/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3758 - accuracy: 0.8347 - val_loss: 0.4807 - val_accuracy: 0.7865\n",
            "Epoch 3113/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.8347 - val_loss: 0.4807 - val_accuracy: 0.7865\n",
            "Epoch 3114/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3757 - accuracy: 0.8347 - val_loss: 0.4806 - val_accuracy: 0.7865\n",
            "Epoch 3115/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8347 - val_loss: 0.4806 - val_accuracy: 0.7865\n",
            "Epoch 3116/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3756 - accuracy: 0.8347 - val_loss: 0.4805 - val_accuracy: 0.7865\n",
            "Epoch 3117/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8347 - val_loss: 0.4805 - val_accuracy: 0.7865\n",
            "Epoch 3118/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3755 - accuracy: 0.8347 - val_loss: 0.4805 - val_accuracy: 0.7865\n",
            "Epoch 3119/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8347 - val_loss: 0.4805 - val_accuracy: 0.7865\n",
            "Epoch 3120/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3754 - accuracy: 0.8347 - val_loss: 0.4805 - val_accuracy: 0.7865\n",
            "Epoch 3121/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3753 - accuracy: 0.8347 - val_loss: 0.4804 - val_accuracy: 0.7865\n",
            "Epoch 3122/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3753 - accuracy: 0.8347 - val_loss: 0.4804 - val_accuracy: 0.7865\n",
            "Epoch 3123/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3752 - accuracy: 0.8347 - val_loss: 0.4804 - val_accuracy: 0.7865\n",
            "Epoch 3124/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3752 - accuracy: 0.8347 - val_loss: 0.4804 - val_accuracy: 0.7865\n",
            "Epoch 3125/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8347 - val_loss: 0.4804 - val_accuracy: 0.7865\n",
            "Epoch 3126/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8347 - val_loss: 0.4804 - val_accuracy: 0.7865\n",
            "Epoch 3127/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3750 - accuracy: 0.8347 - val_loss: 0.4804 - val_accuracy: 0.7865\n",
            "Epoch 3128/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3750 - accuracy: 0.8347 - val_loss: 0.4803 - val_accuracy: 0.7865\n",
            "Epoch 3129/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3749 - accuracy: 0.8347 - val_loss: 0.4803 - val_accuracy: 0.7865\n",
            "Epoch 3130/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3749 - accuracy: 0.8347 - val_loss: 0.4803 - val_accuracy: 0.7865\n",
            "Epoch 3131/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.8347 - val_loss: 0.4803 - val_accuracy: 0.7865\n",
            "Epoch 3132/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3747 - accuracy: 0.8347 - val_loss: 0.4803 - val_accuracy: 0.7865\n",
            "Epoch 3133/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8347 - val_loss: 0.4803 - val_accuracy: 0.7865\n",
            "Epoch 3134/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3747 - accuracy: 0.8347 - val_loss: 0.4803 - val_accuracy: 0.7865\n",
            "Epoch 3135/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3746 - accuracy: 0.8347 - val_loss: 0.4803 - val_accuracy: 0.7865\n",
            "Epoch 3136/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3745 - accuracy: 0.8347 - val_loss: 0.4803 - val_accuracy: 0.7865\n",
            "Epoch 3137/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3745 - accuracy: 0.8347 - val_loss: 0.4803 - val_accuracy: 0.7865\n",
            "Epoch 3138/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8347 - val_loss: 0.4803 - val_accuracy: 0.7865\n",
            "Epoch 3139/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3744 - accuracy: 0.8347 - val_loss: 0.4803 - val_accuracy: 0.7865\n",
            "Epoch 3140/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3743 - accuracy: 0.8347 - val_loss: 0.4802 - val_accuracy: 0.7865\n",
            "Epoch 3141/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3743 - accuracy: 0.8347 - val_loss: 0.4802 - val_accuracy: 0.7865\n",
            "Epoch 3142/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3742 - accuracy: 0.8347 - val_loss: 0.4802 - val_accuracy: 0.7865\n",
            "Epoch 3143/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3742 - accuracy: 0.8347 - val_loss: 0.4802 - val_accuracy: 0.7865\n",
            "Epoch 3144/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3741 - accuracy: 0.8347 - val_loss: 0.4802 - val_accuracy: 0.7865\n",
            "Epoch 3145/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.8347 - val_loss: 0.4801 - val_accuracy: 0.7865\n",
            "Epoch 3146/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.8347 - val_loss: 0.4801 - val_accuracy: 0.7865\n",
            "Epoch 3147/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.8347 - val_loss: 0.4801 - val_accuracy: 0.7865\n",
            "Epoch 3148/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3739 - accuracy: 0.8347 - val_loss: 0.4801 - val_accuracy: 0.7865\n",
            "Epoch 3149/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7865\n",
            "Epoch 3150/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.8347 - val_loss: 0.4801 - val_accuracy: 0.7865\n",
            "Epoch 3151/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.8375 - val_loss: 0.4800 - val_accuracy: 0.7865\n",
            "Epoch 3152/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8375 - val_loss: 0.4800 - val_accuracy: 0.7865\n",
            "Epoch 3153/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8375 - val_loss: 0.4800 - val_accuracy: 0.7865\n",
            "Epoch 3154/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8375 - val_loss: 0.4800 - val_accuracy: 0.7865\n",
            "Epoch 3155/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3735 - accuracy: 0.8375 - val_loss: 0.4800 - val_accuracy: 0.7865\n",
            "Epoch 3156/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8375 - val_loss: 0.4800 - val_accuracy: 0.7865\n",
            "Epoch 3157/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3734 - accuracy: 0.8375 - val_loss: 0.4799 - val_accuracy: 0.7865\n",
            "Epoch 3158/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3734 - accuracy: 0.8375 - val_loss: 0.4799 - val_accuracy: 0.7865\n",
            "Epoch 3159/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.8375 - val_loss: 0.4799 - val_accuracy: 0.7865\n",
            "Epoch 3160/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3733 - accuracy: 0.8375 - val_loss: 0.4799 - val_accuracy: 0.7865\n",
            "Epoch 3161/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3732 - accuracy: 0.8375 - val_loss: 0.4799 - val_accuracy: 0.7865\n",
            "Epoch 3162/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8375 - val_loss: 0.4799 - val_accuracy: 0.7865\n",
            "Epoch 3163/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3731 - accuracy: 0.8375 - val_loss: 0.4798 - val_accuracy: 0.7865\n",
            "Epoch 3164/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8375 - val_loss: 0.4798 - val_accuracy: 0.7865\n",
            "Epoch 3165/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8375 - val_loss: 0.4798 - val_accuracy: 0.7865\n",
            "Epoch 3166/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3730 - accuracy: 0.8375 - val_loss: 0.4798 - val_accuracy: 0.7865\n",
            "Epoch 3167/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8375 - val_loss: 0.4798 - val_accuracy: 0.7865\n",
            "Epoch 3168/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8375 - val_loss: 0.4798 - val_accuracy: 0.7865\n",
            "Epoch 3169/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3728 - accuracy: 0.8375 - val_loss: 0.4798 - val_accuracy: 0.7865\n",
            "Epoch 3170/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3728 - accuracy: 0.8375 - val_loss: 0.4798 - val_accuracy: 0.7865\n",
            "Epoch 3171/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8375 - val_loss: 0.4798 - val_accuracy: 0.7865\n",
            "Epoch 3172/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3727 - accuracy: 0.8375 - val_loss: 0.4797 - val_accuracy: 0.7865\n",
            "Epoch 3173/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3726 - accuracy: 0.8375 - val_loss: 0.4797 - val_accuracy: 0.7865\n",
            "Epoch 3174/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8375 - val_loss: 0.4797 - val_accuracy: 0.7865\n",
            "Epoch 3175/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3725 - accuracy: 0.8375 - val_loss: 0.4797 - val_accuracy: 0.7865\n",
            "Epoch 3176/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8375 - val_loss: 0.4797 - val_accuracy: 0.7865\n",
            "Epoch 3177/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3724 - accuracy: 0.8375 - val_loss: 0.4797 - val_accuracy: 0.7865\n",
            "Epoch 3178/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3724 - accuracy: 0.8375 - val_loss: 0.4797 - val_accuracy: 0.7865\n",
            "Epoch 3179/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.8375 - val_loss: 0.4797 - val_accuracy: 0.7865\n",
            "Epoch 3180/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3723 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3181/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3722 - accuracy: 0.8375 - val_loss: 0.4797 - val_accuracy: 0.7865\n",
            "Epoch 3182/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3722 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3183/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3184/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3721 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3185/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3720 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3186/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3720 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3187/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3188/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3719 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3189/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3190/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3191/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3192/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3193/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3716 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3194/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3716 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3195/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3196/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3197/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3714 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3198/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3714 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3199/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3713 - accuracy: 0.8375 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3200/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3713 - accuracy: 0.8375 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3201/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3712 - accuracy: 0.8375 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3202/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3712 - accuracy: 0.8375 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3203/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.8347 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3204/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3711 - accuracy: 0.8347 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3205/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3710 - accuracy: 0.8347 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3206/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3710 - accuracy: 0.8347 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3207/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3709 - accuracy: 0.8347 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3208/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3709 - accuracy: 0.8347 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3209/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3708 - accuracy: 0.8347 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3210/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3708 - accuracy: 0.8347 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3211/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3707 - accuracy: 0.8347 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3212/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3707 - accuracy: 0.8347 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3213/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8347 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3214/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3706 - accuracy: 0.8347 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3215/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3705 - accuracy: 0.8347 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3216/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3705 - accuracy: 0.8347 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3217/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8347 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3218/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3704 - accuracy: 0.8347 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3219/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3703 - accuracy: 0.8347 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3220/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3703 - accuracy: 0.8347 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3221/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3702 - accuracy: 0.8347 - val_loss: 0.4794 - val_accuracy: 0.7865\n",
            "Epoch 3222/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3702 - accuracy: 0.8347 - val_loss: 0.4794 - val_accuracy: 0.7865\n",
            "Epoch 3223/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3701 - accuracy: 0.8347 - val_loss: 0.4794 - val_accuracy: 0.7865\n",
            "Epoch 3224/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.8347 - val_loss: 0.4794 - val_accuracy: 0.7865\n",
            "Epoch 3225/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3700 - accuracy: 0.8347 - val_loss: 0.4794 - val_accuracy: 0.7865\n",
            "Epoch 3226/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3700 - accuracy: 0.8347 - val_loss: 0.4794 - val_accuracy: 0.7865\n",
            "Epoch 3227/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8347 - val_loss: 0.4794 - val_accuracy: 0.7865\n",
            "Epoch 3228/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3699 - accuracy: 0.8347 - val_loss: 0.4794 - val_accuracy: 0.7865\n",
            "Epoch 3229/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3698 - accuracy: 0.8347 - val_loss: 0.4794 - val_accuracy: 0.7865\n",
            "Epoch 3230/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3698 - accuracy: 0.8347 - val_loss: 0.4794 - val_accuracy: 0.7865\n",
            "Epoch 3231/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3697 - accuracy: 0.8347 - val_loss: 0.4794 - val_accuracy: 0.7865\n",
            "Epoch 3232/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3697 - accuracy: 0.8347 - val_loss: 0.4793 - val_accuracy: 0.7865\n",
            "Epoch 3233/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3696 - accuracy: 0.8347 - val_loss: 0.4793 - val_accuracy: 0.7865\n",
            "Epoch 3234/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3696 - accuracy: 0.8347 - val_loss: 0.4793 - val_accuracy: 0.7865\n",
            "Epoch 3235/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3695 - accuracy: 0.8347 - val_loss: 0.4793 - val_accuracy: 0.7865\n",
            "Epoch 3236/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3695 - accuracy: 0.8347 - val_loss: 0.4793 - val_accuracy: 0.7865\n",
            "Epoch 3237/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3694 - accuracy: 0.8347 - val_loss: 0.4793 - val_accuracy: 0.7865\n",
            "Epoch 3238/4000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3694 - accuracy: 0.8347 - val_loss: 0.4793 - val_accuracy: 0.7865\n",
            "Epoch 3239/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3693 - accuracy: 0.8347 - val_loss: 0.4793 - val_accuracy: 0.7865\n",
            "Epoch 3240/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3693 - accuracy: 0.8347 - val_loss: 0.4793 - val_accuracy: 0.7865\n",
            "Epoch 3241/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8347 - val_loss: 0.4793 - val_accuracy: 0.7865\n",
            "Epoch 3242/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3692 - accuracy: 0.8347 - val_loss: 0.4793 - val_accuracy: 0.7865\n",
            "Epoch 3243/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3691 - accuracy: 0.8347 - val_loss: 0.4793 - val_accuracy: 0.7865\n",
            "Epoch 3244/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3691 - accuracy: 0.8347 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3245/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3690 - accuracy: 0.8347 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3246/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3690 - accuracy: 0.8347 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3247/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8347 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3248/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3689 - accuracy: 0.8347 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3249/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.8347 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3250/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3688 - accuracy: 0.8347 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3251/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3688 - accuracy: 0.8347 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3252/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3687 - accuracy: 0.8347 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3253/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3687 - accuracy: 0.8347 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3254/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3687 - accuracy: 0.8347 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3255/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3686 - accuracy: 0.8347 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3256/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3686 - accuracy: 0.8347 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3257/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3685 - accuracy: 0.8347 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3258/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3685 - accuracy: 0.8347 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3259/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3685 - accuracy: 0.8347 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3260/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3684 - accuracy: 0.8347 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3261/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3684 - accuracy: 0.8347 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3262/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3683 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3263/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3683 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3264/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3265/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3682 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3266/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3267/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3681 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3268/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3681 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3269/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3680 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3270/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3271/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3680 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3272/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3679 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3273/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3274/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3678 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3275/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3678 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3276/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3678 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3277/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3677 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3278/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3677 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3279/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3676 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3280/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3281/4000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3676 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3282/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3675 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3283/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3675 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3284/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3674 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3285/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3674 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3286/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3287/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3288/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3673 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3289/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3672 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3290/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3672 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3291/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3671 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3292/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3671 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3293/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3671 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3294/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3670 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3295/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3296/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3669 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3297/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3669 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3298/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3669 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3299/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3668 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3300/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3668 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3301/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3667 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3302/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3667 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3303/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3666 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3304/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3666 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3305/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3666 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3306/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3665 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3307/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3308/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3664 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3309/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3664 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3310/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3663 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3311/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3663 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3312/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3663 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3313/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3662 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3314/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3662 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3315/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3661 - accuracy: 0.8347 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3316/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3661 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3317/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3660 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3318/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3660 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3319/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3659 - accuracy: 0.8347 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3320/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3659 - accuracy: 0.8375 - val_loss: 0.4790 - val_accuracy: 0.7865\n",
            "Epoch 3321/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3659 - accuracy: 0.8375 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3322/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3658 - accuracy: 0.8375 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3323/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3658 - accuracy: 0.8375 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3324/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3657 - accuracy: 0.8375 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3325/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3657 - accuracy: 0.8375 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3326/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3656 - accuracy: 0.8403 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3327/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3656 - accuracy: 0.8403 - val_loss: 0.4791 - val_accuracy: 0.7865\n",
            "Epoch 3328/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3655 - accuracy: 0.8403 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3329/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3655 - accuracy: 0.8403 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3330/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3655 - accuracy: 0.8403 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3331/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3654 - accuracy: 0.8403 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3332/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3654 - accuracy: 0.8403 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3333/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3653 - accuracy: 0.8403 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3334/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3653 - accuracy: 0.8403 - val_loss: 0.4792 - val_accuracy: 0.7865\n",
            "Epoch 3335/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3653 - accuracy: 0.8403 - val_loss: 0.4793 - val_accuracy: 0.7865\n",
            "Epoch 3336/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3652 - accuracy: 0.8403 - val_loss: 0.4793 - val_accuracy: 0.7865\n",
            "Epoch 3337/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3651 - accuracy: 0.8403 - val_loss: 0.4793 - val_accuracy: 0.7865\n",
            "Epoch 3338/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3651 - accuracy: 0.8403 - val_loss: 0.4794 - val_accuracy: 0.7865\n",
            "Epoch 3339/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3650 - accuracy: 0.8403 - val_loss: 0.4794 - val_accuracy: 0.7865\n",
            "Epoch 3340/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3650 - accuracy: 0.8403 - val_loss: 0.4794 - val_accuracy: 0.7865\n",
            "Epoch 3341/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3650 - accuracy: 0.8403 - val_loss: 0.4794 - val_accuracy: 0.7865\n",
            "Epoch 3342/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3649 - accuracy: 0.8403 - val_loss: 0.4794 - val_accuracy: 0.7865\n",
            "Epoch 3343/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3649 - accuracy: 0.8403 - val_loss: 0.4794 - val_accuracy: 0.7865\n",
            "Epoch 3344/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3648 - accuracy: 0.8403 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3345/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3648 - accuracy: 0.8403 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3346/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3647 - accuracy: 0.8403 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3347/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3647 - accuracy: 0.8403 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3348/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3646 - accuracy: 0.8403 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3349/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3646 - accuracy: 0.8403 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3350/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3646 - accuracy: 0.8403 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3351/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3645 - accuracy: 0.8403 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3352/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3645 - accuracy: 0.8403 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3353/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3644 - accuracy: 0.8403 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3354/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3644 - accuracy: 0.8403 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3355/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3643 - accuracy: 0.8403 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3356/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3643 - accuracy: 0.8403 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3357/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3643 - accuracy: 0.8403 - val_loss: 0.4795 - val_accuracy: 0.7865\n",
            "Epoch 3358/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3642 - accuracy: 0.8403 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3359/4000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3642 - accuracy: 0.8403 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3360/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3641 - accuracy: 0.8403 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3361/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3641 - accuracy: 0.8403 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3362/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3640 - accuracy: 0.8403 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3363/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3640 - accuracy: 0.8403 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3364/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3640 - accuracy: 0.8403 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3365/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3639 - accuracy: 0.8403 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3366/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3639 - accuracy: 0.8403 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3367/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3638 - accuracy: 0.8403 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3368/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3638 - accuracy: 0.8403 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3369/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3637 - accuracy: 0.8403 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3370/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3637 - accuracy: 0.8403 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3371/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3637 - accuracy: 0.8403 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3372/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3636 - accuracy: 0.8403 - val_loss: 0.4796 - val_accuracy: 0.7865\n",
            "Epoch 3373/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3636 - accuracy: 0.8403 - val_loss: 0.4796 - val_accuracy: 0.7921\n",
            "Epoch 3374/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3635 - accuracy: 0.8403 - val_loss: 0.4796 - val_accuracy: 0.7921\n",
            "Epoch 3375/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3635 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3376/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3635 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3377/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3634 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3378/4000\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.3634 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3379/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3634 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3380/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3633 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3381/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3633 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3382/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3632 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3383/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3632 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3384/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3632 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3385/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3631 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3386/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3631 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3387/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3631 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3388/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3630 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3389/4000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3630 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3390/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3630 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3391/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3629 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3392/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3629 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3393/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3629 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3394/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3628 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3395/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3628 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3396/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3628 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3397/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3627 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3398/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3627 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3399/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3627 - accuracy: 0.8403 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3400/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3626 - accuracy: 0.8375 - val_loss: 0.4798 - val_accuracy: 0.7921\n",
            "Epoch 3401/4000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3626 - accuracy: 0.8375 - val_loss: 0.4797 - val_accuracy: 0.7921\n",
            "Epoch 3402/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3626 - accuracy: 0.8375 - val_loss: 0.4798 - val_accuracy: 0.7921\n",
            "Epoch 3403/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3625 - accuracy: 0.8375 - val_loss: 0.4798 - val_accuracy: 0.7921\n",
            "Epoch 3404/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3625 - accuracy: 0.8375 - val_loss: 0.4798 - val_accuracy: 0.7921\n",
            "Epoch 3405/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3625 - accuracy: 0.8375 - val_loss: 0.4798 - val_accuracy: 0.7921\n",
            "Epoch 3406/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3624 - accuracy: 0.8375 - val_loss: 0.4798 - val_accuracy: 0.7921\n",
            "Epoch 3407/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3624 - accuracy: 0.8375 - val_loss: 0.4798 - val_accuracy: 0.7921\n",
            "Epoch 3408/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3623 - accuracy: 0.8375 - val_loss: 0.4798 - val_accuracy: 0.7921\n",
            "Epoch 3409/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3623 - accuracy: 0.8375 - val_loss: 0.4798 - val_accuracy: 0.7921\n",
            "Epoch 3410/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3623 - accuracy: 0.8375 - val_loss: 0.4798 - val_accuracy: 0.7921\n",
            "Epoch 3411/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3622 - accuracy: 0.8375 - val_loss: 0.4799 - val_accuracy: 0.7921\n",
            "Epoch 3412/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3622 - accuracy: 0.8375 - val_loss: 0.4799 - val_accuracy: 0.7921\n",
            "Epoch 3413/4000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3622 - accuracy: 0.8375 - val_loss: 0.4799 - val_accuracy: 0.7921\n",
            "Epoch 3414/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3621 - accuracy: 0.8375 - val_loss: 0.4799 - val_accuracy: 0.7921\n",
            "Epoch 3415/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3621 - accuracy: 0.8375 - val_loss: 0.4799 - val_accuracy: 0.7921\n",
            "Epoch 3416/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3621 - accuracy: 0.8375 - val_loss: 0.4799 - val_accuracy: 0.7921\n",
            "Epoch 3417/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3620 - accuracy: 0.8375 - val_loss: 0.4800 - val_accuracy: 0.7921\n",
            "Epoch 3418/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3620 - accuracy: 0.8375 - val_loss: 0.4800 - val_accuracy: 0.7921\n",
            "Epoch 3419/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3619 - accuracy: 0.8375 - val_loss: 0.4800 - val_accuracy: 0.7921\n",
            "Epoch 3420/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3619 - accuracy: 0.8375 - val_loss: 0.4800 - val_accuracy: 0.7921\n",
            "Epoch 3421/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3619 - accuracy: 0.8375 - val_loss: 0.4800 - val_accuracy: 0.7921\n",
            "Epoch 3422/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3618 - accuracy: 0.8375 - val_loss: 0.4800 - val_accuracy: 0.7921\n",
            "Epoch 3423/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3618 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3424/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3618 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3425/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3617 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3426/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3617 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3427/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3617 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3428/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3616 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3429/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3616 - accuracy: 0.8403 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3430/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3615 - accuracy: 0.8403 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3431/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3615 - accuracy: 0.8403 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3432/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3615 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3433/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3614 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3434/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3614 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3435/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3614 - accuracy: 0.8403 - val_loss: 0.4800 - val_accuracy: 0.7921\n",
            "Epoch 3436/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3613 - accuracy: 0.8403 - val_loss: 0.4800 - val_accuracy: 0.7921\n",
            "Epoch 3437/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3613 - accuracy: 0.8403 - val_loss: 0.4800 - val_accuracy: 0.7921\n",
            "Epoch 3438/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3613 - accuracy: 0.8403 - val_loss: 0.4800 - val_accuracy: 0.7921\n",
            "Epoch 3439/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3612 - accuracy: 0.8403 - val_loss: 0.4800 - val_accuracy: 0.7921\n",
            "Epoch 3440/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3612 - accuracy: 0.8403 - val_loss: 0.4800 - val_accuracy: 0.7921\n",
            "Epoch 3441/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3612 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3442/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3611 - accuracy: 0.8375 - val_loss: 0.4800 - val_accuracy: 0.7921\n",
            "Epoch 3443/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3611 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3444/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3611 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3445/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3610 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3446/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3610 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3447/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3609 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3448/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3609 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3449/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3609 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3450/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3608 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3451/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3608 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3452/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3608 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3453/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3607 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3454/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3607 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3455/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3607 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3456/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3606 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3457/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3606 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3458/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3606 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3459/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3605 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3460/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3605 - accuracy: 0.8375 - val_loss: 0.4801 - val_accuracy: 0.7921\n",
            "Epoch 3461/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3604 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3462/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3604 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3463/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3604 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3464/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3603 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3465/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3603 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3466/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3603 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3467/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3602 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3468/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3602 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3469/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3602 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3470/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3601 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3471/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3601 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3472/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3601 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3473/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3600 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3474/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3600 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3475/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3599 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3476/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3599 - accuracy: 0.8375 - val_loss: 0.4803 - val_accuracy: 0.7921\n",
            "Epoch 3477/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3599 - accuracy: 0.8375 - val_loss: 0.4803 - val_accuracy: 0.7921\n",
            "Epoch 3478/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3598 - accuracy: 0.8375 - val_loss: 0.4803 - val_accuracy: 0.7921\n",
            "Epoch 3479/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3598 - accuracy: 0.8375 - val_loss: 0.4803 - val_accuracy: 0.7921\n",
            "Epoch 3480/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3598 - accuracy: 0.8375 - val_loss: 0.4803 - val_accuracy: 0.7921\n",
            "Epoch 3481/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3597 - accuracy: 0.8375 - val_loss: 0.4803 - val_accuracy: 0.7921\n",
            "Epoch 3482/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3597 - accuracy: 0.8375 - val_loss: 0.4803 - val_accuracy: 0.7921\n",
            "Epoch 3483/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3597 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3484/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3596 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3485/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3596 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3486/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3596 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3487/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3596 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3488/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3595 - accuracy: 0.8375 - val_loss: 0.4803 - val_accuracy: 0.7921\n",
            "Epoch 3489/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3595 - accuracy: 0.8375 - val_loss: 0.4803 - val_accuracy: 0.7921\n",
            "Epoch 3490/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3594 - accuracy: 0.8375 - val_loss: 0.4803 - val_accuracy: 0.7921\n",
            "Epoch 3491/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3594 - accuracy: 0.8375 - val_loss: 0.4803 - val_accuracy: 0.7921\n",
            "Epoch 3492/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3594 - accuracy: 0.8375 - val_loss: 0.4803 - val_accuracy: 0.7921\n",
            "Epoch 3493/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3593 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3494/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3593 - accuracy: 0.8375 - val_loss: 0.4802 - val_accuracy: 0.7921\n",
            "Epoch 3495/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3593 - accuracy: 0.8375 - val_loss: 0.4803 - val_accuracy: 0.7921\n",
            "Epoch 3496/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3593 - accuracy: 0.8375 - val_loss: 0.4803 - val_accuracy: 0.7921\n",
            "Epoch 3497/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3592 - accuracy: 0.8375 - val_loss: 0.4803 - val_accuracy: 0.7921\n",
            "Epoch 3498/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3592 - accuracy: 0.8375 - val_loss: 0.4803 - val_accuracy: 0.7921\n",
            "Epoch 3499/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3592 - accuracy: 0.8375 - val_loss: 0.4803 - val_accuracy: 0.7921\n",
            "Epoch 3500/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3591 - accuracy: 0.8375 - val_loss: 0.4803 - val_accuracy: 0.7921\n",
            "Epoch 3501/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3591 - accuracy: 0.8375 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3502/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3591 - accuracy: 0.8375 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3503/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3590 - accuracy: 0.8375 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3504/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3590 - accuracy: 0.8375 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3505/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3590 - accuracy: 0.8375 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3506/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3589 - accuracy: 0.8375 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3507/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3589 - accuracy: 0.8375 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3508/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3589 - accuracy: 0.8375 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3509/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3589 - accuracy: 0.8375 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3510/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3588 - accuracy: 0.8375 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3511/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3588 - accuracy: 0.8375 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3512/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3588 - accuracy: 0.8375 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3513/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3587 - accuracy: 0.8375 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3514/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3587 - accuracy: 0.8375 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3515/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3587 - accuracy: 0.8375 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3516/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3586 - accuracy: 0.8375 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3517/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3586 - accuracy: 0.8375 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3518/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3586 - accuracy: 0.8375 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3519/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3585 - accuracy: 0.8375 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3520/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3585 - accuracy: 0.8375 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3521/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3585 - accuracy: 0.8375 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3522/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3584 - accuracy: 0.8375 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3523/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3584 - accuracy: 0.8375 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3524/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3584 - accuracy: 0.8375 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3525/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3584 - accuracy: 0.8375 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3526/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3583 - accuracy: 0.8375 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3527/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3583 - accuracy: 0.8375 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3528/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3583 - accuracy: 0.8403 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3529/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3582 - accuracy: 0.8403 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3530/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3582 - accuracy: 0.8403 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3531/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3582 - accuracy: 0.8375 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3532/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3581 - accuracy: 0.8375 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3533/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3581 - accuracy: 0.8375 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3534/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3581 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3535/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3580 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3536/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3580 - accuracy: 0.8403 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3537/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3580 - accuracy: 0.8403 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3538/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3580 - accuracy: 0.8403 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3539/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3580 - accuracy: 0.8403 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3540/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3579 - accuracy: 0.8403 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3541/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3579 - accuracy: 0.8403 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3542/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3579 - accuracy: 0.8403 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3543/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3578 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3544/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3578 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3545/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3578 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3546/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3577 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3547/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3577 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3548/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3577 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3549/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3577 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3550/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3576 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3551/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3576 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3552/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3576 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3553/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3575 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3554/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3575 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3555/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3575 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3556/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3574 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3557/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3574 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3558/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3574 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3559/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3573 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3560/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3573 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3561/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3573 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3562/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3573 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3563/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3572 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3564/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3572 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3565/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3572 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3566/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3571 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3567/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3571 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3568/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3571 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3569/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3570 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3570/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3570 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3571/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3570 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3572/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3569 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3573/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3569 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3574/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3569 - accuracy: 0.8403 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3575/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3569 - accuracy: 0.8403 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3576/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3568 - accuracy: 0.8403 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3577/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3568 - accuracy: 0.8403 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3578/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3568 - accuracy: 0.8403 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3579/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3567 - accuracy: 0.8403 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3580/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3567 - accuracy: 0.8403 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3581/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3567 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3582/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3567 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3583/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3566 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3584/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3566 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3585/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3566 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3586/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3566 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3587/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3565 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3588/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3565 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3589/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3565 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3590/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3564 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3591/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3564 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3592/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3564 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3593/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3563 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3594/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3563 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3595/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3563 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3596/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3562 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3597/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3562 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3598/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3562 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3599/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3562 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3600/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3561 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3601/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3561 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3602/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3561 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3603/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3560 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3604/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3560 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3605/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3560 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3606/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3559 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3607/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3559 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3608/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3559 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3609/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3559 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3610/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3558 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3611/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3558 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3612/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3558 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3613/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3557 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3614/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3557 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3615/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3557 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3616/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3557 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3617/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3556 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3618/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3556 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3619/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3556 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3620/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3555 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3621/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3555 - accuracy: 0.8459 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3622/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3555 - accuracy: 0.8459 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3623/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3554 - accuracy: 0.8459 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3624/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3554 - accuracy: 0.8459 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3625/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3554 - accuracy: 0.8459 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3626/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3554 - accuracy: 0.8459 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3627/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3553 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3628/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3553 - accuracy: 0.8431 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3629/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3553 - accuracy: 0.8431 - val_loss: 0.4804 - val_accuracy: 0.7921\n",
            "Epoch 3630/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3553 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3631/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3552 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3632/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3552 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3633/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3552 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3634/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3552 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3635/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3551 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3636/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3551 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3637/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3551 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3638/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3551 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3639/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3550 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3640/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3550 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3641/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3550 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3642/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3549 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3643/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3549 - accuracy: 0.8431 - val_loss: 0.4806 - val_accuracy: 0.7921\n",
            "Epoch 3644/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3549 - accuracy: 0.8431 - val_loss: 0.4806 - val_accuracy: 0.7921\n",
            "Epoch 3645/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3548 - accuracy: 0.8431 - val_loss: 0.4806 - val_accuracy: 0.7921\n",
            "Epoch 3646/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3548 - accuracy: 0.8431 - val_loss: 0.4806 - val_accuracy: 0.7921\n",
            "Epoch 3647/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3548 - accuracy: 0.8431 - val_loss: 0.4806 - val_accuracy: 0.7921\n",
            "Epoch 3648/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3548 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3649/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3547 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3650/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3547 - accuracy: 0.8431 - val_loss: 0.4805 - val_accuracy: 0.7921\n",
            "Epoch 3651/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3547 - accuracy: 0.8431 - val_loss: 0.4806 - val_accuracy: 0.7921\n",
            "Epoch 3652/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3546 - accuracy: 0.8431 - val_loss: 0.4806 - val_accuracy: 0.7921\n",
            "Epoch 3653/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3546 - accuracy: 0.8431 - val_loss: 0.4806 - val_accuracy: 0.7921\n",
            "Epoch 3654/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3546 - accuracy: 0.8431 - val_loss: 0.4806 - val_accuracy: 0.7921\n",
            "Epoch 3655/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3546 - accuracy: 0.8431 - val_loss: 0.4806 - val_accuracy: 0.7921\n",
            "Epoch 3656/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3545 - accuracy: 0.8431 - val_loss: 0.4806 - val_accuracy: 0.7921\n",
            "Epoch 3657/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3545 - accuracy: 0.8431 - val_loss: 0.4807 - val_accuracy: 0.7921\n",
            "Epoch 3658/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3545 - accuracy: 0.8431 - val_loss: 0.4807 - val_accuracy: 0.7921\n",
            "Epoch 3659/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3544 - accuracy: 0.8431 - val_loss: 0.4807 - val_accuracy: 0.7921\n",
            "Epoch 3660/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3544 - accuracy: 0.8459 - val_loss: 0.4807 - val_accuracy: 0.7921\n",
            "Epoch 3661/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3544 - accuracy: 0.8459 - val_loss: 0.4807 - val_accuracy: 0.7921\n",
            "Epoch 3662/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3544 - accuracy: 0.8459 - val_loss: 0.4807 - val_accuracy: 0.7921\n",
            "Epoch 3663/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3543 - accuracy: 0.8459 - val_loss: 0.4807 - val_accuracy: 0.7921\n",
            "Epoch 3664/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3543 - accuracy: 0.8459 - val_loss: 0.4807 - val_accuracy: 0.7921\n",
            "Epoch 3665/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3543 - accuracy: 0.8459 - val_loss: 0.4808 - val_accuracy: 0.7921\n",
            "Epoch 3666/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3543 - accuracy: 0.8459 - val_loss: 0.4808 - val_accuracy: 0.7921\n",
            "Epoch 3667/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3542 - accuracy: 0.8459 - val_loss: 0.4808 - val_accuracy: 0.7921\n",
            "Epoch 3668/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3542 - accuracy: 0.8459 - val_loss: 0.4808 - val_accuracy: 0.7921\n",
            "Epoch 3669/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3542 - accuracy: 0.8459 - val_loss: 0.4808 - val_accuracy: 0.7921\n",
            "Epoch 3670/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3541 - accuracy: 0.8459 - val_loss: 0.4808 - val_accuracy: 0.7921\n",
            "Epoch 3671/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3541 - accuracy: 0.8459 - val_loss: 0.4808 - val_accuracy: 0.7921\n",
            "Epoch 3672/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3541 - accuracy: 0.8459 - val_loss: 0.4808 - val_accuracy: 0.7921\n",
            "Epoch 3673/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3540 - accuracy: 0.8459 - val_loss: 0.4808 - val_accuracy: 0.7921\n",
            "Epoch 3674/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3540 - accuracy: 0.8459 - val_loss: 0.4809 - val_accuracy: 0.7921\n",
            "Epoch 3675/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3540 - accuracy: 0.8459 - val_loss: 0.4809 - val_accuracy: 0.7921\n",
            "Epoch 3676/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3540 - accuracy: 0.8459 - val_loss: 0.4809 - val_accuracy: 0.7921\n",
            "Epoch 3677/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3539 - accuracy: 0.8487 - val_loss: 0.4810 - val_accuracy: 0.7921\n",
            "Epoch 3678/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3539 - accuracy: 0.8487 - val_loss: 0.4810 - val_accuracy: 0.7921\n",
            "Epoch 3679/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3539 - accuracy: 0.8487 - val_loss: 0.4810 - val_accuracy: 0.7921\n",
            "Epoch 3680/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3539 - accuracy: 0.8487 - val_loss: 0.4810 - val_accuracy: 0.7921\n",
            "Epoch 3681/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3538 - accuracy: 0.8487 - val_loss: 0.4810 - val_accuracy: 0.7921\n",
            "Epoch 3682/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3538 - accuracy: 0.8487 - val_loss: 0.4810 - val_accuracy: 0.7921\n",
            "Epoch 3683/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3538 - accuracy: 0.8487 - val_loss: 0.4810 - val_accuracy: 0.7921\n",
            "Epoch 3684/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3537 - accuracy: 0.8487 - val_loss: 0.4810 - val_accuracy: 0.7921\n",
            "Epoch 3685/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3537 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3686/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3537 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3687/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3537 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3688/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3536 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3689/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3536 - accuracy: 0.8487 - val_loss: 0.4810 - val_accuracy: 0.7921\n",
            "Epoch 3690/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3536 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3691/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3536 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3692/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3535 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3693/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3535 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3694/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3535 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3695/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3534 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3696/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3534 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3697/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3534 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3698/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3534 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3699/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3533 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3700/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3533 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3701/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3533 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3702/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3532 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3703/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3532 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3704/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3532 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3705/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3532 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3706/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3531 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3707/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3531 - accuracy: 0.8487 - val_loss: 0.4811 - val_accuracy: 0.7921\n",
            "Epoch 3708/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3531 - accuracy: 0.8487 - val_loss: 0.4812 - val_accuracy: 0.7921\n",
            "Epoch 3709/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3531 - accuracy: 0.8487 - val_loss: 0.4812 - val_accuracy: 0.7921\n",
            "Epoch 3710/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3530 - accuracy: 0.8487 - val_loss: 0.4812 - val_accuracy: 0.7921\n",
            "Epoch 3711/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3530 - accuracy: 0.8487 - val_loss: 0.4812 - val_accuracy: 0.7921\n",
            "Epoch 3712/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3530 - accuracy: 0.8487 - val_loss: 0.4812 - val_accuracy: 0.7921\n",
            "Epoch 3713/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3530 - accuracy: 0.8487 - val_loss: 0.4812 - val_accuracy: 0.7921\n",
            "Epoch 3714/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3529 - accuracy: 0.8487 - val_loss: 0.4812 - val_accuracy: 0.7921\n",
            "Epoch 3715/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3529 - accuracy: 0.8487 - val_loss: 0.4813 - val_accuracy: 0.7921\n",
            "Epoch 3716/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3529 - accuracy: 0.8487 - val_loss: 0.4813 - val_accuracy: 0.7921\n",
            "Epoch 3717/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3529 - accuracy: 0.8487 - val_loss: 0.4813 - val_accuracy: 0.7921\n",
            "Epoch 3718/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3528 - accuracy: 0.8487 - val_loss: 0.4813 - val_accuracy: 0.7921\n",
            "Epoch 3719/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3528 - accuracy: 0.8487 - val_loss: 0.4812 - val_accuracy: 0.7921\n",
            "Epoch 3720/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3528 - accuracy: 0.8487 - val_loss: 0.4812 - val_accuracy: 0.7921\n",
            "Epoch 3721/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3528 - accuracy: 0.8487 - val_loss: 0.4812 - val_accuracy: 0.7921\n",
            "Epoch 3722/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3527 - accuracy: 0.8487 - val_loss: 0.4812 - val_accuracy: 0.7921\n",
            "Epoch 3723/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3527 - accuracy: 0.8487 - val_loss: 0.4813 - val_accuracy: 0.7921\n",
            "Epoch 3724/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3527 - accuracy: 0.8487 - val_loss: 0.4812 - val_accuracy: 0.7921\n",
            "Epoch 3725/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3527 - accuracy: 0.8487 - val_loss: 0.4812 - val_accuracy: 0.7921\n",
            "Epoch 3726/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3526 - accuracy: 0.8487 - val_loss: 0.4812 - val_accuracy: 0.7921\n",
            "Epoch 3727/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3526 - accuracy: 0.8487 - val_loss: 0.4812 - val_accuracy: 0.7921\n",
            "Epoch 3728/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3526 - accuracy: 0.8487 - val_loss: 0.4812 - val_accuracy: 0.7921\n",
            "Epoch 3729/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3526 - accuracy: 0.8487 - val_loss: 0.4813 - val_accuracy: 0.7921\n",
            "Epoch 3730/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3525 - accuracy: 0.8487 - val_loss: 0.4813 - val_accuracy: 0.7921\n",
            "Epoch 3731/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3525 - accuracy: 0.8487 - val_loss: 0.4813 - val_accuracy: 0.7921\n",
            "Epoch 3732/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3525 - accuracy: 0.8487 - val_loss: 0.4814 - val_accuracy: 0.7921\n",
            "Epoch 3733/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3525 - accuracy: 0.8459 - val_loss: 0.4814 - val_accuracy: 0.7921\n",
            "Epoch 3734/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3524 - accuracy: 0.8459 - val_loss: 0.4814 - val_accuracy: 0.7921\n",
            "Epoch 3735/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3524 - accuracy: 0.8459 - val_loss: 0.4814 - val_accuracy: 0.7921\n",
            "Epoch 3736/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3524 - accuracy: 0.8459 - val_loss: 0.4814 - val_accuracy: 0.7921\n",
            "Epoch 3737/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3524 - accuracy: 0.8459 - val_loss: 0.4814 - val_accuracy: 0.7921\n",
            "Epoch 3738/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3523 - accuracy: 0.8459 - val_loss: 0.4814 - val_accuracy: 0.7921\n",
            "Epoch 3739/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3523 - accuracy: 0.8459 - val_loss: 0.4814 - val_accuracy: 0.7921\n",
            "Epoch 3740/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3523 - accuracy: 0.8459 - val_loss: 0.4814 - val_accuracy: 0.7921\n",
            "Epoch 3741/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3523 - accuracy: 0.8459 - val_loss: 0.4814 - val_accuracy: 0.7921\n",
            "Epoch 3742/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3522 - accuracy: 0.8459 - val_loss: 0.4815 - val_accuracy: 0.7921\n",
            "Epoch 3743/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3522 - accuracy: 0.8459 - val_loss: 0.4815 - val_accuracy: 0.7921\n",
            "Epoch 3744/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3522 - accuracy: 0.8459 - val_loss: 0.4815 - val_accuracy: 0.7921\n",
            "Epoch 3745/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3522 - accuracy: 0.8459 - val_loss: 0.4815 - val_accuracy: 0.7921\n",
            "Epoch 3746/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3521 - accuracy: 0.8459 - val_loss: 0.4815 - val_accuracy: 0.7921\n",
            "Epoch 3747/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3521 - accuracy: 0.8459 - val_loss: 0.4815 - val_accuracy: 0.7921\n",
            "Epoch 3748/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3521 - accuracy: 0.8459 - val_loss: 0.4815 - val_accuracy: 0.7921\n",
            "Epoch 3749/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3521 - accuracy: 0.8459 - val_loss: 0.4815 - val_accuracy: 0.7921\n",
            "Epoch 3750/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3520 - accuracy: 0.8459 - val_loss: 0.4815 - val_accuracy: 0.7921\n",
            "Epoch 3751/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3520 - accuracy: 0.8459 - val_loss: 0.4816 - val_accuracy: 0.7921\n",
            "Epoch 3752/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3520 - accuracy: 0.8459 - val_loss: 0.4816 - val_accuracy: 0.7921\n",
            "Epoch 3753/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3520 - accuracy: 0.8459 - val_loss: 0.4815 - val_accuracy: 0.7921\n",
            "Epoch 3754/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3519 - accuracy: 0.8459 - val_loss: 0.4816 - val_accuracy: 0.7921\n",
            "Epoch 3755/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3519 - accuracy: 0.8459 - val_loss: 0.4816 - val_accuracy: 0.7921\n",
            "Epoch 3756/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3519 - accuracy: 0.8459 - val_loss: 0.4816 - val_accuracy: 0.7921\n",
            "Epoch 3757/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3519 - accuracy: 0.8459 - val_loss: 0.4816 - val_accuracy: 0.7921\n",
            "Epoch 3758/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3518 - accuracy: 0.8459 - val_loss: 0.4816 - val_accuracy: 0.7921\n",
            "Epoch 3759/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3518 - accuracy: 0.8459 - val_loss: 0.4816 - val_accuracy: 0.7921\n",
            "Epoch 3760/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3518 - accuracy: 0.8459 - val_loss: 0.4817 - val_accuracy: 0.7921\n",
            "Epoch 3761/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3518 - accuracy: 0.8459 - val_loss: 0.4817 - val_accuracy: 0.7921\n",
            "Epoch 3762/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3517 - accuracy: 0.8459 - val_loss: 0.4817 - val_accuracy: 0.7921\n",
            "Epoch 3763/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3517 - accuracy: 0.8459 - val_loss: 0.4817 - val_accuracy: 0.7921\n",
            "Epoch 3764/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3517 - accuracy: 0.8459 - val_loss: 0.4817 - val_accuracy: 0.7921\n",
            "Epoch 3765/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3517 - accuracy: 0.8459 - val_loss: 0.4817 - val_accuracy: 0.7921\n",
            "Epoch 3766/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3516 - accuracy: 0.8459 - val_loss: 0.4817 - val_accuracy: 0.7921\n",
            "Epoch 3767/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3516 - accuracy: 0.8459 - val_loss: 0.4818 - val_accuracy: 0.7921\n",
            "Epoch 3768/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3516 - accuracy: 0.8459 - val_loss: 0.4818 - val_accuracy: 0.7921\n",
            "Epoch 3769/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3515 - accuracy: 0.8459 - val_loss: 0.4818 - val_accuracy: 0.7921\n",
            "Epoch 3770/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3515 - accuracy: 0.8459 - val_loss: 0.4818 - val_accuracy: 0.7921\n",
            "Epoch 3771/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3515 - accuracy: 0.8459 - val_loss: 0.4818 - val_accuracy: 0.7921\n",
            "Epoch 3772/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3515 - accuracy: 0.8459 - val_loss: 0.4817 - val_accuracy: 0.7921\n",
            "Epoch 3773/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3514 - accuracy: 0.8459 - val_loss: 0.4818 - val_accuracy: 0.7921\n",
            "Epoch 3774/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3514 - accuracy: 0.8459 - val_loss: 0.4818 - val_accuracy: 0.7921\n",
            "Epoch 3775/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3514 - accuracy: 0.8459 - val_loss: 0.4818 - val_accuracy: 0.7921\n",
            "Epoch 3776/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3514 - accuracy: 0.8459 - val_loss: 0.4818 - val_accuracy: 0.7921\n",
            "Epoch 3777/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3513 - accuracy: 0.8459 - val_loss: 0.4818 - val_accuracy: 0.7921\n",
            "Epoch 3778/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3513 - accuracy: 0.8459 - val_loss: 0.4818 - val_accuracy: 0.7921\n",
            "Epoch 3779/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3513 - accuracy: 0.8459 - val_loss: 0.4819 - val_accuracy: 0.7921\n",
            "Epoch 3780/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3513 - accuracy: 0.8459 - val_loss: 0.4819 - val_accuracy: 0.7921\n",
            "Epoch 3781/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3512 - accuracy: 0.8459 - val_loss: 0.4819 - val_accuracy: 0.7921\n",
            "Epoch 3782/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3512 - accuracy: 0.8459 - val_loss: 0.4819 - val_accuracy: 0.7921\n",
            "Epoch 3783/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3512 - accuracy: 0.8459 - val_loss: 0.4819 - val_accuracy: 0.7921\n",
            "Epoch 3784/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3512 - accuracy: 0.8459 - val_loss: 0.4820 - val_accuracy: 0.7921\n",
            "Epoch 3785/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3511 - accuracy: 0.8459 - val_loss: 0.4820 - val_accuracy: 0.7921\n",
            "Epoch 3786/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3511 - accuracy: 0.8459 - val_loss: 0.4820 - val_accuracy: 0.7921\n",
            "Epoch 3787/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3511 - accuracy: 0.8459 - val_loss: 0.4820 - val_accuracy: 0.7921\n",
            "Epoch 3788/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3510 - accuracy: 0.8459 - val_loss: 0.4821 - val_accuracy: 0.7921\n",
            "Epoch 3789/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3510 - accuracy: 0.8459 - val_loss: 0.4821 - val_accuracy: 0.7921\n",
            "Epoch 3790/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3510 - accuracy: 0.8459 - val_loss: 0.4821 - val_accuracy: 0.7921\n",
            "Epoch 3791/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3510 - accuracy: 0.8459 - val_loss: 0.4821 - val_accuracy: 0.7921\n",
            "Epoch 3792/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3509 - accuracy: 0.8459 - val_loss: 0.4821 - val_accuracy: 0.7921\n",
            "Epoch 3793/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3509 - accuracy: 0.8459 - val_loss: 0.4821 - val_accuracy: 0.7921\n",
            "Epoch 3794/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3509 - accuracy: 0.8459 - val_loss: 0.4821 - val_accuracy: 0.7921\n",
            "Epoch 3795/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3509 - accuracy: 0.8459 - val_loss: 0.4821 - val_accuracy: 0.7921\n",
            "Epoch 3796/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3509 - accuracy: 0.8459 - val_loss: 0.4821 - val_accuracy: 0.7921\n",
            "Epoch 3797/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3508 - accuracy: 0.8459 - val_loss: 0.4821 - val_accuracy: 0.7921\n",
            "Epoch 3798/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3508 - accuracy: 0.8459 - val_loss: 0.4821 - val_accuracy: 0.7921\n",
            "Epoch 3799/4000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3508 - accuracy: 0.8459 - val_loss: 0.4821 - val_accuracy: 0.7921\n",
            "Epoch 3800/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3508 - accuracy: 0.8459 - val_loss: 0.4821 - val_accuracy: 0.7921\n",
            "Epoch 3801/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3507 - accuracy: 0.8459 - val_loss: 0.4821 - val_accuracy: 0.7921\n",
            "Epoch 3802/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3507 - accuracy: 0.8459 - val_loss: 0.4822 - val_accuracy: 0.7921\n",
            "Epoch 3803/4000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3507 - accuracy: 0.8459 - val_loss: 0.4822 - val_accuracy: 0.7921\n",
            "Epoch 3804/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3507 - accuracy: 0.8459 - val_loss: 0.4822 - val_accuracy: 0.7921\n",
            "Epoch 3805/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3506 - accuracy: 0.8459 - val_loss: 0.4822 - val_accuracy: 0.7921\n",
            "Epoch 3806/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3506 - accuracy: 0.8459 - val_loss: 0.4822 - val_accuracy: 0.7921\n",
            "Epoch 3807/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3506 - accuracy: 0.8459 - val_loss: 0.4823 - val_accuracy: 0.7921\n",
            "Epoch 3808/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3506 - accuracy: 0.8459 - val_loss: 0.4823 - val_accuracy: 0.7921\n",
            "Epoch 3809/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3505 - accuracy: 0.8459 - val_loss: 0.4823 - val_accuracy: 0.7921\n",
            "Epoch 3810/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3505 - accuracy: 0.8459 - val_loss: 0.4823 - val_accuracy: 0.7921\n",
            "Epoch 3811/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3505 - accuracy: 0.8459 - val_loss: 0.4823 - val_accuracy: 0.7921\n",
            "Epoch 3812/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3505 - accuracy: 0.8459 - val_loss: 0.4823 - val_accuracy: 0.7921\n",
            "Epoch 3813/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3504 - accuracy: 0.8459 - val_loss: 0.4823 - val_accuracy: 0.7921\n",
            "Epoch 3814/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3504 - accuracy: 0.8459 - val_loss: 0.4824 - val_accuracy: 0.7921\n",
            "Epoch 3815/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3504 - accuracy: 0.8459 - val_loss: 0.4824 - val_accuracy: 0.7921\n",
            "Epoch 3816/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3503 - accuracy: 0.8459 - val_loss: 0.4824 - val_accuracy: 0.7921\n",
            "Epoch 3817/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3503 - accuracy: 0.8459 - val_loss: 0.4824 - val_accuracy: 0.7921\n",
            "Epoch 3818/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3503 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3819/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3503 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3820/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3503 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3821/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3502 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3822/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3502 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3823/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3502 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3824/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3502 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3825/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3501 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3826/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3501 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3827/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3501 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3828/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3501 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3829/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3500 - accuracy: 0.8459 - val_loss: 0.4824 - val_accuracy: 0.7921\n",
            "Epoch 3830/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3500 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3831/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3500 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3832/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3500 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3833/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3499 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3834/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3499 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3835/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3499 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3836/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3499 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3837/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3498 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3838/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3498 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3839/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3498 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3840/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3498 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3841/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3497 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3842/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3497 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3843/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3497 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3844/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3497 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3845/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3496 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3846/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3496 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3847/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3496 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3848/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3496 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3849/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3495 - accuracy: 0.8459 - val_loss: 0.4825 - val_accuracy: 0.7921\n",
            "Epoch 3850/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3495 - accuracy: 0.8459 - val_loss: 0.4826 - val_accuracy: 0.7921\n",
            "Epoch 3851/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3495 - accuracy: 0.8459 - val_loss: 0.4826 - val_accuracy: 0.7921\n",
            "Epoch 3852/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3495 - accuracy: 0.8459 - val_loss: 0.4826 - val_accuracy: 0.7921\n",
            "Epoch 3853/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3494 - accuracy: 0.8459 - val_loss: 0.4826 - val_accuracy: 0.7921\n",
            "Epoch 3854/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3494 - accuracy: 0.8459 - val_loss: 0.4826 - val_accuracy: 0.7921\n",
            "Epoch 3855/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3494 - accuracy: 0.8459 - val_loss: 0.4826 - val_accuracy: 0.7921\n",
            "Epoch 3856/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3494 - accuracy: 0.8459 - val_loss: 0.4826 - val_accuracy: 0.7921\n",
            "Epoch 3857/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3494 - accuracy: 0.8459 - val_loss: 0.4826 - val_accuracy: 0.7921\n",
            "Epoch 3858/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3493 - accuracy: 0.8459 - val_loss: 0.4826 - val_accuracy: 0.7921\n",
            "Epoch 3859/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3493 - accuracy: 0.8459 - val_loss: 0.4826 - val_accuracy: 0.7921\n",
            "Epoch 3860/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3493 - accuracy: 0.8459 - val_loss: 0.4826 - val_accuracy: 0.7921\n",
            "Epoch 3861/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3493 - accuracy: 0.8459 - val_loss: 0.4826 - val_accuracy: 0.7921\n",
            "Epoch 3862/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3492 - accuracy: 0.8459 - val_loss: 0.4826 - val_accuracy: 0.7921\n",
            "Epoch 3863/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3492 - accuracy: 0.8459 - val_loss: 0.4826 - val_accuracy: 0.7921\n",
            "Epoch 3864/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3492 - accuracy: 0.8459 - val_loss: 0.4826 - val_accuracy: 0.7921\n",
            "Epoch 3865/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3492 - accuracy: 0.8459 - val_loss: 0.4827 - val_accuracy: 0.7921\n",
            "Epoch 3866/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3491 - accuracy: 0.8459 - val_loss: 0.4827 - val_accuracy: 0.7921\n",
            "Epoch 3867/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3491 - accuracy: 0.8459 - val_loss: 0.4827 - val_accuracy: 0.7921\n",
            "Epoch 3868/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3491 - accuracy: 0.8459 - val_loss: 0.4827 - val_accuracy: 0.7921\n",
            "Epoch 3869/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3491 - accuracy: 0.8459 - val_loss: 0.4827 - val_accuracy: 0.7921\n",
            "Epoch 3870/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3490 - accuracy: 0.8459 - val_loss: 0.4827 - val_accuracy: 0.7921\n",
            "Epoch 3871/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3490 - accuracy: 0.8459 - val_loss: 0.4827 - val_accuracy: 0.7921\n",
            "Epoch 3872/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3490 - accuracy: 0.8459 - val_loss: 0.4827 - val_accuracy: 0.7921\n",
            "Epoch 3873/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3490 - accuracy: 0.8459 - val_loss: 0.4827 - val_accuracy: 0.7921\n",
            "Epoch 3874/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3489 - accuracy: 0.8459 - val_loss: 0.4827 - val_accuracy: 0.7921\n",
            "Epoch 3875/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3489 - accuracy: 0.8459 - val_loss: 0.4827 - val_accuracy: 0.7921\n",
            "Epoch 3876/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3489 - accuracy: 0.8459 - val_loss: 0.4827 - val_accuracy: 0.7921\n",
            "Epoch 3877/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3489 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3878/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3488 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3879/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3488 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3880/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3488 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3881/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3487 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3882/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3487 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3883/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3487 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3884/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3487 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3885/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3486 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3886/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3486 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3887/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3486 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3888/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3486 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3889/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3485 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3890/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3485 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3891/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3485 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3892/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3485 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3893/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3484 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3894/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3484 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3895/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3484 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3896/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3484 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3897/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3483 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3898/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3483 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3899/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3483 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3900/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3483 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3901/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3482 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3902/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3482 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3903/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3482 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3904/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3482 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3905/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3482 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3906/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3481 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3907/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3481 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3908/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3481 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3909/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3481 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3910/4000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.3480 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3911/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3480 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3912/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3480 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3913/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3480 - accuracy: 0.8459 - val_loss: 0.4828 - val_accuracy: 0.7921\n",
            "Epoch 3914/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3479 - accuracy: 0.8459 - val_loss: 0.4829 - val_accuracy: 0.7921\n",
            "Epoch 3915/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3479 - accuracy: 0.8459 - val_loss: 0.4829 - val_accuracy: 0.7921\n",
            "Epoch 3916/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3479 - accuracy: 0.8487 - val_loss: 0.4829 - val_accuracy: 0.7921\n",
            "Epoch 3917/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3479 - accuracy: 0.8487 - val_loss: 0.4829 - val_accuracy: 0.7921\n",
            "Epoch 3918/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3478 - accuracy: 0.8487 - val_loss: 0.4829 - val_accuracy: 0.7921\n",
            "Epoch 3919/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3478 - accuracy: 0.8487 - val_loss: 0.4829 - val_accuracy: 0.7921\n",
            "Epoch 3920/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3478 - accuracy: 0.8487 - val_loss: 0.4829 - val_accuracy: 0.7921\n",
            "Epoch 3921/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3478 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7921\n",
            "Epoch 3922/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3478 - accuracy: 0.8487 - val_loss: 0.4829 - val_accuracy: 0.7921\n",
            "Epoch 3923/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3477 - accuracy: 0.8487 - val_loss: 0.4829 - val_accuracy: 0.7921\n",
            "Epoch 3924/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3477 - accuracy: 0.8487 - val_loss: 0.4829 - val_accuracy: 0.7921\n",
            "Epoch 3925/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3477 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7921\n",
            "Epoch 3926/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3477 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7921\n",
            "Epoch 3927/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3476 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7921\n",
            "Epoch 3928/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3476 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7921\n",
            "Epoch 3929/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3476 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7921\n",
            "Epoch 3930/4000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.3476 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7921\n",
            "Epoch 3931/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3476 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7921\n",
            "Epoch 3932/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3475 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7921\n",
            "Epoch 3933/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3475 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7921\n",
            "Epoch 3934/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3475 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7921\n",
            "Epoch 3935/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3475 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7921\n",
            "Epoch 3936/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3475 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7921\n",
            "Epoch 3937/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3474 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7921\n",
            "Epoch 3938/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3474 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3939/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3474 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3940/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3474 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3941/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3473 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3942/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3473 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3943/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3473 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3944/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3473 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3945/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3473 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3946/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3472 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3947/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3472 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3948/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3472 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3949/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3472 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3950/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3472 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3951/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3471 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3952/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3471 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3953/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3471 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3954/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3471 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3955/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3471 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3956/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3470 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3957/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3470 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3958/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3470 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3959/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3470 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3960/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3470 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3961/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3469 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3962/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3469 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3963/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3469 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3964/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3469 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3965/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3469 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3966/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3469 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3967/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3468 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3968/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3468 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3969/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3468 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3970/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3468 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3971/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3468 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3972/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3467 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3973/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3467 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3974/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3467 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7921\n",
            "Epoch 3975/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3467 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7978\n",
            "Epoch 3976/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3467 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7978\n",
            "Epoch 3977/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3466 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7978\n",
            "Epoch 3978/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3466 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7978\n",
            "Epoch 3979/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3466 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7978\n",
            "Epoch 3980/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3466 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7978\n",
            "Epoch 3981/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3466 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7978\n",
            "Epoch 3982/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3465 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7978\n",
            "Epoch 3983/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3465 - accuracy: 0.8487 - val_loss: 0.4830 - val_accuracy: 0.7978\n",
            "Epoch 3984/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3465 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7978\n",
            "Epoch 3985/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3465 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7978\n",
            "Epoch 3986/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3465 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7978\n",
            "Epoch 3987/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3464 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7978\n",
            "Epoch 3988/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3464 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7978\n",
            "Epoch 3989/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3464 - accuracy: 0.8487 - val_loss: 0.4831 - val_accuracy: 0.7978\n",
            "Epoch 3990/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3464 - accuracy: 0.8487 - val_loss: 0.4832 - val_accuracy: 0.7978\n",
            "Epoch 3991/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3464 - accuracy: 0.8487 - val_loss: 0.4832 - val_accuracy: 0.7978\n",
            "Epoch 3992/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3463 - accuracy: 0.8487 - val_loss: 0.4832 - val_accuracy: 0.7978\n",
            "Epoch 3993/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3463 - accuracy: 0.8515 - val_loss: 0.4832 - val_accuracy: 0.7978\n",
            "Epoch 3994/4000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.3463 - accuracy: 0.8515 - val_loss: 0.4832 - val_accuracy: 0.7978\n",
            "Epoch 3995/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3463 - accuracy: 0.8515 - val_loss: 0.4832 - val_accuracy: 0.7978\n",
            "Epoch 3996/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3463 - accuracy: 0.8515 - val_loss: 0.4832 - val_accuracy: 0.7978\n",
            "Epoch 3997/4000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.3463 - accuracy: 0.8515 - val_loss: 0.4832 - val_accuracy: 0.7978\n",
            "Epoch 3998/4000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.3462 - accuracy: 0.8515 - val_loss: 0.4832 - val_accuracy: 0.7978\n",
            "Epoch 3999/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3462 - accuracy: 0.8515 - val_loss: 0.4832 - val_accuracy: 0.7978\n",
            "Epoch 4000/4000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.3462 - accuracy: 0.8515 - val_loss: 0.4832 - val_accuracy: 0.7978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizamos agora a curva de decaimento da loss para entender se o treinamento da rede foi \"saudável\"."
      ],
      "metadata": {
        "id": "CC2F8NxM5pYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(range(EPOCHS), history.history['loss'])\n",
        "plt.plot(range(EPOCHS), history.history['val_loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "VxzlSHvb5pgi",
        "outputId": "c9ee311a-3137-4b02-807c-65c367357a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos agora aplicar a rede aprendida na base de teste:"
      ],
      "metadata": {
        "id": "AckAm6xt81JK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_data_test[numeric_columns] = (features_data_test[numeric_columns]-train_mean)/(train_std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24Yogwq7ISyn",
        "outputId": "4eed48c0-f7ee-449d-c87a-c57983ca4699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(features_data_test.to_numpy())\n",
        "pred = np.argmax(pred, axis=-1)\n",
        "real = np.argmax(labels_data_test.to_numpy(), axis=-1)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(real, pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"not survived\", \"survived\"])\n",
        "disp.plot()\n",
        "plt.show()\n",
        "print(f\"Taxa de acerto: {np.sum(pred==real)/pred.shape[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "HonCjEvs9HwN",
        "outputId": "564835d2-a187-4425-836a-fe389e4c24be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Taxa de acerto: 0.7932960893854749\n"
          ]
        }
      ]
    }
  ]
}